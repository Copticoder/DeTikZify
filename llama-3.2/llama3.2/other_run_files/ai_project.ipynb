{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarelherraoui/miniconda3/envs/gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moe2015\u001b[0m (\u001b[33moe2015-mbzuai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/omarelherraoui/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/omarelherraoui/Documents/DeTikZify/detikzify/evaluate/wandb/run-20241107_230214-x39pjj9s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/x39pjj9s' target=\"_blank\">colorful-fire-4</a></strong> to <a href='https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset' target=\"_blank\">https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/x39pjj9s' target=\"_blank\">https://wandb.ai/oe2015-mbzuai/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/x39pjj9s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token = \"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\")\n",
    "\n",
    "wandb.login(key=\"0689fc9447a488ce270ed7b6220641e9eb65a62d\")\n",
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "\n",
    "new_model = \"llama-3.2-3b-detikzfy\"\n",
    "dataset_name = \"bitext/Bitext-customer-support-llm-chatbot-training-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "\n",
    "# Check for GPU (MPS) availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS device found.\")\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "0.42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarelherraoui/miniconda3/envs/gpu/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "print(bnb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarelherraoui/miniconda3/envs/gpu/lib/python3.9/site-packages/transformers/modeling_utils.py:3479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:37<00:00,  7.56s/it]\n",
      "/Users/omarelherraoui/miniconda3/envs/gpu/lib/python3.9/site-packages/transformers/models/auto/processing_auto.py:230: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# QLoRA config\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "\n",
    "# %pip install -U bitsandbytes\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch_dtype,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "# )\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "   model_id,\n",
    "   use_auth_token = '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',  # Insert your Hugging Face token here\n",
    "   torch_dtype=torch.bfloat16,\n",
    "   device_map=\"auto\",\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "   model_id,\n",
    "   use_auth_token = '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',  # Insert your Hugging Face token here\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\documentclass[10pt, oneside]{amsart}\n",
      "\\usepackage{amssymb}\n",
      "\\usepackage{amsmath}\n",
      "\\usepackage{color}\n",
      "\\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage[colorlinks=true, pdfstartview=FitV,linkcolor=ForestGreen,citecolor=ForestGreen, urlcolor=black]{hyperref}\n",
      "\\usepackage{tikz}\n",
      "\n",
      "\\begin{document}\n",
      "\n",
      "\\begin{tikzpicture}[scale =1]\n",
      "\\draw[dashed] (-6, 0) -- (6, 0) node[anchor=north, scale=1] {$Q_1$};\n",
      "% big square\n",
      "  \\draw [blue] (-3.5,0) -- (3.5,0); \n",
      "   \\draw[blue] (-3.5,-7) -- (3.5,-7);\n",
      "  \\draw [blue](-3.5,0) -- (-3.5,-7);\n",
      "  \\draw [blue](3.5,0) -- (3.5,-7) node[anchor=north, scale=1] {$Q_{\\frac{1}{2}}$};\n",
      "  %medium\n",
      "   \\draw [violet](-1,0) -- (1, 0);\n",
      "   \\draw [violet](-1,-2) -- (1, -2);\n",
      "   \\draw [violet](-1,0) -- (-1, -2);\n",
      "   \\draw [violet](1,0) -- (1, -2)  node[anchor=north, scale=1] {$Q_{r_0}$};\n",
      "   %medium past\n",
      "    \\draw[violet] (-1,-4) -- (1, -4);\n",
      "   \\draw [violet](-1,-6) -- (1, -6);\n",
      "   \\draw [violet](-1,-4) -- (-1, -6);\n",
      "   \\draw [violet](1,-4) -- (1, -6)  node[anchor=north, scale=1] {$Q^-_{r_0}$};\n",
      "     \\draw [orange](-0.5,0) -- (0.5, 0);\n",
      "   \\draw[orange] (-0.5,-1) -- (0.5, -1);\n",
      "   \\draw [orange](-0.5,0) -- (-0.5, -1);\n",
      "   \\draw [orange](0.5,0) -- (0.5, -1)  node[anchor=north, scale=0.71] {$Q_{\\frac{r_0}{2}}$};\n",
      "    \\draw[orange] {(-0.5,-4.5) -- (0.5, -4.5)};\n",
      "   \\draw [orange](-0.5,-5.5) -- (0.5, -5.5);\n",
      "   \\draw [orange](-0.5,-4.5) -- (-0.5, -5.5);\n",
      "   \\draw [orange](0.5,-4.5) -- (0.5, -5.5) node[anchor=north, scale=0.71] {$\\tilde Q^-_{\\frac{r_0}{2}}$};\n",
      "     \\draw [red](-0.25,0) -- (0.25, 0);\n",
      "   \\draw [red](-0.25,-0.5) -- (0.25, -0.5);\n",
      "   \\draw[red] (-0.25,0) -- (-0.25, -0.5);\n",
      "   \\draw[red] (0.25,0) -- (0.25, -0.5) node[anchor=north, scale=0.7] {$Q_{\\frac{r_0}{4}}$};\n",
      "     \\draw[red] (-0.25,-4.5) -- (0.25, -4.5);\n",
      "  \\draw[red] (-0.25,-5) -- (0.25, -5);\n",
      "   \\draw[red] (-0.25,-4.5) -- (-0.25, -5);\n",
      "   \\draw[red] (0.25,-4.5) -- (0.25, -5)node[anchor=north, scale=0.7] {$\\tilde Q^-_{\\frac{r_0}{4}}$};\n",
      "\\end{tikzpicture}\n",
      "\n",
      "\\end{document}\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x384 at 0x38183A8E0>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# full dataset\n",
    "ds_test = load_dataset(\"nllg/datikz-v2\", split=\"test\")\n",
    "# only the train split\n",
    "# ds_train = load_dataset(\"nllg/datikz-v2\", split=\"train\")\n",
    "# for sample in ds:\n",
    "#     print(sample[\"code\"])\n",
    "print(ds_test[0]['code'])\n",
    "print(ds_test[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarelherraoui/miniconda3/envs/gpu/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import Metrics\n",
    "from torchmetrics.image.kid import KernelInceptionDistance as KID\n",
    "from torchmetrics.text import ExtendedEditDistance\n",
    "\n",
    "# from dreamsim1 import DreamSim  # Ensure dreamsim is installed and imported\n",
    "from crystalbleu1 import CrystalBLEU  # Ensure crystalbleu is installed and imported\n",
    "\n",
    "# Define Metric Classes\n",
    "class TexEditDistance(ExtendedEditDistance):\n",
    "    def compute(self, preds, target):\n",
    "        return super().compute(preds, target)\n",
    "\n",
    "class ImageSim:\n",
    "    def compute(self, img1, img2):\n",
    "        return torch.cosine_similarity(img1, img2).item()\n",
    "\n",
    "class DreamSim:\n",
    "    def __init__(self, model_name=\"ensemble\"):\n",
    "        self.model, self.processor = model, processor\n",
    "\n",
    "    def compute(self, img1, img2):\n",
    "        img1, img2 = self.processor(img1), self.processor(img2)\n",
    "        with torch.no_grad():\n",
    "            return 1 - self.model(img1, img2).item()  # Higher is better\n",
    "\n",
    "# class CrystalBLEU:\n",
    "#     def __init__(self, corpus, k=500, n=4):\n",
    "#         self.corpus = corpus\n",
    "#         self.k = k\n",
    "#         self.n = n\n",
    "\n",
    "#     def compute(self, references, hypotheses):\n",
    "#         return CrystalBLEU(list_of_references=references, hypotheses=hypotheses)\n",
    "\n",
    "# Initialize Metrics\n",
    "kid_metric = KID()\n",
    "tex_edit_distance = TexEditDistance()\n",
    "image_sim_metric = ImageSim()\n",
    "dreamsim_metric = DreamSim()\n",
    "corpus_bleu_metric = CrystalBLEU(corpus=[ex[\"code\"] for ex in ds_test])  # Corpus from the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_tikz_code(image):\n",
    "    prompt = (\n",
    "        \"This is a picture of a scientific figure. <|image|> Generate LaTeX code that draws this scientific figure using TikZ. \"\n",
    "        \"Ensure that the LaTeX code is self-contained and does not require any packages except TikZ-related imports. \"\n",
    "        \"Don't forget to include \\\\usepackage{tikz}! Return your result in a ```latex code block.\"\n",
    "    )\n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=300)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Evaluation Loop\n",
    "for example in ds_test:\n",
    "    reference_code = example['code']\n",
    "    image_url = example['image']\n",
    "\n",
    "    # Generate TikZ code\n",
    "    generated_code = generate_tikz_code(image_url)\n",
    "    \n",
    "    # Kernel Inception Distance (KID) for generated vs. reference image\n",
    "    # kid_metric.update(generated_code, reference_code)\n",
    "    \n",
    "    # TEX Edit Distance\n",
    "    tex_edit_distance.update([generated_code], [[reference_code]])\n",
    "\n",
    "    # Image Similarity\n",
    "    # img_sim_score = image_sim_metric.compute(generated_code, reference_code)\n",
    "    \n",
    "    # DreamSim Metric\n",
    "    # dreamsim_score = dreamsim_metric.compute(generated_code, reference_code)\n",
    "\n",
    "    # CrystalBLEU\n",
    "    corpus_bleu_metric.update(\n",
    "        list_of_references=[[reference_code]],\n",
    "        hypotheses=[generated_code]\n",
    "    )\n",
    "    print(\"done\")\n",
    "\n",
    "# Compute and print final scores\n",
    "# print(\"Kernel Inception Distance:\", kid_metric.compute())\n",
    "print(\"TEX Edit Distance:\", tex_edit_distance.compute())\n",
    "# print(\"Image Similarity:\", img_sim_score)\n",
    "# print(\"DreamSim Score:\", dreamsim_score)\n",
    "print(\"CrystalBLEU Score:\", corpus_bleu_metric.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
