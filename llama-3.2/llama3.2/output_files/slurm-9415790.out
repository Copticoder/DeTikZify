Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:11<00:44, 11.07s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:20<00:29,  9.96s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:29<00:19,  9.60s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:39<00:09,  9.91s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:43<00:00,  7.54s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:43<00:00,  8.63s/it]
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
trainable params: 11,796,480 || all params: 10,682,017,315 || trainable%: 0.1104
#############################
Generating test split:   0%|          | 0/561 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 561/561 [00:00<00:00, 4602.78 examples/s]Generating test split: 100%|██████████| 561/561 [00:00<00:00, 4461.64 examples/s]
Generating train split:   0%|          | 0/49692 [00:00<?, ? examples/s]Generating train split:   3%|▎         | 1400/49692 [00:00<00:03, 12561.99 examples/s]Generating train split:   6%|▌         | 2900/49692 [00:00<00:03, 13287.48 examples/s]Generating train split:   9%|▊         | 4300/49692 [00:00<00:03, 13453.17 examples/s]Generating train split:  12%|█▏        | 5800/49692 [00:00<00:03, 13601.44 examples/s]Generating train split:  15%|█▍        | 7300/49692 [00:00<00:03, 13766.34 examples/s]Generating train split:  18%|█▊        | 8800/49692 [00:00<00:02, 13931.87 examples/s]Generating train split:  21%|██        | 10400/49692 [00:00<00:02, 14217.63 examples/s]Generating train split:  24%|██▍       | 11900/49692 [00:00<00:02, 14213.11 examples/s]Generating train split:  27%|██▋       | 13400/49692 [00:00<00:02, 14149.83 examples/s]Generating train split:  31%|███       | 15400/49692 [00:01<00:02, 13243.81 examples/s]Generating train split:  34%|███▍      | 16900/49692 [00:01<00:03, 8347.96 examples/s] Generating train split:  36%|███▋      | 18100/49692 [00:01<00:03, 8885.00 examples/s]Generating train split:  39%|███▉      | 19300/49692 [00:01<00:03, 9376.70 examples/s]Generating train split:  41%|████▏     | 20600/49692 [00:01<00:02, 10027.82 examples/s]Generating train split:  44%|████▍     | 21900/49692 [00:01<00:02, 10533.52 examples/s]Generating train split:  47%|████▋     | 23300/49692 [00:02<00:02, 11059.36 examples/s]Generating train split:  50%|████▉     | 24700/49692 [00:02<00:02, 11524.63 examples/s]Generating train split:  52%|█████▏    | 25946/49692 [00:02<00:02, 11603.55 examples/s]Generating train split:  55%|█████▍    | 27246/49692 [00:02<00:01, 11650.92 examples/s]Generating train split:  57%|█████▋    | 28546/49692 [00:02<00:01, 11752.48 examples/s]Generating train split:  60%|██████    | 29946/49692 [00:02<00:01, 12031.33 examples/s]Generating train split:  63%|██████▎   | 31346/49692 [00:02<00:01, 12148.37 examples/s]Generating train split:  67%|██████▋   | 33146/49692 [00:02<00:01, 12036.06 examples/s]Generating train split:  70%|███████   | 34946/49692 [00:02<00:01, 11904.41 examples/s]Generating train split:  73%|███████▎  | 36246/49692 [00:03<00:01, 11922.10 examples/s]Generating train split:  75%|███████▌  | 37446/49692 [00:03<00:01, 11850.04 examples/s]Generating train split:  78%|███████▊  | 38846/49692 [00:03<00:00, 12027.09 examples/s]Generating train split:  81%|████████  | 40146/49692 [00:03<00:00, 11960.53 examples/s]Generating train split:  84%|████████▎ | 41546/49692 [00:03<00:00, 12078.89 examples/s]Generating train split:  86%|████████▌ | 42846/49692 [00:03<00:00, 12089.06 examples/s]Generating train split:  89%|████████▉ | 44146/49692 [00:03<00:00, 12019.78 examples/s]Generating train split:  92%|█████████▏| 45946/49692 [00:03<00:00, 11582.30 examples/s]Generating train split:  96%|█████████▌| 47546/49692 [00:04<00:00, 10925.50 examples/s]Generating train split:  98%|█████████▊| 48946/49692 [00:04<00:00, 7124.41 examples/s] Generating train split: 100%|██████████| 49692/49692 [00:04<00:00, 10959.50 examples/s]
Epoch 1/3
Training:   0%|          | 0/6212 [00:00<?, ?it/s]Training:   0%|          | 0/6212 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/train3.py", line 414, in <module>
    train_model(model.language_model, train_dataloader, optimizer, epochs=3)
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/train3.py", line 371, in train_model
    for i, batch in enumerate(tqdm(train_dataloader, desc="Training")):
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/train3.py", line 259, in collate_fn
    image_batch_no_trunc = processor(
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/models/mllama/processing_mllama.py", line 304, in __call__
    raise ValueError(
ValueError: The number of image token (1) should be the same as in the number of provided images (8)
