WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:11<00:47, 11.91s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:15<00:21,  7.08s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:19<00:11,  5.53s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:04,  4.80s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.82s/it]
Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:12,  6.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:10<00:04,  4.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.73s/it]
Some weights of the model checkpoint at /home/oe2015/final_model_checkpoint_512_quant were not used when initializing MllamaForCausalLM: ['model.layers.0.mlp.down_proj.SCB', 'model.layers.0.mlp.down_proj.weight_format', 'model.layers.0.mlp.gate_proj.SCB', 'model.layers.0.mlp.gate_proj.weight_format', 'model.layers.0.mlp.up_proj.SCB', 'model.layers.0.mlp.up_proj.weight_format', 'model.layers.0.self_attn.k_proj.SCB', 'model.layers.0.self_attn.k_proj.weight_format', 'model.layers.0.self_attn.o_proj.SCB', 'model.layers.0.self_attn.o_proj.weight_format', 'model.layers.0.self_attn.q_proj.base_layer.SCB', 'model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.base_layer.weight_format', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.SCB', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight_format', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.mlp.down_proj.SCB', 'model.layers.1.mlp.down_proj.weight_format', 'model.layers.1.mlp.gate_proj.SCB', 'model.layers.1.mlp.gate_proj.weight_format', 'model.layers.1.mlp.up_proj.SCB', 'model.layers.1.mlp.up_proj.weight_format', 'model.layers.1.self_attn.k_proj.SCB', 'model.layers.1.self_attn.k_proj.weight_format', 'model.layers.1.self_attn.o_proj.SCB', 'model.layers.1.self_attn.o_proj.weight_format', 'model.layers.1.self_attn.q_proj.base_layer.SCB', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight_format', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.SCB', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight_format', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.10.mlp.down_proj.SCB', 'model.layers.10.mlp.down_proj.weight_format', 'model.layers.10.mlp.gate_proj.SCB', 'model.layers.10.mlp.gate_proj.weight_format', 'model.layers.10.mlp.up_proj.SCB', 'model.layers.10.mlp.up_proj.weight_format', 'model.layers.10.self_attn.k_proj.SCB', 'model.layers.10.self_attn.k_proj.weight_format', 'model.layers.10.self_attn.o_proj.SCB', 'model.layers.10.self_attn.o_proj.weight_format', 'model.layers.10.self_attn.q_proj.base_layer.SCB', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight_format', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.SCB', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight_format', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.11.mlp.down_proj.SCB', 'model.layers.11.mlp.down_proj.weight_format', 'model.layers.11.mlp.gate_proj.SCB', 'model.layers.11.mlp.gate_proj.weight_format', 'model.layers.11.mlp.up_proj.SCB', 'model.layers.11.mlp.up_proj.weight_format', 'model.layers.11.self_attn.k_proj.SCB', 'model.layers.11.self_attn.k_proj.weight_format', 'model.layers.11.self_attn.o_proj.SCB', 'model.layers.11.self_attn.o_proj.weight_format', 'model.layers.11.self_attn.q_proj.base_layer.SCB', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight_format', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.v_proj.base_layer.SCB', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight_format', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.mlp.down_proj.SCB', 'model.layers.12.mlp.down_proj.weight_format', 'model.layers.12.mlp.gate_proj.SCB', 'model.layers.12.mlp.gate_proj.weight_format', 'model.layers.12.mlp.up_proj.SCB', 'model.layers.12.mlp.up_proj.weight_format', 'model.layers.12.self_attn.k_proj.SCB', 'model.layers.12.self_attn.k_proj.weight_format', 'model.layers.12.self_attn.o_proj.SCB', 'model.layers.12.self_attn.o_proj.weight_format', 'model.layers.12.self_attn.q_proj.base_layer.SCB', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight_format', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.SCB', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight_format', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.13.cross_attn.k_proj.SCB', 'model.layers.13.cross_attn.k_proj.weight_format', 'model.layers.13.cross_attn.o_proj.SCB', 'model.layers.13.cross_attn.o_proj.weight_format', 'model.layers.13.cross_attn.q_proj.base_layer.SCB', 'model.layers.13.cross_attn.q_proj.base_layer.weight', 'model.layers.13.cross_attn.q_proj.base_layer.weight_format', 'model.layers.13.cross_attn.q_proj.lora_A.default.weight', 'model.layers.13.cross_attn.q_proj.lora_B.default.weight', 'model.layers.13.cross_attn.v_proj.base_layer.SCB', 'model.layers.13.cross_attn.v_proj.base_layer.weight', 'model.layers.13.cross_attn.v_proj.base_layer.weight_format', 'model.layers.13.cross_attn.v_proj.lora_A.default.weight', 'model.layers.13.cross_attn.v_proj.lora_B.default.weight', 'model.layers.13.mlp.down_proj.SCB', 'model.layers.13.mlp.down_proj.weight_format', 'model.layers.13.mlp.gate_proj.SCB', 'model.layers.13.mlp.gate_proj.weight_format', 'model.layers.13.mlp.up_proj.SCB', 'model.layers.13.mlp.up_proj.weight_format', 'model.layers.14.mlp.down_proj.SCB', 'model.layers.14.mlp.down_proj.weight_format', 'model.layers.14.mlp.gate_proj.SCB', 'model.layers.14.mlp.gate_proj.weight_format', 'model.layers.14.mlp.up_proj.SCB', 'model.layers.14.mlp.up_proj.weight_format', 'model.layers.14.self_attn.k_proj.SCB', 'model.layers.14.self_attn.k_proj.weight_format', 'model.layers.14.self_attn.o_proj.SCB', 'model.layers.14.self_attn.o_proj.weight_format', 'model.layers.14.self_attn.q_proj.base_layer.SCB', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight_format', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.SCB', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight_format', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.mlp.down_proj.SCB', 'model.layers.15.mlp.down_proj.weight_format', 'model.layers.15.mlp.gate_proj.SCB', 'model.layers.15.mlp.gate_proj.weight_format', 'model.layers.15.mlp.up_proj.SCB', 'model.layers.15.mlp.up_proj.weight_format', 'model.layers.15.self_attn.k_proj.SCB', 'model.layers.15.self_attn.k_proj.weight_format', 'model.layers.15.self_attn.o_proj.SCB', 'model.layers.15.self_attn.o_proj.weight_format', 'model.layers.15.self_attn.q_proj.base_layer.SCB', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight_format', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.SCB', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight_format', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.mlp.down_proj.SCB', 'model.layers.16.mlp.down_proj.weight_format', 'model.layers.16.mlp.gate_proj.SCB', 'model.layers.16.mlp.gate_proj.weight_format', 'model.layers.16.mlp.up_proj.SCB', 'model.layers.16.mlp.up_proj.weight_format', 'model.layers.16.self_attn.k_proj.SCB', 'model.layers.16.self_attn.k_proj.weight_format', 'model.layers.16.self_attn.o_proj.SCB', 'model.layers.16.self_attn.o_proj.weight_format', 'model.layers.16.self_attn.q_proj.base_layer.SCB', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight_format', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.SCB', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight_format', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.17.mlp.down_proj.SCB', 'model.layers.17.mlp.down_proj.weight_format', 'model.layers.17.mlp.gate_proj.SCB', 'model.layers.17.mlp.gate_proj.weight_format', 'model.layers.17.mlp.up_proj.SCB', 'model.layers.17.mlp.up_proj.weight_format', 'model.layers.17.self_attn.k_proj.SCB', 'model.layers.17.self_attn.k_proj.weight_format', 'model.layers.17.self_attn.o_proj.SCB', 'model.layers.17.self_attn.o_proj.weight_format', 'model.layers.17.self_attn.q_proj.base_layer.SCB', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight_format', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.base_layer.SCB', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight_format', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.cross_attn.k_proj.SCB', 'model.layers.18.cross_attn.k_proj.weight_format', 'model.layers.18.cross_attn.o_proj.SCB', 'model.layers.18.cross_attn.o_proj.weight_format', 'model.layers.18.cross_attn.q_proj.base_layer.SCB', 'model.layers.18.cross_attn.q_proj.base_layer.weight', 'model.layers.18.cross_attn.q_proj.base_layer.weight_format', 'model.layers.18.cross_attn.q_proj.lora_A.default.weight', 'model.layers.18.cross_attn.q_proj.lora_B.default.weight', 'model.layers.18.cross_attn.v_proj.base_layer.SCB', 'model.layers.18.cross_attn.v_proj.base_layer.weight', 'model.layers.18.cross_attn.v_proj.base_layer.weight_format', 'model.layers.18.cross_attn.v_proj.lora_A.default.weight', 'model.layers.18.cross_attn.v_proj.lora_B.default.weight', 'model.layers.18.mlp.down_proj.SCB', 'model.layers.18.mlp.down_proj.weight_format', 'model.layers.18.mlp.gate_proj.SCB', 'model.layers.18.mlp.gate_proj.weight_format', 'model.layers.18.mlp.up_proj.SCB', 'model.layers.18.mlp.up_proj.weight_format', 'model.layers.19.mlp.down_proj.SCB', 'model.layers.19.mlp.down_proj.weight_format', 'model.layers.19.mlp.gate_proj.SCB', 'model.layers.19.mlp.gate_proj.weight_format', 'model.layers.19.mlp.up_proj.SCB', 'model.layers.19.mlp.up_proj.weight_format', 'model.layers.19.self_attn.k_proj.SCB', 'model.layers.19.self_attn.k_proj.weight_format', 'model.layers.19.self_attn.o_proj.SCB', 'model.layers.19.self_attn.o_proj.weight_format', 'model.layers.19.self_attn.q_proj.base_layer.SCB', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight_format', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.v_proj.base_layer.SCB', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight_format', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.2.mlp.down_proj.SCB', 'model.layers.2.mlp.down_proj.weight_format', 'model.layers.2.mlp.gate_proj.SCB', 'model.layers.2.mlp.gate_proj.weight_format', 'model.layers.2.mlp.up_proj.SCB', 'model.layers.2.mlp.up_proj.weight_format', 'model.layers.2.self_attn.k_proj.SCB', 'model.layers.2.self_attn.k_proj.weight_format', 'model.layers.2.self_attn.o_proj.SCB', 'model.layers.2.self_attn.o_proj.weight_format', 'model.layers.2.self_attn.q_proj.base_layer.SCB', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight_format', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.base_layer.SCB', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight_format', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.mlp.down_proj.SCB', 'model.layers.20.mlp.down_proj.weight_format', 'model.layers.20.mlp.gate_proj.SCB', 'model.layers.20.mlp.gate_proj.weight_format', 'model.layers.20.mlp.up_proj.SCB', 'model.layers.20.mlp.up_proj.weight_format', 'model.layers.20.self_attn.k_proj.SCB', 'model.layers.20.self_attn.k_proj.weight_format', 'model.layers.20.self_attn.o_proj.SCB', 'model.layers.20.self_attn.o_proj.weight_format', 'model.layers.20.self_attn.q_proj.base_layer.SCB', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight_format', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.SCB', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight_format', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.mlp.down_proj.SCB', 'model.layers.21.mlp.down_proj.weight_format', 'model.layers.21.mlp.gate_proj.SCB', 'model.layers.21.mlp.gate_proj.weight_format', 'model.layers.21.mlp.up_proj.SCB', 'model.layers.21.mlp.up_proj.weight_format', 'model.layers.21.self_attn.k_proj.SCB', 'model.layers.21.self_attn.k_proj.weight_format', 'model.layers.21.self_attn.o_proj.SCB', 'model.layers.21.self_attn.o_proj.weight_format', 'model.layers.21.self_attn.q_proj.base_layer.SCB', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight_format', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.SCB', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight_format', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.mlp.down_proj.SCB', 'model.layers.22.mlp.down_proj.weight_format', 'model.layers.22.mlp.gate_proj.SCB', 'model.layers.22.mlp.gate_proj.weight_format', 'model.layers.22.mlp.up_proj.SCB', 'model.layers.22.mlp.up_proj.weight_format', 'model.layers.22.self_attn.k_proj.SCB', 'model.layers.22.self_attn.k_proj.weight_format', 'model.layers.22.self_attn.o_proj.SCB', 'model.layers.22.self_attn.o_proj.weight_format', 'model.layers.22.self_attn.q_proj.base_layer.SCB', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight_format', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.SCB', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight_format', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.cross_attn.k_proj.SCB', 'model.layers.23.cross_attn.k_proj.weight_format', 'model.layers.23.cross_attn.o_proj.SCB', 'model.layers.23.cross_attn.o_proj.weight_format', 'model.layers.23.cross_attn.q_proj.base_layer.SCB', 'model.layers.23.cross_attn.q_proj.base_layer.weight', 'model.layers.23.cross_attn.q_proj.base_layer.weight_format', 'model.layers.23.cross_attn.q_proj.lora_A.default.weight', 'model.layers.23.cross_attn.q_proj.lora_B.default.weight', 'model.layers.23.cross_attn.v_proj.base_layer.SCB', 'model.layers.23.cross_attn.v_proj.base_layer.weight', 'model.layers.23.cross_attn.v_proj.base_layer.weight_format', 'model.layers.23.cross_attn.v_proj.lora_A.default.weight', 'model.layers.23.cross_attn.v_proj.lora_B.default.weight', 'model.layers.23.mlp.down_proj.SCB', 'model.layers.23.mlp.down_proj.weight_format', 'model.layers.23.mlp.gate_proj.SCB', 'model.layers.23.mlp.gate_proj.weight_format', 'model.layers.23.mlp.up_proj.SCB', 'model.layers.23.mlp.up_proj.weight_format', 'model.layers.24.mlp.down_proj.SCB', 'model.layers.24.mlp.down_proj.weight_format', 'model.layers.24.mlp.gate_proj.SCB', 'model.layers.24.mlp.gate_proj.weight_format', 'model.layers.24.mlp.up_proj.SCB', 'model.layers.24.mlp.up_proj.weight_format', 'model.layers.24.self_attn.k_proj.SCB', 'model.layers.24.self_attn.k_proj.weight_format', 'model.layers.24.self_attn.o_proj.SCB', 'model.layers.24.self_attn.o_proj.weight_format', 'model.layers.24.self_attn.q_proj.base_layer.SCB', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight_format', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.SCB', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight_format', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.25.mlp.down_proj.SCB', 'model.layers.25.mlp.down_proj.weight_format', 'model.layers.25.mlp.gate_proj.SCB', 'model.layers.25.mlp.gate_proj.weight_format', 'model.layers.25.mlp.up_proj.SCB', 'model.layers.25.mlp.up_proj.weight_format', 'model.layers.25.self_attn.k_proj.SCB', 'model.layers.25.self_attn.k_proj.weight_format', 'model.layers.25.self_attn.o_proj.SCB', 'model.layers.25.self_attn.o_proj.weight_format', 'model.layers.25.self_attn.q_proj.base_layer.SCB', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight_format', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.SCB', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight_format', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.mlp.down_proj.SCB', 'model.layers.26.mlp.down_proj.weight_format', 'model.layers.26.mlp.gate_proj.SCB', 'model.layers.26.mlp.gate_proj.weight_format', 'model.layers.26.mlp.up_proj.SCB', 'model.layers.26.mlp.up_proj.weight_format', 'model.layers.26.self_attn.k_proj.SCB', 'model.layers.26.self_attn.k_proj.weight_format', 'model.layers.26.self_attn.o_proj.SCB', 'model.layers.26.self_attn.o_proj.weight_format', 'model.layers.26.self_attn.q_proj.base_layer.SCB', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight_format', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.SCB', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight_format', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.mlp.down_proj.SCB', 'model.layers.27.mlp.down_proj.weight_format', 'model.layers.27.mlp.gate_proj.SCB', 'model.layers.27.mlp.gate_proj.weight_format', 'model.layers.27.mlp.up_proj.SCB', 'model.layers.27.mlp.up_proj.weight_format', 'model.layers.27.self_attn.k_proj.SCB', 'model.layers.27.self_attn.k_proj.weight_format', 'model.layers.27.self_attn.o_proj.SCB', 'model.layers.27.self_attn.o_proj.weight_format', 'model.layers.27.self_attn.q_proj.base_layer.SCB', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight_format', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.SCB', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight_format', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.cross_attn.k_proj.SCB', 'model.layers.28.cross_attn.k_proj.weight_format', 'model.layers.28.cross_attn.o_proj.SCB', 'model.layers.28.cross_attn.o_proj.weight_format', 'model.layers.28.cross_attn.q_proj.base_layer.SCB', 'model.layers.28.cross_attn.q_proj.base_layer.weight', 'model.layers.28.cross_attn.q_proj.base_layer.weight_format', 'model.layers.28.cross_attn.q_proj.lora_A.default.weight', 'model.layers.28.cross_attn.q_proj.lora_B.default.weight', 'model.layers.28.cross_attn.v_proj.base_layer.SCB', 'model.layers.28.cross_attn.v_proj.base_layer.weight', 'model.layers.28.cross_attn.v_proj.base_layer.weight_format', 'model.layers.28.cross_attn.v_proj.lora_A.default.weight', 'model.layers.28.cross_attn.v_proj.lora_B.default.weight', 'model.layers.28.mlp.down_proj.SCB', 'model.layers.28.mlp.down_proj.weight_format', 'model.layers.28.mlp.gate_proj.SCB', 'model.layers.28.mlp.gate_proj.weight_format', 'model.layers.28.mlp.up_proj.SCB', 'model.layers.28.mlp.up_proj.weight_format', 'model.layers.29.mlp.down_proj.SCB', 'model.layers.29.mlp.down_proj.weight_format', 'model.layers.29.mlp.gate_proj.SCB', 'model.layers.29.mlp.gate_proj.weight_format', 'model.layers.29.mlp.up_proj.SCB', 'model.layers.29.mlp.up_proj.weight_format', 'model.layers.29.self_attn.k_proj.SCB', 'model.layers.29.self_attn.k_proj.weight_format', 'model.layers.29.self_attn.o_proj.SCB', 'model.layers.29.self_attn.o_proj.weight_format', 'model.layers.29.self_attn.q_proj.base_layer.SCB', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight_format', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.29.self_attn.v_proj.base_layer.SCB', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight_format', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.3.cross_attn.k_proj.SCB', 'model.layers.3.cross_attn.k_proj.weight_format', 'model.layers.3.cross_attn.o_proj.SCB', 'model.layers.3.cross_attn.o_proj.weight_format', 'model.layers.3.cross_attn.q_proj.base_layer.SCB', 'model.layers.3.cross_attn.q_proj.base_layer.weight', 'model.layers.3.cross_attn.q_proj.base_layer.weight_format', 'model.layers.3.cross_attn.q_proj.lora_A.default.weight', 'model.layers.3.cross_attn.q_proj.lora_B.default.weight', 'model.layers.3.cross_attn.v_proj.base_layer.SCB', 'model.layers.3.cross_attn.v_proj.base_layer.weight', 'model.layers.3.cross_attn.v_proj.base_layer.weight_format', 'model.layers.3.cross_attn.v_proj.lora_A.default.weight', 'model.layers.3.cross_attn.v_proj.lora_B.default.weight', 'model.layers.3.mlp.down_proj.SCB', 'model.layers.3.mlp.down_proj.weight_format', 'model.layers.3.mlp.gate_proj.SCB', 'model.layers.3.mlp.gate_proj.weight_format', 'model.layers.3.mlp.up_proj.SCB', 'model.layers.3.mlp.up_proj.weight_format', 'model.layers.30.mlp.down_proj.SCB', 'model.layers.30.mlp.down_proj.weight_format', 'model.layers.30.mlp.gate_proj.SCB', 'model.layers.30.mlp.gate_proj.weight_format', 'model.layers.30.mlp.up_proj.SCB', 'model.layers.30.mlp.up_proj.weight_format', 'model.layers.30.self_attn.k_proj.SCB', 'model.layers.30.self_attn.k_proj.weight_format', 'model.layers.30.self_attn.o_proj.SCB', 'model.layers.30.self_attn.o_proj.weight_format', 'model.layers.30.self_attn.q_proj.base_layer.SCB', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight_format', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.v_proj.base_layer.SCB', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight_format', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.mlp.down_proj.SCB', 'model.layers.31.mlp.down_proj.weight_format', 'model.layers.31.mlp.gate_proj.SCB', 'model.layers.31.mlp.gate_proj.weight_format', 'model.layers.31.mlp.up_proj.SCB', 'model.layers.31.mlp.up_proj.weight_format', 'model.layers.31.self_attn.k_proj.SCB', 'model.layers.31.self_attn.k_proj.weight_format', 'model.layers.31.self_attn.o_proj.SCB', 'model.layers.31.self_attn.o_proj.weight_format', 'model.layers.31.self_attn.q_proj.base_layer.SCB', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight_format', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.SCB', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight_format', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.32.mlp.down_proj.SCB', 'model.layers.32.mlp.down_proj.weight_format', 'model.layers.32.mlp.gate_proj.SCB', 'model.layers.32.mlp.gate_proj.weight_format', 'model.layers.32.mlp.up_proj.SCB', 'model.layers.32.mlp.up_proj.weight_format', 'model.layers.32.self_attn.k_proj.SCB', 'model.layers.32.self_attn.k_proj.weight_format', 'model.layers.32.self_attn.o_proj.SCB', 'model.layers.32.self_attn.o_proj.weight_format', 'model.layers.32.self_attn.q_proj.base_layer.SCB', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight_format', 'model.layers.32.self_attn.q_proj.lora_A.default.weight', 'model.layers.32.self_attn.q_proj.lora_B.default.weight', 'model.layers.32.self_attn.v_proj.base_layer.SCB', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.base_layer.weight_format', 'model.layers.32.self_attn.v_proj.lora_A.default.weight', 'model.layers.32.self_attn.v_proj.lora_B.default.weight', 'model.layers.33.cross_attn.k_proj.SCB', 'model.layers.33.cross_attn.k_proj.weight_format', 'model.layers.33.cross_attn.o_proj.SCB', 'model.layers.33.cross_attn.o_proj.weight_format', 'model.layers.33.cross_attn.q_proj.base_layer.SCB', 'model.layers.33.cross_attn.q_proj.base_layer.weight', 'model.layers.33.cross_attn.q_proj.base_layer.weight_format', 'model.layers.33.cross_attn.q_proj.lora_A.default.weight', 'model.layers.33.cross_attn.q_proj.lora_B.default.weight', 'model.layers.33.cross_attn.v_proj.base_layer.SCB', 'model.layers.33.cross_attn.v_proj.base_layer.weight', 'model.layers.33.cross_attn.v_proj.base_layer.weight_format', 'model.layers.33.cross_attn.v_proj.lora_A.default.weight', 'model.layers.33.cross_attn.v_proj.lora_B.default.weight', 'model.layers.33.mlp.down_proj.SCB', 'model.layers.33.mlp.down_proj.weight_format', 'model.layers.33.mlp.gate_proj.SCB', 'model.layers.33.mlp.gate_proj.weight_format', 'model.layers.33.mlp.up_proj.SCB', 'model.layers.33.mlp.up_proj.weight_format', 'model.layers.34.mlp.down_proj.SCB', 'model.layers.34.mlp.down_proj.weight_format', 'model.layers.34.mlp.gate_proj.SCB', 'model.layers.34.mlp.gate_proj.weight_format', 'model.layers.34.mlp.up_proj.SCB', 'model.layers.34.mlp.up_proj.weight_format', 'model.layers.34.self_attn.k_proj.SCB', 'model.layers.34.self_attn.k_proj.weight_format', 'model.layers.34.self_attn.o_proj.SCB', 'model.layers.34.self_attn.o_proj.weight_format', 'model.layers.34.self_attn.q_proj.base_layer.SCB', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight_format', 'model.layers.34.self_attn.q_proj.lora_A.default.weight', 'model.layers.34.self_attn.q_proj.lora_B.default.weight', 'model.layers.34.self_attn.v_proj.base_layer.SCB', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.base_layer.weight_format', 'model.layers.34.self_attn.v_proj.lora_A.default.weight', 'model.layers.34.self_attn.v_proj.lora_B.default.weight', 'model.layers.35.mlp.down_proj.SCB', 'model.layers.35.mlp.down_proj.weight_format', 'model.layers.35.mlp.gate_proj.SCB', 'model.layers.35.mlp.gate_proj.weight_format', 'model.layers.35.mlp.up_proj.SCB', 'model.layers.35.mlp.up_proj.weight_format', 'model.layers.35.self_attn.k_proj.SCB', 'model.layers.35.self_attn.k_proj.weight_format', 'model.layers.35.self_attn.o_proj.SCB', 'model.layers.35.self_attn.o_proj.weight_format', 'model.layers.35.self_attn.q_proj.base_layer.SCB', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight_format', 'model.layers.35.self_attn.q_proj.lora_A.default.weight', 'model.layers.35.self_attn.q_proj.lora_B.default.weight', 'model.layers.35.self_attn.v_proj.base_layer.SCB', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.base_layer.weight_format', 'model.layers.35.self_attn.v_proj.lora_A.default.weight', 'model.layers.35.self_attn.v_proj.lora_B.default.weight', 'model.layers.36.mlp.down_proj.SCB', 'model.layers.36.mlp.down_proj.weight_format', 'model.layers.36.mlp.gate_proj.SCB', 'model.layers.36.mlp.gate_proj.weight_format', 'model.layers.36.mlp.up_proj.SCB', 'model.layers.36.mlp.up_proj.weight_format', 'model.layers.36.self_attn.k_proj.SCB', 'model.layers.36.self_attn.k_proj.weight_format', 'model.layers.36.self_attn.o_proj.SCB', 'model.layers.36.self_attn.o_proj.weight_format', 'model.layers.36.self_attn.q_proj.base_layer.SCB', 'model.layers.36.self_attn.q_proj.base_layer.weight', 'model.layers.36.self_attn.q_proj.base_layer.weight_format', 'model.layers.36.self_attn.q_proj.lora_A.default.weight', 'model.layers.36.self_attn.q_proj.lora_B.default.weight', 'model.layers.36.self_attn.v_proj.base_layer.SCB', 'model.layers.36.self_attn.v_proj.base_layer.weight', 'model.layers.36.self_attn.v_proj.base_layer.weight_format', 'model.layers.36.self_attn.v_proj.lora_A.default.weight', 'model.layers.36.self_attn.v_proj.lora_B.default.weight', 'model.layers.37.mlp.down_proj.SCB', 'model.layers.37.mlp.down_proj.weight_format', 'model.layers.37.mlp.gate_proj.SCB', 'model.layers.37.mlp.gate_proj.weight_format', 'model.layers.37.mlp.up_proj.SCB', 'model.layers.37.mlp.up_proj.weight_format', 'model.layers.37.self_attn.k_proj.SCB', 'model.layers.37.self_attn.k_proj.weight_format', 'model.layers.37.self_attn.o_proj.SCB', 'model.layers.37.self_attn.o_proj.weight_format', 'model.layers.37.self_attn.q_proj.base_layer.SCB', 'model.layers.37.self_attn.q_proj.base_layer.weight', 'model.layers.37.self_attn.q_proj.base_layer.weight_format', 'model.layers.37.self_attn.q_proj.lora_A.default.weight', 'model.layers.37.self_attn.q_proj.lora_B.default.weight', 'model.layers.37.self_attn.v_proj.base_layer.SCB', 'model.layers.37.self_attn.v_proj.base_layer.weight', 'model.layers.37.self_attn.v_proj.base_layer.weight_format', 'model.layers.37.self_attn.v_proj.lora_A.default.weight', 'model.layers.37.self_attn.v_proj.lora_B.default.weight', 'model.layers.38.cross_attn.k_proj.SCB', 'model.layers.38.cross_attn.k_proj.weight_format', 'model.layers.38.cross_attn.o_proj.SCB', 'model.layers.38.cross_attn.o_proj.weight_format', 'model.layers.38.cross_attn.q_proj.base_layer.SCB', 'model.layers.38.cross_attn.q_proj.base_layer.weight', 'model.layers.38.cross_attn.q_proj.base_layer.weight_format', 'model.layers.38.cross_attn.q_proj.lora_A.default.weight', 'model.layers.38.cross_attn.q_proj.lora_B.default.weight', 'model.layers.38.cross_attn.v_proj.base_layer.SCB', 'model.layers.38.cross_attn.v_proj.base_layer.weight', 'model.layers.38.cross_attn.v_proj.base_layer.weight_format', 'model.layers.38.cross_attn.v_proj.lora_A.default.weight', 'model.layers.38.cross_attn.v_proj.lora_B.default.weight', 'model.layers.38.mlp.down_proj.SCB', 'model.layers.38.mlp.down_proj.weight_format', 'model.layers.38.mlp.gate_proj.SCB', 'model.layers.38.mlp.gate_proj.weight_format', 'model.layers.38.mlp.up_proj.SCB', 'model.layers.38.mlp.up_proj.weight_format', 'model.layers.39.mlp.down_proj.SCB', 'model.layers.39.mlp.down_proj.weight_format', 'model.layers.39.mlp.gate_proj.SCB', 'model.layers.39.mlp.gate_proj.weight_format', 'model.layers.39.mlp.up_proj.SCB', 'model.layers.39.mlp.up_proj.weight_format', 'model.layers.39.self_attn.k_proj.SCB', 'model.layers.39.self_attn.k_proj.weight_format', 'model.layers.39.self_attn.o_proj.SCB', 'model.layers.39.self_attn.o_proj.weight_format', 'model.layers.39.self_attn.q_proj.base_layer.SCB', 'model.layers.39.self_attn.q_proj.base_layer.weight', 'model.layers.39.self_attn.q_proj.base_layer.weight_format', 'model.layers.39.self_attn.q_proj.lora_A.default.weight', 'model.layers.39.self_attn.q_proj.lora_B.default.weight', 'model.layers.39.self_attn.v_proj.base_layer.SCB', 'model.layers.39.self_attn.v_proj.base_layer.weight', 'model.layers.39.self_attn.v_proj.base_layer.weight_format', 'model.layers.39.self_attn.v_proj.lora_A.default.weight', 'model.layers.39.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.mlp.down_proj.SCB', 'model.layers.4.mlp.down_proj.weight_format', 'model.layers.4.mlp.gate_proj.SCB', 'model.layers.4.mlp.gate_proj.weight_format', 'model.layers.4.mlp.up_proj.SCB', 'model.layers.4.mlp.up_proj.weight_format', 'model.layers.4.self_attn.k_proj.SCB', 'model.layers.4.self_attn.k_proj.weight_format', 'model.layers.4.self_attn.o_proj.SCB', 'model.layers.4.self_attn.o_proj.weight_format', 'model.layers.4.self_attn.q_proj.base_layer.SCB', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight_format', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.SCB', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight_format', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.5.mlp.down_proj.SCB', 'model.layers.5.mlp.down_proj.weight_format', 'model.layers.5.mlp.gate_proj.SCB', 'model.layers.5.mlp.gate_proj.weight_format', 'model.layers.5.mlp.up_proj.SCB', 'model.layers.5.mlp.up_proj.weight_format', 'model.layers.5.self_attn.k_proj.SCB', 'model.layers.5.self_attn.k_proj.weight_format', 'model.layers.5.self_attn.o_proj.SCB', 'model.layers.5.self_attn.o_proj.weight_format', 'model.layers.5.self_attn.q_proj.base_layer.SCB', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight_format', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.SCB', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight_format', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.mlp.down_proj.SCB', 'model.layers.6.mlp.down_proj.weight_format', 'model.layers.6.mlp.gate_proj.SCB', 'model.layers.6.mlp.gate_proj.weight_format', 'model.layers.6.mlp.up_proj.SCB', 'model.layers.6.mlp.up_proj.weight_format', 'model.layers.6.self_attn.k_proj.SCB', 'model.layers.6.self_attn.k_proj.weight_format', 'model.layers.6.self_attn.o_proj.SCB', 'model.layers.6.self_attn.o_proj.weight_format', 'model.layers.6.self_attn.q_proj.base_layer.SCB', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight_format', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.SCB', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight_format', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.mlp.down_proj.SCB', 'model.layers.7.mlp.down_proj.weight_format', 'model.layers.7.mlp.gate_proj.SCB', 'model.layers.7.mlp.gate_proj.weight_format', 'model.layers.7.mlp.up_proj.SCB', 'model.layers.7.mlp.up_proj.weight_format', 'model.layers.7.self_attn.k_proj.SCB', 'model.layers.7.self_attn.k_proj.weight_format', 'model.layers.7.self_attn.o_proj.SCB', 'model.layers.7.self_attn.o_proj.weight_format', 'model.layers.7.self_attn.q_proj.base_layer.SCB', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight_format', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.SCB', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight_format', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.8.cross_attn.k_proj.SCB', 'model.layers.8.cross_attn.k_proj.weight_format', 'model.layers.8.cross_attn.o_proj.SCB', 'model.layers.8.cross_attn.o_proj.weight_format', 'model.layers.8.cross_attn.q_proj.base_layer.SCB', 'model.layers.8.cross_attn.q_proj.base_layer.weight', 'model.layers.8.cross_attn.q_proj.base_layer.weight_format', 'model.layers.8.cross_attn.q_proj.lora_A.default.weight', 'model.layers.8.cross_attn.q_proj.lora_B.default.weight', 'model.layers.8.cross_attn.v_proj.base_layer.SCB', 'model.layers.8.cross_attn.v_proj.base_layer.weight', 'model.layers.8.cross_attn.v_proj.base_layer.weight_format', 'model.layers.8.cross_attn.v_proj.lora_A.default.weight', 'model.layers.8.cross_attn.v_proj.lora_B.default.weight', 'model.layers.8.mlp.down_proj.SCB', 'model.layers.8.mlp.down_proj.weight_format', 'model.layers.8.mlp.gate_proj.SCB', 'model.layers.8.mlp.gate_proj.weight_format', 'model.layers.8.mlp.up_proj.SCB', 'model.layers.8.mlp.up_proj.weight_format', 'model.layers.9.mlp.down_proj.SCB', 'model.layers.9.mlp.down_proj.weight_format', 'model.layers.9.mlp.gate_proj.SCB', 'model.layers.9.mlp.gate_proj.weight_format', 'model.layers.9.mlp.up_proj.SCB', 'model.layers.9.mlp.up_proj.weight_format', 'model.layers.9.self_attn.k_proj.SCB', 'model.layers.9.self_attn.k_proj.weight_format', 'model.layers.9.self_attn.o_proj.SCB', 'model.layers.9.self_attn.o_proj.weight_format', 'model.layers.9.self_attn.q_proj.base_layer.SCB', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight_format', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.SCB', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight_format', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight']
- This IS expected if you are initializing MllamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MllamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of MllamaForCausalLM were not initialized from the model checkpoint at /home/oe2015/final_model_checkpoint_512_quant and are newly initialized: ['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.cross_attn.q_proj.weight', 'model.layers.13.cross_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.cross_attn.q_proj.weight', 'model.layers.18.cross_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.cross_attn.q_proj.weight', 'model.layers.23.cross_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.cross_attn.q_proj.weight', 'model.layers.28.cross_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.cross_attn.q_proj.weight', 'model.layers.3.cross_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.cross_attn.q_proj.weight', 'model.layers.33.cross_attn.v_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.cross_attn.q_proj.weight', 'model.layers.38.cross_attn.v_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.cross_attn.q_proj.weight', 'model.layers.8.cross_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/mapping.py:172: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from '/home/oe2015/final_model_checkpoint_512_quant' to 'mylesgoose/Llama-3.2-11B-Vision-Instruct'. Please ensure that the correct base model is loaded when loading this checkpoint.
  warnings.warn(
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)  # noqa: B028
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_B.default.weight matches: True
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.cross_attn_attn_gate False
base_model.model.model.layers.3.cross_attn_mlp_gate False
base_model.model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.cross_attn_attn_gate False
base_model.model.model.layers.8.cross_attn_mlp_gate False
base_model.model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.cross_attn_attn_gate False
base_model.model.model.layers.13.cross_attn_mlp_gate False
base_model.model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.cross_attn_attn_gate False
base_model.model.model.layers.18.cross_attn_mlp_gate False
base_model.model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.cross_attn_attn_gate False
base_model.model.model.layers.23.cross_attn_mlp_gate False
base_model.model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.cross_attn_attn_gate False
base_model.model.model.layers.28.cross_attn_mlp_gate False
base_model.model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.k_proj.weight False
base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.o_proj.weight False
base_model.model.model.layers.32.mlp.gate_proj.weight False
base_model.model.model.layers.32.mlp.up_proj.weight False
base_model.model.model.layers.32.mlp.down_proj.weight False
base_model.model.model.layers.32.input_layernorm.weight False
base_model.model.model.layers.32.post_attention_layernorm.weight False
base_model.model.model.layers.33.cross_attn_attn_gate False
base_model.model.model.layers.33.cross_attn_mlp_gate False
base_model.model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.model.layers.33.input_layernorm.weight False
base_model.model.model.layers.33.mlp.gate_proj.weight False
base_model.model.model.layers.33.mlp.up_proj.weight False
base_model.model.model.layers.33.mlp.down_proj.weight False
base_model.model.model.layers.33.post_attention_layernorm.weight False
base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.k_proj.weight False
base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.o_proj.weight False
base_model.model.model.layers.34.mlp.gate_proj.weight False
base_model.model.model.layers.34.mlp.up_proj.weight False
base_model.model.model.layers.34.mlp.down_proj.weight False
base_model.model.model.layers.34.input_layernorm.weight False
base_model.model.model.layers.34.post_attention_layernorm.weight False
base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.k_proj.weight False
base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.o_proj.weight False
base_model.model.model.layers.35.mlp.gate_proj.weight False
base_model.model.model.layers.35.mlp.up_proj.weight False
base_model.model.model.layers.35.mlp.down_proj.weight False
base_model.model.model.layers.35.input_layernorm.weight False
base_model.model.model.layers.35.post_attention_layernorm.weight False
base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.k_proj.weight False
base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.o_proj.weight False
base_model.model.model.layers.36.mlp.gate_proj.weight False
base_model.model.model.layers.36.mlp.up_proj.weight False
base_model.model.model.layers.36.mlp.down_proj.weight False
base_model.model.model.layers.36.input_layernorm.weight False
base_model.model.model.layers.36.post_attention_layernorm.weight False
base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.k_proj.weight False
base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.o_proj.weight False
base_model.model.model.layers.37.mlp.gate_proj.weight False
base_model.model.model.layers.37.mlp.up_proj.weight False
base_model.model.model.layers.37.mlp.down_proj.weight False
base_model.model.model.layers.37.input_layernorm.weight False
base_model.model.model.layers.37.post_attention_layernorm.weight False
base_model.model.model.layers.38.cross_attn_attn_gate False
base_model.model.model.layers.38.cross_attn_mlp_gate False
base_model.model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.model.layers.38.input_layernorm.weight False
base_model.model.model.layers.38.mlp.gate_proj.weight False
base_model.model.model.layers.38.mlp.up_proj.weight False
base_model.model.model.layers.38.mlp.down_proj.weight False
base_model.model.model.layers.38.post_attention_layernorm.weight False
base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.k_proj.weight False
base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.o_proj.weight False
base_model.model.model.layers.39.mlp.gate_proj.weight False
base_model.model.model.layers.39.mlp.up_proj.weight False
base_model.model.model.layers.39.mlp.down_proj.weight False
base_model.model.model.layers.39.input_layernorm.weight False
base_model.model.model.layers.39.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.lm_head.weight False
base_model.model.vision_model.class_embedding False
base_model.model.vision_model.patch_embedding.weight False
base_model.model.vision_model.gated_positional_embedding.gate False
base_model.model.vision_model.gated_positional_embedding.embedding False
base_model.model.vision_model.gated_positional_embedding.tile_embedding.weight False
base_model.model.vision_model.pre_tile_positional_embedding.gate False
base_model.model.vision_model.pre_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.post_tile_positional_embedding.gate False
base_model.model.vision_model.post_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.layernorm_pre.weight False
base_model.model.vision_model.layernorm_pre.bias False
base_model.model.vision_model.layernorm_post.weight False
base_model.model.vision_model.layernorm_post.bias False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.8.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.9.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.10.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.11.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.12.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.13.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.14.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.15.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.16.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.17.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.18.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.19.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.20.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.21.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.22.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.23.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.24.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.25.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.26.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.27.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.28.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.29.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.30.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.31.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.gate_attn False
base_model.model.vision_model.global_transformer.layers.0.gate_ffn False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.gate_attn False
base_model.model.vision_model.global_transformer.layers.1.gate_ffn False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.gate_attn False
base_model.model.vision_model.global_transformer.layers.2.gate_ffn False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.gate_attn False
base_model.model.vision_model.global_transformer.layers.3.gate_ffn False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.gate_attn False
base_model.model.vision_model.global_transformer.layers.4.gate_ffn False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.gate_attn False
base_model.model.vision_model.global_transformer.layers.5.gate_ffn False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.gate_attn False
base_model.model.vision_model.global_transformer.layers.6.gate_ffn False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.gate_attn False
base_model.model.vision_model.global_transformer.layers.7.gate_ffn False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.bias False
base_model.model.language_model.model.embed_tokens.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.0.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.0.mlp.up_proj.weight False
base_model.model.language_model.model.layers.0.mlp.down_proj.weight False
base_model.model.language_model.model.layers.0.input_layernorm.weight False
base_model.model.language_model.model.layers.0.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.1.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.1.mlp.up_proj.weight False
base_model.model.language_model.model.layers.1.mlp.down_proj.weight False
base_model.model.language_model.model.layers.1.input_layernorm.weight False
base_model.model.language_model.model.layers.1.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.2.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.2.mlp.up_proj.weight False
base_model.model.language_model.model.layers.2.mlp.down_proj.weight False
base_model.model.language_model.model.layers.2.input_layernorm.weight False
base_model.model.language_model.model.layers.2.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.3.cross_attn_attn_gate False
base_model.model.language_model.model.layers.3.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.3.input_layernorm.weight False
base_model.model.language_model.model.layers.3.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.3.mlp.up_proj.weight False
base_model.model.language_model.model.layers.3.mlp.down_proj.weight False
base_model.model.language_model.model.layers.3.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.4.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.4.mlp.up_proj.weight False
base_model.model.language_model.model.layers.4.mlp.down_proj.weight False
base_model.model.language_model.model.layers.4.input_layernorm.weight False
base_model.model.language_model.model.layers.4.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.5.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.5.mlp.up_proj.weight False
base_model.model.language_model.model.layers.5.mlp.down_proj.weight False
base_model.model.language_model.model.layers.5.input_layernorm.weight False
base_model.model.language_model.model.layers.5.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.6.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.6.mlp.up_proj.weight False
base_model.model.language_model.model.layers.6.mlp.down_proj.weight False
base_model.model.language_model.model.layers.6.input_layernorm.weight False
base_model.model.language_model.model.layers.6.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.7.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.7.mlp.up_proj.weight False
base_model.model.language_model.model.layers.7.mlp.down_proj.weight False
base_model.model.language_model.model.layers.7.input_layernorm.weight False
base_model.model.language_model.model.layers.7.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.8.cross_attn_attn_gate False
base_model.model.language_model.model.layers.8.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.8.input_layernorm.weight False
base_model.model.language_model.model.layers.8.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.8.mlp.up_proj.weight False
base_model.model.language_model.model.layers.8.mlp.down_proj.weight False
base_model.model.language_model.model.layers.8.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.9.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.9.mlp.up_proj.weight False
base_model.model.language_model.model.layers.9.mlp.down_proj.weight False
base_model.model.language_model.model.layers.9.input_layernorm.weight False
base_model.model.language_model.model.layers.9.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.10.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.10.mlp.up_proj.weight False
base_model.model.language_model.model.layers.10.mlp.down_proj.weight False
base_model.model.language_model.model.layers.10.input_layernorm.weight False
base_model.model.language_model.model.layers.10.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.11.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.11.mlp.up_proj.weight False
base_model.model.language_model.model.layers.11.mlp.down_proj.weight False
base_model.model.language_model.model.layers.11.input_layernorm.weight False
base_model.model.language_model.model.layers.11.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.12.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.12.mlp.up_proj.weight False
base_model.model.language_model.model.layers.12.mlp.down_proj.weight False
base_model.model.language_model.model.layers.12.input_layernorm.weight False
base_model.model.language_model.model.layers.12.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.13.cross_attn_attn_gate False
base_model.model.language_model.model.layers.13.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.13.input_layernorm.weight False
base_model.model.language_model.model.layers.13.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.13.mlp.up_proj.weight False
base_model.model.language_model.model.layers.13.mlp.down_proj.weight False
base_model.model.language_model.model.layers.13.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.14.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.14.mlp.up_proj.weight False
base_model.model.language_model.model.layers.14.mlp.down_proj.weight False
base_model.model.language_model.model.layers.14.input_layernorm.weight False
base_model.model.language_model.model.layers.14.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.15.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.15.mlp.up_proj.weight False
base_model.model.language_model.model.layers.15.mlp.down_proj.weight False
base_model.model.language_model.model.layers.15.input_layernorm.weight False
base_model.model.language_model.model.layers.15.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.16.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.16.mlp.up_proj.weight False
base_model.model.language_model.model.layers.16.mlp.down_proj.weight False
base_model.model.language_model.model.layers.16.input_layernorm.weight False
base_model.model.language_model.model.layers.16.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.17.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.17.mlp.up_proj.weight False
base_model.model.language_model.model.layers.17.mlp.down_proj.weight False
base_model.model.language_model.model.layers.17.input_layernorm.weight False
base_model.model.language_model.model.layers.17.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.18.cross_attn_attn_gate False
base_model.model.language_model.model.layers.18.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.18.input_layernorm.weight False
base_model.model.language_model.model.layers.18.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.18.mlp.up_proj.weight False
base_model.model.language_model.model.layers.18.mlp.down_proj.weight False
base_model.model.language_model.model.layers.18.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.19.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.19.mlp.up_proj.weight False
base_model.model.language_model.model.layers.19.mlp.down_proj.weight False
base_model.model.language_model.model.layers.19.input_layernorm.weight False
base_model.model.language_model.model.layers.19.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.20.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.20.mlp.up_proj.weight False
base_model.model.language_model.model.layers.20.mlp.down_proj.weight False
base_model.model.language_model.model.layers.20.input_layernorm.weight False
base_model.model.language_model.model.layers.20.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.21.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.21.mlp.up_proj.weight False
base_model.model.language_model.model.layers.21.mlp.down_proj.weight False
base_model.model.language_model.model.layers.21.input_layernorm.weight False
base_model.model.language_model.model.layers.21.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.22.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.22.mlp.up_proj.weight False
base_model.model.language_model.model.layers.22.mlp.down_proj.weight False
base_model.model.language_model.model.layers.22.input_layernorm.weight False
base_model.model.language_model.model.layers.22.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.23.cross_attn_attn_gate False
base_model.model.language_model.model.layers.23.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.23.input_layernorm.weight False
base_model.model.language_model.model.layers.23.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.23.mlp.up_proj.weight False
base_model.model.language_model.model.layers.23.mlp.down_proj.weight False
base_model.model.language_model.model.layers.23.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.24.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.24.mlp.up_proj.weight False
base_model.model.language_model.model.layers.24.mlp.down_proj.weight False
base_model.model.language_model.model.layers.24.input_layernorm.weight False
base_model.model.language_model.model.layers.24.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.25.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.25.mlp.up_proj.weight False
base_model.model.language_model.model.layers.25.mlp.down_proj.weight False
base_model.model.language_model.model.layers.25.input_layernorm.weight False
base_model.model.language_model.model.layers.25.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.26.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.26.mlp.up_proj.weight False
base_model.model.language_model.model.layers.26.mlp.down_proj.weight False
base_model.model.language_model.model.layers.26.input_layernorm.weight False
base_model.model.language_model.model.layers.26.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.27.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.27.mlp.up_proj.weight False
base_model.model.language_model.model.layers.27.mlp.down_proj.weight False
base_model.model.language_model.model.layers.27.input_layernorm.weight False
base_model.model.language_model.model.layers.27.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.28.cross_attn_attn_gate False
base_model.model.language_model.model.layers.28.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.28.input_layernorm.weight False
base_model.model.language_model.model.layers.28.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.28.mlp.up_proj.weight False
base_model.model.language_model.model.layers.28.mlp.down_proj.weight False
base_model.model.language_model.model.layers.28.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.29.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.29.mlp.up_proj.weight False
base_model.model.language_model.model.layers.29.mlp.down_proj.weight False
base_model.model.language_model.model.layers.29.input_layernorm.weight False
base_model.model.language_model.model.layers.29.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.30.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.30.mlp.up_proj.weight False
base_model.model.language_model.model.layers.30.mlp.down_proj.weight False
base_model.model.language_model.model.layers.30.input_layernorm.weight False
base_model.model.language_model.model.layers.30.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.31.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.31.mlp.up_proj.weight False
base_model.model.language_model.model.layers.31.mlp.down_proj.weight False
base_model.model.language_model.model.layers.31.input_layernorm.weight False
base_model.model.language_model.model.layers.31.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.32.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.32.mlp.up_proj.weight False
base_model.model.language_model.model.layers.32.mlp.down_proj.weight False
base_model.model.language_model.model.layers.32.input_layernorm.weight False
base_model.model.language_model.model.layers.32.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.33.cross_attn_attn_gate False
base_model.model.language_model.model.layers.33.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.33.input_layernorm.weight False
base_model.model.language_model.model.layers.33.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.33.mlp.up_proj.weight False
base_model.model.language_model.model.layers.33.mlp.down_proj.weight False
base_model.model.language_model.model.layers.33.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.34.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.34.mlp.up_proj.weight False
base_model.model.language_model.model.layers.34.mlp.down_proj.weight False
base_model.model.language_model.model.layers.34.input_layernorm.weight False
base_model.model.language_model.model.layers.34.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.35.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.35.mlp.up_proj.weight False
base_model.model.language_model.model.layers.35.mlp.down_proj.weight False
base_model.model.language_model.model.layers.35.input_layernorm.weight False
base_model.model.language_model.model.layers.35.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.36.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.36.mlp.up_proj.weight False
base_model.model.language_model.model.layers.36.mlp.down_proj.weight False
base_model.model.language_model.model.layers.36.input_layernorm.weight False
base_model.model.language_model.model.layers.36.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.37.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.37.mlp.up_proj.weight False
base_model.model.language_model.model.layers.37.mlp.down_proj.weight False
base_model.model.language_model.model.layers.37.input_layernorm.weight False
base_model.model.language_model.model.layers.37.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.38.cross_attn_attn_gate False
base_model.model.language_model.model.layers.38.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.38.input_layernorm.weight False
base_model.model.language_model.model.layers.38.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.38.mlp.up_proj.weight False
base_model.model.language_model.model.layers.38.mlp.down_proj.weight False
base_model.model.language_model.model.layers.38.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.39.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.39.mlp.up_proj.weight False
base_model.model.language_model.model.layers.39.mlp.down_proj.weight False
base_model.model.language_model.model.layers.39.input_layernorm.weight False
base_model.model.language_model.model.layers.39.post_attention_layernorm.weight False
base_model.model.language_model.model.norm.weight False
base_model.model.language_model.lm_head.weight False
base_model.model.multi_modal_projector.weight False
base_model.model.multi_modal_projector.bias False
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_B.default.weight matches: True
MISMATCH: model.layers.0.self_attn.q_proj.lora_A.default.weight
Difference: 0.48423606157302856
MISMATCH: model.layers.0.self_attn.q_proj.lora_B.default.weight
Difference: 0.04695240408182144
MISMATCH: model.layers.0.self_attn.v_proj.lora_A.default.weight
Difference: 1.6696062088012695
MISMATCH: model.layers.0.self_attn.v_proj.lora_B.default.weight
Difference: 0.023460516706109047
MISMATCH: model.layers.1.self_attn.q_proj.lora_A.default.weight
Difference: 0.07364079356193542
MISMATCH: model.layers.1.self_attn.q_proj.lora_B.default.weight
Difference: 0.028232689946889877
MISMATCH: model.layers.1.self_attn.v_proj.lora_A.default.weight
Difference: 0.2828364968299866
MISMATCH: model.layers.1.self_attn.v_proj.lora_B.default.weight
Difference: 0.022568367421627045
MISMATCH: model.layers.2.self_attn.q_proj.lora_A.default.weight
Difference: 0.048734553158283234
MISMATCH: model.layers.2.self_attn.q_proj.lora_B.default.weight
Difference: 0.028164591640233994
MISMATCH: model.layers.2.self_attn.v_proj.lora_A.default.weight
Difference: 0.0636448860168457
MISMATCH: model.layers.2.self_attn.v_proj.lora_B.default.weight
Difference: 0.021822841838002205
MISMATCH: model.layers.3.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03115267865359783
Matched: model.layers.3.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.3.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031200744211673737
Matched: model.layers.3.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.4.self_attn.q_proj.lora_A.default.weight
Difference: 0.04912279546260834
MISMATCH: model.layers.4.self_attn.q_proj.lora_B.default.weight
Difference: 0.03781513124704361
MISMATCH: model.layers.4.self_attn.v_proj.lora_A.default.weight
Difference: 0.06739101558923721
MISMATCH: model.layers.4.self_attn.v_proj.lora_B.default.weight
Difference: 0.022797834128141403
MISMATCH: model.layers.5.self_attn.q_proj.lora_A.default.weight
Difference: 0.050791963934898376
MISMATCH: model.layers.5.self_attn.q_proj.lora_B.default.weight
Difference: 0.029393337666988373
MISMATCH: model.layers.5.self_attn.v_proj.lora_A.default.weight
Difference: 0.057058122009038925
MISMATCH: model.layers.5.self_attn.v_proj.lora_B.default.weight
Difference: 0.020101753994822502
MISMATCH: model.layers.6.self_attn.q_proj.lora_A.default.weight
Difference: 0.050905466079711914
MISMATCH: model.layers.6.self_attn.q_proj.lora_B.default.weight
Difference: 0.027180176228284836
MISMATCH: model.layers.6.self_attn.v_proj.lora_A.default.weight
Difference: 0.057582780718803406
MISMATCH: model.layers.6.self_attn.v_proj.lora_B.default.weight
Difference: 0.021435540169477463
MISMATCH: model.layers.7.self_attn.q_proj.lora_A.default.weight
Difference: 0.0515337809920311
MISMATCH: model.layers.7.self_attn.q_proj.lora_B.default.weight
Difference: 0.03000328689813614
MISMATCH: model.layers.7.self_attn.v_proj.lora_A.default.weight
Difference: 0.058910224586725235
MISMATCH: model.layers.7.self_attn.v_proj.lora_B.default.weight
Difference: 0.022067034617066383
MISMATCH: model.layers.8.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031163938343524933
Matched: model.layers.8.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.8.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031225545331835747
Matched: model.layers.8.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.9.self_attn.q_proj.lora_A.default.weight
Difference: 0.05717063322663307
MISMATCH: model.layers.9.self_attn.q_proj.lora_B.default.weight
Difference: 0.02994222566485405
MISMATCH: model.layers.9.self_attn.v_proj.lora_A.default.weight
Difference: 0.058904122561216354
MISMATCH: model.layers.9.self_attn.v_proj.lora_B.default.weight
Difference: 0.01972036436200142
MISMATCH: model.layers.10.self_attn.q_proj.lora_A.default.weight
Difference: 0.05777905136346817
MISMATCH: model.layers.10.self_attn.q_proj.lora_B.default.weight
Difference: 0.031508881598711014
MISMATCH: model.layers.10.self_attn.v_proj.lora_A.default.weight
Difference: 0.06978277862071991
MISMATCH: model.layers.10.self_attn.v_proj.lora_B.default.weight
Difference: 0.0231583621352911
MISMATCH: model.layers.11.self_attn.q_proj.lora_A.default.weight
Difference: 0.06333817541599274
MISMATCH: model.layers.11.self_attn.q_proj.lora_B.default.weight
Difference: 0.030590632930397987
MISMATCH: model.layers.11.self_attn.v_proj.lora_A.default.weight
Difference: 0.07756568491458893
MISMATCH: model.layers.11.self_attn.v_proj.lora_B.default.weight
Difference: 0.02785596437752247
MISMATCH: model.layers.12.self_attn.q_proj.lora_A.default.weight
Difference: 0.0528276264667511
MISMATCH: model.layers.12.self_attn.q_proj.lora_B.default.weight
Difference: 0.028563421219587326
MISMATCH: model.layers.12.self_attn.v_proj.lora_A.default.weight
Difference: 0.06749282032251358
MISMATCH: model.layers.12.self_attn.v_proj.lora_B.default.weight
Difference: 0.020120324566960335
MISMATCH: model.layers.13.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03104298934340477
Matched: model.layers.13.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.13.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031097328290343285
Matched: model.layers.13.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.14.self_attn.q_proj.lora_A.default.weight
Difference: 0.06130248308181763
MISMATCH: model.layers.14.self_attn.q_proj.lora_B.default.weight
Difference: 0.03896832466125488
MISMATCH: model.layers.14.self_attn.v_proj.lora_A.default.weight
Difference: 0.07528232783079147
MISMATCH: model.layers.14.self_attn.v_proj.lora_B.default.weight
Difference: 0.019899873062968254
MISMATCH: model.layers.15.self_attn.q_proj.lora_A.default.weight
Difference: 0.05470592901110649
MISMATCH: model.layers.15.self_attn.q_proj.lora_B.default.weight
Difference: 0.03234405443072319
MISMATCH: model.layers.15.self_attn.v_proj.lora_A.default.weight
Difference: 0.06466209888458252
MISMATCH: model.layers.15.self_attn.v_proj.lora_B.default.weight
Difference: 0.021429510787129402
MISMATCH: model.layers.16.self_attn.q_proj.lora_A.default.weight
Difference: 0.05895860493183136
MISMATCH: model.layers.16.self_attn.q_proj.lora_B.default.weight
Difference: 0.03260485827922821
MISMATCH: model.layers.16.self_attn.v_proj.lora_A.default.weight
Difference: 0.06392484903335571
MISMATCH: model.layers.16.self_attn.v_proj.lora_B.default.weight
Difference: 0.022144200280308723
MISMATCH: model.layers.17.self_attn.q_proj.lora_A.default.weight
Difference: 0.05659353360533714
MISMATCH: model.layers.17.self_attn.q_proj.lora_B.default.weight
Difference: 0.03169916570186615
MISMATCH: model.layers.17.self_attn.v_proj.lora_A.default.weight
Difference: 0.07158640027046204
MISMATCH: model.layers.17.self_attn.v_proj.lora_B.default.weight
Difference: 0.029613321647047997
MISMATCH: model.layers.18.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031178994104266167
Matched: model.layers.18.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.18.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031046530231833458
Matched: model.layers.18.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.19.self_attn.q_proj.lora_A.default.weight
Difference: 0.06502518057823181
MISMATCH: model.layers.19.self_attn.q_proj.lora_B.default.weight
Difference: 0.034627579152584076
MISMATCH: model.layers.19.self_attn.v_proj.lora_A.default.weight
Difference: 0.07970882952213287
MISMATCH: model.layers.19.self_attn.v_proj.lora_B.default.weight
Difference: 0.023317307233810425
MISMATCH: model.layers.20.self_attn.q_proj.lora_A.default.weight
Difference: 0.05807150900363922
MISMATCH: model.layers.20.self_attn.q_proj.lora_B.default.weight
Difference: 0.054310742765665054
MISMATCH: model.layers.20.self_attn.v_proj.lora_A.default.weight
Difference: 0.07391867786645889
MISMATCH: model.layers.20.self_attn.v_proj.lora_B.default.weight
Difference: 0.0246605072170496
MISMATCH: model.layers.21.self_attn.q_proj.lora_A.default.weight
Difference: 0.06627940386533737
MISMATCH: model.layers.21.self_attn.q_proj.lora_B.default.weight
Difference: 0.0333738774061203
MISMATCH: model.layers.21.self_attn.v_proj.lora_A.default.weight
Difference: 0.07561594992876053
MISMATCH: model.layers.21.self_attn.v_proj.lora_B.default.weight
Difference: 0.022458020597696304
MISMATCH: model.layers.22.self_attn.q_proj.lora_A.default.weight
Difference: 0.05694996938109398
MISMATCH: model.layers.22.self_attn.q_proj.lora_B.default.weight
Difference: 0.06507500261068344
MISMATCH: model.layers.22.self_attn.v_proj.lora_A.default.weight
Difference: 0.07395912706851959
MISMATCH: model.layers.22.self_attn.v_proj.lora_B.default.weight
Difference: 0.02196865901350975
MISMATCH: model.layers.23.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031054673716425896
Matched: model.layers.23.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.23.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031150931492447853
Matched: model.layers.23.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.24.self_attn.q_proj.lora_A.default.weight
Difference: 0.05803610756993294
MISMATCH: model.layers.24.self_attn.q_proj.lora_B.default.weight
Difference: 0.039557166397571564
MISMATCH: model.layers.24.self_attn.v_proj.lora_A.default.weight
Difference: 0.07091428339481354
MISMATCH: model.layers.24.self_attn.v_proj.lora_B.default.weight
Difference: 0.019417639821767807
MISMATCH: model.layers.25.self_attn.q_proj.lora_A.default.weight
Difference: 0.06139189749956131
MISMATCH: model.layers.25.self_attn.q_proj.lora_B.default.weight
Difference: 0.04665140062570572
MISMATCH: model.layers.25.self_attn.v_proj.lora_A.default.weight
Difference: 0.07016805559396744
MISMATCH: model.layers.25.self_attn.v_proj.lora_B.default.weight
Difference: 0.021046016365289688
MISMATCH: model.layers.26.self_attn.q_proj.lora_A.default.weight
Difference: 0.07192765921354294
MISMATCH: model.layers.26.self_attn.q_proj.lora_B.default.weight
Difference: 0.07576151192188263
MISMATCH: model.layers.26.self_attn.v_proj.lora_A.default.weight
Difference: 0.07913943380117416
MISMATCH: model.layers.26.self_attn.v_proj.lora_B.default.weight
Difference: 0.023631084710359573
MISMATCH: model.layers.27.self_attn.q_proj.lora_A.default.weight
Difference: 0.06200973317027092
MISMATCH: model.layers.27.self_attn.q_proj.lora_B.default.weight
Difference: 0.051984477788209915
MISMATCH: model.layers.27.self_attn.v_proj.lora_A.default.weight
Difference: 0.09341171383857727
MISMATCH: model.layers.27.self_attn.v_proj.lora_B.default.weight
Difference: 0.0231477040797472
MISMATCH: model.layers.28.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03111119009554386
Matched: model.layers.28.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.28.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031104324385523796
Matched: model.layers.28.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.29.self_attn.q_proj.lora_A.default.weight
Difference: 0.05856567248702049
MISMATCH: model.layers.29.self_attn.q_proj.lora_B.default.weight
Difference: 0.04849151894450188
MISMATCH: model.layers.29.self_attn.v_proj.lora_A.default.weight
Difference: 0.083279550075531
MISMATCH: model.layers.29.self_attn.v_proj.lora_B.default.weight
Difference: 0.02336476556956768
MISMATCH: model.layers.30.self_attn.q_proj.lora_A.default.weight
Difference: 0.054974496364593506
MISMATCH: model.layers.30.self_attn.q_proj.lora_B.default.weight
Difference: 0.036576785147190094
MISMATCH: model.layers.30.self_attn.v_proj.lora_A.default.weight
Difference: 0.06473198533058167
MISMATCH: model.layers.30.self_attn.v_proj.lora_B.default.weight
Difference: 0.023211682215332985
MISMATCH: model.layers.31.self_attn.q_proj.lora_A.default.weight
Difference: 0.05661679804325104
MISMATCH: model.layers.31.self_attn.q_proj.lora_B.default.weight
Difference: 0.03524459898471832
MISMATCH: model.layers.31.self_attn.v_proj.lora_A.default.weight
Difference: 0.07589033991098404
MISMATCH: model.layers.31.self_attn.v_proj.lora_B.default.weight
Difference: 0.02254106104373932
MISMATCH: model.layers.32.self_attn.q_proj.lora_A.default.weight
Difference: 0.05956451967358589
MISMATCH: model.layers.32.self_attn.q_proj.lora_B.default.weight
Difference: 0.04070692136883736
MISMATCH: model.layers.32.self_attn.v_proj.lora_A.default.weight
Difference: 0.08063861727714539
MISMATCH: model.layers.32.self_attn.v_proj.lora_B.default.weight
Difference: 0.025932766497135162
MISMATCH: model.layers.33.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031105322763323784
Matched: model.layers.33.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.33.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03110956959426403
Matched: model.layers.33.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.34.self_attn.q_proj.lora_A.default.weight
Difference: 0.060254618525505066
MISMATCH: model.layers.34.self_attn.q_proj.lora_B.default.weight
Difference: 0.06335432827472687
MISMATCH: model.layers.34.self_attn.v_proj.lora_A.default.weight
Difference: 0.07700518518686295
MISMATCH: model.layers.34.self_attn.v_proj.lora_B.default.weight
Difference: 0.025377722457051277
MISMATCH: model.layers.35.self_attn.q_proj.lora_A.default.weight
Difference: 0.060502585023641586
MISMATCH: model.layers.35.self_attn.q_proj.lora_B.default.weight
Difference: 0.05941809341311455
MISMATCH: model.layers.35.self_attn.v_proj.lora_A.default.weight
Difference: 0.10005351901054382
MISMATCH: model.layers.35.self_attn.v_proj.lora_B.default.weight
Difference: 0.023711536079645157
MISMATCH: model.layers.36.self_attn.q_proj.lora_A.default.weight
Difference: 0.0553964227437973
MISMATCH: model.layers.36.self_attn.q_proj.lora_B.default.weight
Difference: 0.054739031940698624
MISMATCH: model.layers.36.self_attn.v_proj.lora_A.default.weight
Difference: 0.07921740412712097
MISMATCH: model.layers.36.self_attn.v_proj.lora_B.default.weight
Difference: 0.02249295637011528
MISMATCH: model.layers.37.self_attn.q_proj.lora_A.default.weight
Difference: 0.0650814026594162
MISMATCH: model.layers.37.self_attn.q_proj.lora_B.default.weight
Difference: 0.03575053811073303
MISMATCH: model.layers.37.self_attn.v_proj.lora_A.default.weight
Difference: 0.08436111360788345
MISMATCH: model.layers.37.self_attn.v_proj.lora_B.default.weight
Difference: 0.036374129354953766
MISMATCH: model.layers.38.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031149109825491905
Matched: model.layers.38.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.38.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03113511949777603
Matched: model.layers.38.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.39.self_attn.q_proj.lora_A.default.weight
Difference: 0.11822546273469925
MISMATCH: model.layers.39.self_attn.q_proj.lora_B.default.weight
Difference: 0.19028238952159882
MISMATCH: model.layers.39.self_attn.v_proj.lora_A.default.weight
Difference: 0.0781547799706459
MISMATCH: model.layers.39.self_attn.v_proj.lora_B.default.weight
Difference: 0.03365113586187363
Some LoRA layers did not match.
bbbbb
Length of the updated dataset: 560
Traceback (most recent call last):
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/omar.py", line 508, in <module>
    latex_code = full_output[start:end].strip()
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/omar.py", line 401, in generate_tikz_code
    
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/peft_model.py", line 817, in generate
    return self.get_base_model().generate(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/generation/utils.py", line 1972, in generate
    self._validate_model_kwargs(model_kwargs.copy())
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/generation/utils.py", line 1360, in _validate_model_kwargs
    raise ValueError(
ValueError: The following `model_kwargs` are not used by the model: ['pixel_values', 'aspect_ratio_ids', 'aspect_ratio_mask'] (note: typos in the generate arguments will also show up in this list)
