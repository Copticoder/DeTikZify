Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:05,  1.32s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.15s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.07s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.04s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:04<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:04<00:00,  1.08it/s]
Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]
Some weights of the model checkpoint at /home/oe2015/final_model_checkpoint_512_quant were not used when initializing MllamaForCausalLM: ['model.layers.0.mlp.down_proj.SCB', 'model.layers.0.mlp.down_proj.weight_format', 'model.layers.0.mlp.gate_proj.SCB', 'model.layers.0.mlp.gate_proj.weight_format', 'model.layers.0.mlp.up_proj.SCB', 'model.layers.0.mlp.up_proj.weight_format', 'model.layers.0.self_attn.k_proj.SCB', 'model.layers.0.self_attn.k_proj.weight_format', 'model.layers.0.self_attn.o_proj.SCB', 'model.layers.0.self_attn.o_proj.weight_format', 'model.layers.0.self_attn.q_proj.base_layer.SCB', 'model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.base_layer.weight_format', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.SCB', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight_format', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.mlp.down_proj.SCB', 'model.layers.1.mlp.down_proj.weight_format', 'model.layers.1.mlp.gate_proj.SCB', 'model.layers.1.mlp.gate_proj.weight_format', 'model.layers.1.mlp.up_proj.SCB', 'model.layers.1.mlp.up_proj.weight_format', 'model.layers.1.self_attn.k_proj.SCB', 'model.layers.1.self_attn.k_proj.weight_format', 'model.layers.1.self_attn.o_proj.SCB', 'model.layers.1.self_attn.o_proj.weight_format', 'model.layers.1.self_attn.q_proj.base_layer.SCB', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight_format', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.SCB', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight_format', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.10.mlp.down_proj.SCB', 'model.layers.10.mlp.down_proj.weight_format', 'model.layers.10.mlp.gate_proj.SCB', 'model.layers.10.mlp.gate_proj.weight_format', 'model.layers.10.mlp.up_proj.SCB', 'model.layers.10.mlp.up_proj.weight_format', 'model.layers.10.self_attn.k_proj.SCB', 'model.layers.10.self_attn.k_proj.weight_format', 'model.layers.10.self_attn.o_proj.SCB', 'model.layers.10.self_attn.o_proj.weight_format', 'model.layers.10.self_attn.q_proj.base_layer.SCB', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight_format', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.SCB', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight_format', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.11.mlp.down_proj.SCB', 'model.layers.11.mlp.down_proj.weight_format', 'model.layers.11.mlp.gate_proj.SCB', 'model.layers.11.mlp.gate_proj.weight_format', 'model.layers.11.mlp.up_proj.SCB', 'model.layers.11.mlp.up_proj.weight_format', 'model.layers.11.self_attn.k_proj.SCB', 'model.layers.11.self_attn.k_proj.weight_format', 'model.layers.11.self_attn.o_proj.SCB', 'model.layers.11.self_attn.o_proj.weight_format', 'model.layers.11.self_attn.q_proj.base_layer.SCB', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight_format', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.v_proj.base_layer.SCB', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight_format', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.mlp.down_proj.SCB', 'model.layers.12.mlp.down_proj.weight_format', 'model.layers.12.mlp.gate_proj.SCB', 'model.layers.12.mlp.gate_proj.weight_format', 'model.layers.12.mlp.up_proj.SCB', 'model.layers.12.mlp.up_proj.weight_format', 'model.layers.12.self_attn.k_proj.SCB', 'model.layers.12.self_attn.k_proj.weight_format', 'model.layers.12.self_attn.o_proj.SCB', 'model.layers.12.self_attn.o_proj.weight_format', 'model.layers.12.self_attn.q_proj.base_layer.SCB', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight_format', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.SCB', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight_format', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.13.cross_attn.k_proj.SCB', 'model.layers.13.cross_attn.k_proj.weight_format', 'model.layers.13.cross_attn.o_proj.SCB', 'model.layers.13.cross_attn.o_proj.weight_format', 'model.layers.13.cross_attn.q_proj.base_layer.SCB', 'model.layers.13.cross_attn.q_proj.base_layer.weight', 'model.layers.13.cross_attn.q_proj.base_layer.weight_format', 'model.layers.13.cross_attn.q_proj.lora_A.default.weight', 'model.layers.13.cross_attn.q_proj.lora_B.default.weight', 'model.layers.13.cross_attn.v_proj.base_layer.SCB', 'model.layers.13.cross_attn.v_proj.base_layer.weight', 'model.layers.13.cross_attn.v_proj.base_layer.weight_format', 'model.layers.13.cross_attn.v_proj.lora_A.default.weight', 'model.layers.13.cross_attn.v_proj.lora_B.default.weight', 'model.layers.13.mlp.down_proj.SCB', 'model.layers.13.mlp.down_proj.weight_format', 'model.layers.13.mlp.gate_proj.SCB', 'model.layers.13.mlp.gate_proj.weight_format', 'model.layers.13.mlp.up_proj.SCB', 'model.layers.13.mlp.up_proj.weight_format', 'model.layers.14.mlp.down_proj.SCB', 'model.layers.14.mlp.down_proj.weight_format', 'model.layers.14.mlp.gate_proj.SCB', 'model.layers.14.mlp.gate_proj.weight_format', 'model.layers.14.mlp.up_proj.SCB', 'model.layers.14.mlp.up_proj.weight_format', 'model.layers.14.self_attn.k_proj.SCB', 'model.layers.14.self_attn.k_proj.weight_format', 'model.layers.14.self_attn.o_proj.SCB', 'model.layers.14.self_attn.o_proj.weight_format', 'model.layers.14.self_attn.q_proj.base_layer.SCB', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight_format', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.SCB', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight_format', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.mlp.down_proj.SCB', 'model.layers.15.mlp.down_proj.weight_format', 'model.layers.15.mlp.gate_proj.SCB', 'model.layers.15.mlp.gate_proj.weight_format', 'model.layers.15.mlp.up_proj.SCB', 'model.layers.15.mlp.up_proj.weight_format', 'model.layers.15.self_attn.k_proj.SCB', 'model.layers.15.self_attn.k_proj.weight_format', 'model.layers.15.self_attn.o_proj.SCB', 'model.layers.15.self_attn.o_proj.weight_format', 'model.layers.15.self_attn.q_proj.base_layer.SCB', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight_format', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.SCB', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight_format', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.mlp.down_proj.SCB', 'model.layers.16.mlp.down_proj.weight_format', 'model.layers.16.mlp.gate_proj.SCB', 'model.layers.16.mlp.gate_proj.weight_format', 'model.layers.16.mlp.up_proj.SCB', 'model.layers.16.mlp.up_proj.weight_format', 'model.layers.16.self_attn.k_proj.SCB', 'model.layers.16.self_attn.k_proj.weight_format', 'model.layers.16.self_attn.o_proj.SCB', 'model.layers.16.self_attn.o_proj.weight_format', 'model.layers.16.self_attn.q_proj.base_layer.SCB', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight_format', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.SCB', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight_format', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.17.mlp.down_proj.SCB', 'model.layers.17.mlp.down_proj.weight_format', 'model.layers.17.mlp.gate_proj.SCB', 'model.layers.17.mlp.gate_proj.weight_format', 'model.layers.17.mlp.up_proj.SCB', 'model.layers.17.mlp.up_proj.weight_format', 'model.layers.17.self_attn.k_proj.SCB', 'model.layers.17.self_attn.k_proj.weight_format', 'model.layers.17.self_attn.o_proj.SCB', 'model.layers.17.self_attn.o_proj.weight_format', 'model.layers.17.self_attn.q_proj.base_layer.SCB', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight_format', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.base_layer.SCB', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight_format', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.cross_attn.k_proj.SCB', 'model.layers.18.cross_attn.k_proj.weight_format', 'model.layers.18.cross_attn.o_proj.SCB', 'model.layers.18.cross_attn.o_proj.weight_format', 'model.layers.18.cross_attn.q_proj.base_layer.SCB', 'model.layers.18.cross_attn.q_proj.base_layer.weight', 'model.layers.18.cross_attn.q_proj.base_layer.weight_format', 'model.layers.18.cross_attn.q_proj.lora_A.default.weight', 'model.layers.18.cross_attn.q_proj.lora_B.default.weight', 'model.layers.18.cross_attn.v_proj.base_layer.SCB', 'model.layers.18.cross_attn.v_proj.base_layer.weight', 'model.layers.18.cross_attn.v_proj.base_layer.weight_format', 'model.layers.18.cross_attn.v_proj.lora_A.default.weight', 'model.layers.18.cross_attn.v_proj.lora_B.default.weight', 'model.layers.18.mlp.down_proj.SCB', 'model.layers.18.mlp.down_proj.weight_format', 'model.layers.18.mlp.gate_proj.SCB', 'model.layers.18.mlp.gate_proj.weight_format', 'model.layers.18.mlp.up_proj.SCB', 'model.layers.18.mlp.up_proj.weight_format', 'model.layers.19.mlp.down_proj.SCB', 'model.layers.19.mlp.down_proj.weight_format', 'model.layers.19.mlp.gate_proj.SCB', 'model.layers.19.mlp.gate_proj.weight_format', 'model.layers.19.mlp.up_proj.SCB', 'model.layers.19.mlp.up_proj.weight_format', 'model.layers.19.self_attn.k_proj.SCB', 'model.layers.19.self_attn.k_proj.weight_format', 'model.layers.19.self_attn.o_proj.SCB', 'model.layers.19.self_attn.o_proj.weight_format', 'model.layers.19.self_attn.q_proj.base_layer.SCB', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight_format', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.v_proj.base_layer.SCB', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight_format', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.2.mlp.down_proj.SCB', 'model.layers.2.mlp.down_proj.weight_format', 'model.layers.2.mlp.gate_proj.SCB', 'model.layers.2.mlp.gate_proj.weight_format', 'model.layers.2.mlp.up_proj.SCB', 'model.layers.2.mlp.up_proj.weight_format', 'model.layers.2.self_attn.k_proj.SCB', 'model.layers.2.self_attn.k_proj.weight_format', 'model.layers.2.self_attn.o_proj.SCB', 'model.layers.2.self_attn.o_proj.weight_format', 'model.layers.2.self_attn.q_proj.base_layer.SCB', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight_format', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.base_layer.SCB', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight_format', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.mlp.down_proj.SCB', 'model.layers.20.mlp.down_proj.weight_format', 'model.layers.20.mlp.gate_proj.SCB', 'model.layers.20.mlp.gate_proj.weight_format', 'model.layers.20.mlp.up_proj.SCB', 'model.layers.20.mlp.up_proj.weight_format', 'model.layers.20.self_attn.k_proj.SCB', 'model.layers.20.self_attn.k_proj.weight_format', 'model.layers.20.self_attn.o_proj.SCB', 'model.layers.20.self_attn.o_proj.weight_format', 'model.layers.20.self_attn.q_proj.base_layer.SCB', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight_format', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.SCB', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight_format', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.mlp.down_proj.SCB', 'model.layers.21.mlp.down_proj.weight_format', 'model.layers.21.mlp.gate_proj.SCB', 'model.layers.21.mlp.gate_proj.weight_format', 'model.layers.21.mlp.up_proj.SCB', 'model.layers.21.mlp.up_proj.weight_format', 'model.layers.21.self_attn.k_proj.SCB', 'model.layers.21.self_attn.k_proj.weight_format', 'model.layers.21.self_attn.o_proj.SCB', 'model.layers.21.self_attn.o_proj.weight_format', 'model.layers.21.self_attn.q_proj.base_layer.SCB', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight_format', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.SCB', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight_format', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.mlp.down_proj.SCB', 'model.layers.22.mlp.down_proj.weight_format', 'model.layers.22.mlp.gate_proj.SCB', 'model.layers.22.mlp.gate_proj.weight_format', 'model.layers.22.mlp.up_proj.SCB', 'model.layers.22.mlp.up_proj.weight_format', 'model.layers.22.self_attn.k_proj.SCB', 'model.layers.22.self_attn.k_proj.weight_format', 'model.layers.22.self_attn.o_proj.SCB', 'model.layers.22.self_attn.o_proj.weight_format', 'model.layers.22.self_attn.q_proj.base_layer.SCB', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight_format', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.SCB', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight_format', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.cross_attn.k_proj.SCB', 'model.layers.23.cross_attn.k_proj.weight_format', 'model.layers.23.cross_attn.o_proj.SCB', 'model.layers.23.cross_attn.o_proj.weight_format', 'model.layers.23.cross_attn.q_proj.base_layer.SCB', 'model.layers.23.cross_attn.q_proj.base_layer.weight', 'model.layers.23.cross_attn.q_proj.base_layer.weight_format', 'model.layers.23.cross_attn.q_proj.lora_A.default.weight', 'model.layers.23.cross_attn.q_proj.lora_B.default.weight', 'model.layers.23.cross_attn.v_proj.base_layer.SCB', 'model.layers.23.cross_attn.v_proj.base_layer.weight', 'model.layers.23.cross_attn.v_proj.base_layer.weight_format', 'model.layers.23.cross_attn.v_proj.lora_A.default.weight', 'model.layers.23.cross_attn.v_proj.lora_B.default.weight', 'model.layers.23.mlp.down_proj.SCB', 'model.layers.23.mlp.down_proj.weight_format', 'model.layers.23.mlp.gate_proj.SCB', 'model.layers.23.mlp.gate_proj.weight_format', 'model.layers.23.mlp.up_proj.SCB', 'model.layers.23.mlp.up_proj.weight_format', 'model.layers.24.mlp.down_proj.SCB', 'model.layers.24.mlp.down_proj.weight_format', 'model.layers.24.mlp.gate_proj.SCB', 'model.layers.24.mlp.gate_proj.weight_format', 'model.layers.24.mlp.up_proj.SCB', 'model.layers.24.mlp.up_proj.weight_format', 'model.layers.24.self_attn.k_proj.SCB', 'model.layers.24.self_attn.k_proj.weight_format', 'model.layers.24.self_attn.o_proj.SCB', 'model.layers.24.self_attn.o_proj.weight_format', 'model.layers.24.self_attn.q_proj.base_layer.SCB', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight_format', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.SCB', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight_format', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.25.mlp.down_proj.SCB', 'model.layers.25.mlp.down_proj.weight_format', 'model.layers.25.mlp.gate_proj.SCB', 'model.layers.25.mlp.gate_proj.weight_format', 'model.layers.25.mlp.up_proj.SCB', 'model.layers.25.mlp.up_proj.weight_format', 'model.layers.25.self_attn.k_proj.SCB', 'model.layers.25.self_attn.k_proj.weight_format', 'model.layers.25.self_attn.o_proj.SCB', 'model.layers.25.self_attn.o_proj.weight_format', 'model.layers.25.self_attn.q_proj.base_layer.SCB', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight_format', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.SCB', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight_format', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.mlp.down_proj.SCB', 'model.layers.26.mlp.down_proj.weight_format', 'model.layers.26.mlp.gate_proj.SCB', 'model.layers.26.mlp.gate_proj.weight_format', 'model.layers.26.mlp.up_proj.SCB', 'model.layers.26.mlp.up_proj.weight_format', 'model.layers.26.self_attn.k_proj.SCB', 'model.layers.26.self_attn.k_proj.weight_format', 'model.layers.26.self_attn.o_proj.SCB', 'model.layers.26.self_attn.o_proj.weight_format', 'model.layers.26.self_attn.q_proj.base_layer.SCB', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight_format', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.SCB', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight_format', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.mlp.down_proj.SCB', 'model.layers.27.mlp.down_proj.weight_format', 'model.layers.27.mlp.gate_proj.SCB', 'model.layers.27.mlp.gate_proj.weight_format', 'model.layers.27.mlp.up_proj.SCB', 'model.layers.27.mlp.up_proj.weight_format', 'model.layers.27.self_attn.k_proj.SCB', 'model.layers.27.self_attn.k_proj.weight_format', 'model.layers.27.self_attn.o_proj.SCB', 'model.layers.27.self_attn.o_proj.weight_format', 'model.layers.27.self_attn.q_proj.base_layer.SCB', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight_format', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.SCB', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight_format', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.cross_attn.k_proj.SCB', 'model.layers.28.cross_attn.k_proj.weight_format', 'model.layers.28.cross_attn.o_proj.SCB', 'model.layers.28.cross_attn.o_proj.weight_format', 'model.layers.28.cross_attn.q_proj.base_layer.SCB', 'model.layers.28.cross_attn.q_proj.base_layer.weight', 'model.layers.28.cross_attn.q_proj.base_layer.weight_format', 'model.layers.28.cross_attn.q_proj.lora_A.default.weight', 'model.layers.28.cross_attn.q_proj.lora_B.default.weight', 'model.layers.28.cross_attn.v_proj.base_layer.SCB', 'model.layers.28.cross_attn.v_proj.base_layer.weight', 'model.layers.28.cross_attn.v_proj.base_layer.weight_format', 'model.layers.28.cross_attn.v_proj.lora_A.default.weight', 'model.layers.28.cross_attn.v_proj.lora_B.default.weight', 'model.layers.28.mlp.down_proj.SCB', 'model.layers.28.mlp.down_proj.weight_format', 'model.layers.28.mlp.gate_proj.SCB', 'model.layers.28.mlp.gate_proj.weight_format', 'model.layers.28.mlp.up_proj.SCB', 'model.layers.28.mlp.up_proj.weight_format', 'model.layers.29.mlp.down_proj.SCB', 'model.layers.29.mlp.down_proj.weight_format', 'model.layers.29.mlp.gate_proj.SCB', 'model.layers.29.mlp.gate_proj.weight_format', 'model.layers.29.mlp.up_proj.SCB', 'model.layers.29.mlp.up_proj.weight_format', 'model.layers.29.self_attn.k_proj.SCB', 'model.layers.29.self_attn.k_proj.weight_format', 'model.layers.29.self_attn.o_proj.SCB', 'model.layers.29.self_attn.o_proj.weight_format', 'model.layers.29.self_attn.q_proj.base_layer.SCB', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight_format', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.29.self_attn.v_proj.base_layer.SCB', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight_format', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.3.cross_attn.k_proj.SCB', 'model.layers.3.cross_attn.k_proj.weight_format', 'model.layers.3.cross_attn.o_proj.SCB', 'model.layers.3.cross_attn.o_proj.weight_format', 'model.layers.3.cross_attn.q_proj.base_layer.SCB', 'model.layers.3.cross_attn.q_proj.base_layer.weight', 'model.layers.3.cross_attn.q_proj.base_layer.weight_format', 'model.layers.3.cross_attn.q_proj.lora_A.default.weight', 'model.layers.3.cross_attn.q_proj.lora_B.default.weight', 'model.layers.3.cross_attn.v_proj.base_layer.SCB', 'model.layers.3.cross_attn.v_proj.base_layer.weight', 'model.layers.3.cross_attn.v_proj.base_layer.weight_format', 'model.layers.3.cross_attn.v_proj.lora_A.default.weight', 'model.layers.3.cross_attn.v_proj.lora_B.default.weight', 'model.layers.3.mlp.down_proj.SCB', 'model.layers.3.mlp.down_proj.weight_format', 'model.layers.3.mlp.gate_proj.SCB', 'model.layers.3.mlp.gate_proj.weight_format', 'model.layers.3.mlp.up_proj.SCB', 'model.layers.3.mlp.up_proj.weight_format', 'model.layers.30.mlp.down_proj.SCB', 'model.layers.30.mlp.down_proj.weight_format', 'model.layers.30.mlp.gate_proj.SCB', 'model.layers.30.mlp.gate_proj.weight_format', 'model.layers.30.mlp.up_proj.SCB', 'model.layers.30.mlp.up_proj.weight_format', 'model.layers.30.self_attn.k_proj.SCB', 'model.layers.30.self_attn.k_proj.weight_format', 'model.layers.30.self_attn.o_proj.SCB', 'model.layers.30.self_attn.o_proj.weight_format', 'model.layers.30.self_attn.q_proj.base_layer.SCB', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight_format', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.v_proj.base_layer.SCB', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight_format', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.mlp.down_proj.SCB', 'model.layers.31.mlp.down_proj.weight_format', 'model.layers.31.mlp.gate_proj.SCB', 'model.layers.31.mlp.gate_proj.weight_format', 'model.layers.31.mlp.up_proj.SCB', 'model.layers.31.mlp.up_proj.weight_format', 'model.layers.31.self_attn.k_proj.SCB', 'model.layers.31.self_attn.k_proj.weight_format', 'model.layers.31.self_attn.o_proj.SCB', 'model.layers.31.self_attn.o_proj.weight_format', 'model.layers.31.self_attn.q_proj.base_layer.SCB', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight_format', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.SCB', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight_format', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.32.mlp.down_proj.SCB', 'model.layers.32.mlp.down_proj.weight_format', 'model.layers.32.mlp.gate_proj.SCB', 'model.layers.32.mlp.gate_proj.weight_format', 'model.layers.32.mlp.up_proj.SCB', 'model.layers.32.mlp.up_proj.weight_format', 'model.layers.32.self_attn.k_proj.SCB', 'model.layers.32.self_attn.k_proj.weight_format', 'model.layers.32.self_attn.o_proj.SCB', 'model.layers.32.self_attn.o_proj.weight_format', 'model.layers.32.self_attn.q_proj.base_layer.SCB', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight_format', 'model.layers.32.self_attn.q_proj.lora_A.default.weight', 'model.layers.32.self_attn.q_proj.lora_B.default.weight', 'model.layers.32.self_attn.v_proj.base_layer.SCB', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.base_layer.weight_format', 'model.layers.32.self_attn.v_proj.lora_A.default.weight', 'model.layers.32.self_attn.v_proj.lora_B.default.weight', 'model.layers.33.cross_attn.k_proj.SCB', 'model.layers.33.cross_attn.k_proj.weight_format', 'model.layers.33.cross_attn.o_proj.SCB', 'model.layers.33.cross_attn.o_proj.weight_format', 'model.layers.33.cross_attn.q_proj.base_layer.SCB', 'model.layers.33.cross_attn.q_proj.base_layer.weight', 'model.layers.33.cross_attn.q_proj.base_layer.weight_format', 'model.layers.33.cross_attn.q_proj.lora_A.default.weight', 'model.layers.33.cross_attn.q_proj.lora_B.default.weight', 'model.layers.33.cross_attn.v_proj.base_layer.SCB', 'model.layers.33.cross_attn.v_proj.base_layer.weight', 'model.layers.33.cross_attn.v_proj.base_layer.weight_format', 'model.layers.33.cross_attn.v_proj.lora_A.default.weight', 'model.layers.33.cross_attn.v_proj.lora_B.default.weight', 'model.layers.33.mlp.down_proj.SCB', 'model.layers.33.mlp.down_proj.weight_format', 'model.layers.33.mlp.gate_proj.SCB', 'model.layers.33.mlp.gate_proj.weight_format', 'model.layers.33.mlp.up_proj.SCB', 'model.layers.33.mlp.up_proj.weight_format', 'model.layers.34.mlp.down_proj.SCB', 'model.layers.34.mlp.down_proj.weight_format', 'model.layers.34.mlp.gate_proj.SCB', 'model.layers.34.mlp.gate_proj.weight_format', 'model.layers.34.mlp.up_proj.SCB', 'model.layers.34.mlp.up_proj.weight_format', 'model.layers.34.self_attn.k_proj.SCB', 'model.layers.34.self_attn.k_proj.weight_format', 'model.layers.34.self_attn.o_proj.SCB', 'model.layers.34.self_attn.o_proj.weight_format', 'model.layers.34.self_attn.q_proj.base_layer.SCB', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight_format', 'model.layers.34.self_attn.q_proj.lora_A.default.weight', 'model.layers.34.self_attn.q_proj.lora_B.default.weight', 'model.layers.34.self_attn.v_proj.base_layer.SCB', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.base_layer.weight_format', 'model.layers.34.self_attn.v_proj.lora_A.default.weight', 'model.layers.34.self_attn.v_proj.lora_B.default.weight', 'model.layers.35.mlp.down_proj.SCB', 'model.layers.35.mlp.down_proj.weight_format', 'model.layers.35.mlp.gate_proj.SCB', 'model.layers.35.mlp.gate_proj.weight_format', 'model.layers.35.mlp.up_proj.SCB', 'model.layers.35.mlp.up_proj.weight_format', 'model.layers.35.self_attn.k_proj.SCB', 'model.layers.35.self_attn.k_proj.weight_format', 'model.layers.35.self_attn.o_proj.SCB', 'model.layers.35.self_attn.o_proj.weight_format', 'model.layers.35.self_attn.q_proj.base_layer.SCB', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight_format', 'model.layers.35.self_attn.q_proj.lora_A.default.weight', 'model.layers.35.self_attn.q_proj.lora_B.default.weight', 'model.layers.35.self_attn.v_proj.base_layer.SCB', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.base_layer.weight_format', 'model.layers.35.self_attn.v_proj.lora_A.default.weight', 'model.layers.35.self_attn.v_proj.lora_B.default.weight', 'model.layers.36.mlp.down_proj.SCB', 'model.layers.36.mlp.down_proj.weight_format', 'model.layers.36.mlp.gate_proj.SCB', 'model.layers.36.mlp.gate_proj.weight_format', 'model.layers.36.mlp.up_proj.SCB', 'model.layers.36.mlp.up_proj.weight_format', 'model.layers.36.self_attn.k_proj.SCB', 'model.layers.36.self_attn.k_proj.weight_format', 'model.layers.36.self_attn.o_proj.SCB', 'model.layers.36.self_attn.o_proj.weight_format', 'model.layers.36.self_attn.q_proj.base_layer.SCB', 'model.layers.36.self_attn.q_proj.base_layer.weight', 'model.layers.36.self_attn.q_proj.base_layer.weight_format', 'model.layers.36.self_attn.q_proj.lora_A.default.weight', 'model.layers.36.self_attn.q_proj.lora_B.default.weight', 'model.layers.36.self_attn.v_proj.base_layer.SCB', 'model.layers.36.self_attn.v_proj.base_layer.weight', 'model.layers.36.self_attn.v_proj.base_layer.weight_format', 'model.layers.36.self_attn.v_proj.lora_A.default.weight', 'model.layers.36.self_attn.v_proj.lora_B.default.weight', 'model.layers.37.mlp.down_proj.SCB', 'model.layers.37.mlp.down_proj.weight_format', 'model.layers.37.mlp.gate_proj.SCB', 'model.layers.37.mlp.gate_proj.weight_format', 'model.layers.37.mlp.up_proj.SCB', 'model.layers.37.mlp.up_proj.weight_format', 'model.layers.37.self_attn.k_proj.SCB', 'model.layers.37.self_attn.k_proj.weight_format', 'model.layers.37.self_attn.o_proj.SCB', 'model.layers.37.self_attn.o_proj.weight_format', 'model.layers.37.self_attn.q_proj.base_layer.SCB', 'model.layers.37.self_attn.q_proj.base_layer.weight', 'model.layers.37.self_attn.q_proj.base_layer.weight_format', 'model.layers.37.self_attn.q_proj.lora_A.default.weight', 'model.layers.37.self_attn.q_proj.lora_B.default.weight', 'model.layers.37.self_attn.v_proj.base_layer.SCB', 'model.layers.37.self_attn.v_proj.base_layer.weight', 'model.layers.37.self_attn.v_proj.base_layer.weight_format', 'model.layers.37.self_attn.v_proj.lora_A.default.weight', 'model.layers.37.self_attn.v_proj.lora_B.default.weight', 'model.layers.38.cross_attn.k_proj.SCB', 'model.layers.38.cross_attn.k_proj.weight_format', 'model.layers.38.cross_attn.o_proj.SCB', 'model.layers.38.cross_attn.o_proj.weight_format', 'model.layers.38.cross_attn.q_proj.base_layer.SCB', 'model.layers.38.cross_attn.q_proj.base_layer.weight', 'model.layers.38.cross_attn.q_proj.base_layer.weight_format', 'model.layers.38.cross_attn.q_proj.lora_A.default.weight', 'model.layers.38.cross_attn.q_proj.lora_B.default.weight', 'model.layers.38.cross_attn.v_proj.base_layer.SCB', 'model.layers.38.cross_attn.v_proj.base_layer.weight', 'model.layers.38.cross_attn.v_proj.base_layer.weight_format', 'model.layers.38.cross_attn.v_proj.lora_A.default.weight', 'model.layers.38.cross_attn.v_proj.lora_B.default.weight', 'model.layers.38.mlp.down_proj.SCB', 'model.layers.38.mlp.down_proj.weight_format', 'model.layers.38.mlp.gate_proj.SCB', 'model.layers.38.mlp.gate_proj.weight_format', 'model.layers.38.mlp.up_proj.SCB', 'model.layers.38.mlp.up_proj.weight_format', 'model.layers.39.mlp.down_proj.SCB', 'model.layers.39.mlp.down_proj.weight_format', 'model.layers.39.mlp.gate_proj.SCB', 'model.layers.39.mlp.gate_proj.weight_format', 'model.layers.39.mlp.up_proj.SCB', 'model.layers.39.mlp.up_proj.weight_format', 'model.layers.39.self_attn.k_proj.SCB', 'model.layers.39.self_attn.k_proj.weight_format', 'model.layers.39.self_attn.o_proj.SCB', 'model.layers.39.self_attn.o_proj.weight_format', 'model.layers.39.self_attn.q_proj.base_layer.SCB', 'model.layers.39.self_attn.q_proj.base_layer.weight', 'model.layers.39.self_attn.q_proj.base_layer.weight_format', 'model.layers.39.self_attn.q_proj.lora_A.default.weight', 'model.layers.39.self_attn.q_proj.lora_B.default.weight', 'model.layers.39.self_attn.v_proj.base_layer.SCB', 'model.layers.39.self_attn.v_proj.base_layer.weight', 'model.layers.39.self_attn.v_proj.base_layer.weight_format', 'model.layers.39.self_attn.v_proj.lora_A.default.weight', 'model.layers.39.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.mlp.down_proj.SCB', 'model.layers.4.mlp.down_proj.weight_format', 'model.layers.4.mlp.gate_proj.SCB', 'model.layers.4.mlp.gate_proj.weight_format', 'model.layers.4.mlp.up_proj.SCB', 'model.layers.4.mlp.up_proj.weight_format', 'model.layers.4.self_attn.k_proj.SCB', 'model.layers.4.self_attn.k_proj.weight_format', 'model.layers.4.self_attn.o_proj.SCB', 'model.layers.4.self_attn.o_proj.weight_format', 'model.layers.4.self_attn.q_proj.base_layer.SCB', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight_format', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.SCB', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight_format', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.5.mlp.down_proj.SCB', 'model.layers.5.mlp.down_proj.weight_format', 'model.layers.5.mlp.gate_proj.SCB', 'model.layers.5.mlp.gate_proj.weight_format', 'model.layers.5.mlp.up_proj.SCB', 'model.layers.5.mlp.up_proj.weight_format', 'model.layers.5.self_attn.k_proj.SCB', 'model.layers.5.self_attn.k_proj.weight_format', 'model.layers.5.self_attn.o_proj.SCB', 'model.layers.5.self_attn.o_proj.weight_format', 'model.layers.5.self_attn.q_proj.base_layer.SCB', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight_format', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.SCB', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight_format', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.mlp.down_proj.SCB', 'model.layers.6.mlp.down_proj.weight_format', 'model.layers.6.mlp.gate_proj.SCB', 'model.layers.6.mlp.gate_proj.weight_format', 'model.layers.6.mlp.up_proj.SCB', 'model.layers.6.mlp.up_proj.weight_format', 'model.layers.6.self_attn.k_proj.SCB', 'model.layers.6.self_attn.k_proj.weight_format', 'model.layers.6.self_attn.o_proj.SCB', 'model.layers.6.self_attn.o_proj.weight_format', 'model.layers.6.self_attn.q_proj.base_layer.SCB', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight_format', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.SCB', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight_format', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.mlp.down_proj.SCB', 'model.layers.7.mlp.down_proj.weight_format', 'model.layers.7.mlp.gate_proj.SCB', 'model.layers.7.mlp.gate_proj.weight_format', 'model.layers.7.mlp.up_proj.SCB', 'model.layers.7.mlp.up_proj.weight_format', 'model.layers.7.self_attn.k_proj.SCB', 'model.layers.7.self_attn.k_proj.weight_format', 'model.layers.7.self_attn.o_proj.SCB', 'model.layers.7.self_attn.o_proj.weight_format', 'model.layers.7.self_attn.q_proj.base_layer.SCB', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight_format', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.SCB', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight_format', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.8.cross_attn.k_proj.SCB', 'model.layers.8.cross_attn.k_proj.weight_format', 'model.layers.8.cross_attn.o_proj.SCB', 'model.layers.8.cross_attn.o_proj.weight_format', 'model.layers.8.cross_attn.q_proj.base_layer.SCB', 'model.layers.8.cross_attn.q_proj.base_layer.weight', 'model.layers.8.cross_attn.q_proj.base_layer.weight_format', 'model.layers.8.cross_attn.q_proj.lora_A.default.weight', 'model.layers.8.cross_attn.q_proj.lora_B.default.weight', 'model.layers.8.cross_attn.v_proj.base_layer.SCB', 'model.layers.8.cross_attn.v_proj.base_layer.weight', 'model.layers.8.cross_attn.v_proj.base_layer.weight_format', 'model.layers.8.cross_attn.v_proj.lora_A.default.weight', 'model.layers.8.cross_attn.v_proj.lora_B.default.weight', 'model.layers.8.mlp.down_proj.SCB', 'model.layers.8.mlp.down_proj.weight_format', 'model.layers.8.mlp.gate_proj.SCB', 'model.layers.8.mlp.gate_proj.weight_format', 'model.layers.8.mlp.up_proj.SCB', 'model.layers.8.mlp.up_proj.weight_format', 'model.layers.9.mlp.down_proj.SCB', 'model.layers.9.mlp.down_proj.weight_format', 'model.layers.9.mlp.gate_proj.SCB', 'model.layers.9.mlp.gate_proj.weight_format', 'model.layers.9.mlp.up_proj.SCB', 'model.layers.9.mlp.up_proj.weight_format', 'model.layers.9.self_attn.k_proj.SCB', 'model.layers.9.self_attn.k_proj.weight_format', 'model.layers.9.self_attn.o_proj.SCB', 'model.layers.9.self_attn.o_proj.weight_format', 'model.layers.9.self_attn.q_proj.base_layer.SCB', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight_format', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.SCB', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight_format', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight']
- This IS expected if you are initializing MllamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MllamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of MllamaForCausalLM were not initialized from the model checkpoint at /home/oe2015/final_model_checkpoint_512_quant and are newly initialized: ['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.cross_attn.q_proj.weight', 'model.layers.13.cross_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.cross_attn.q_proj.weight', 'model.layers.18.cross_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.cross_attn.q_proj.weight', 'model.layers.23.cross_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.cross_attn.q_proj.weight', 'model.layers.28.cross_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.cross_attn.q_proj.weight', 'model.layers.3.cross_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.cross_attn.q_proj.weight', 'model.layers.33.cross_attn.v_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.cross_attn.q_proj.weight', 'model.layers.38.cross_attn.v_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.cross_attn.q_proj.weight', 'model.layers.8.cross_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/mapping.py:172: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from '/home/oe2015/final_model_checkpoint_512_quant' to 'mylesgoose/Llama-3.2-11B-Vision-Instruct'. Please ensure that the correct base model is loaded when loading this checkpoint.
  warnings.warn(
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)  # noqa: B028
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_B.default.weight matches: True
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.cross_attn_attn_gate False
base_model.model.model.layers.3.cross_attn_mlp_gate False
base_model.model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.cross_attn_attn_gate False
base_model.model.model.layers.8.cross_attn_mlp_gate False
base_model.model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.cross_attn_attn_gate False
base_model.model.model.layers.13.cross_attn_mlp_gate False
base_model.model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.cross_attn_attn_gate False
base_model.model.model.layers.18.cross_attn_mlp_gate False
base_model.model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.cross_attn_attn_gate False
base_model.model.model.layers.23.cross_attn_mlp_gate False
base_model.model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.cross_attn_attn_gate False
base_model.model.model.layers.28.cross_attn_mlp_gate False
base_model.model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.k_proj.weight False
base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.o_proj.weight False
base_model.model.model.layers.32.mlp.gate_proj.weight False
base_model.model.model.layers.32.mlp.up_proj.weight False
base_model.model.model.layers.32.mlp.down_proj.weight False
base_model.model.model.layers.32.input_layernorm.weight False
base_model.model.model.layers.32.post_attention_layernorm.weight False
base_model.model.model.layers.33.cross_attn_attn_gate False
base_model.model.model.layers.33.cross_attn_mlp_gate False
base_model.model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.model.layers.33.input_layernorm.weight False
base_model.model.model.layers.33.mlp.gate_proj.weight False
base_model.model.model.layers.33.mlp.up_proj.weight False
base_model.model.model.layers.33.mlp.down_proj.weight False
base_model.model.model.layers.33.post_attention_layernorm.weight False
base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.k_proj.weight False
base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.o_proj.weight False
base_model.model.model.layers.34.mlp.gate_proj.weight False
base_model.model.model.layers.34.mlp.up_proj.weight False
base_model.model.model.layers.34.mlp.down_proj.weight False
base_model.model.model.layers.34.input_layernorm.weight False
base_model.model.model.layers.34.post_attention_layernorm.weight False
base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.k_proj.weight False
base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.o_proj.weight False
base_model.model.model.layers.35.mlp.gate_proj.weight False
base_model.model.model.layers.35.mlp.up_proj.weight False
base_model.model.model.layers.35.mlp.down_proj.weight False
base_model.model.model.layers.35.input_layernorm.weight False
base_model.model.model.layers.35.post_attention_layernorm.weight False
base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.k_proj.weight False
base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.o_proj.weight False
base_model.model.model.layers.36.mlp.gate_proj.weight False
base_model.model.model.layers.36.mlp.up_proj.weight False
base_model.model.model.layers.36.mlp.down_proj.weight False
base_model.model.model.layers.36.input_layernorm.weight False
base_model.model.model.layers.36.post_attention_layernorm.weight False
base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.k_proj.weight False
base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.o_proj.weight False
base_model.model.model.layers.37.mlp.gate_proj.weight False
base_model.model.model.layers.37.mlp.up_proj.weight False
base_model.model.model.layers.37.mlp.down_proj.weight False
base_model.model.model.layers.37.input_layernorm.weight False
base_model.model.model.layers.37.post_attention_layernorm.weight False
base_model.model.model.layers.38.cross_attn_attn_gate False
base_model.model.model.layers.38.cross_attn_mlp_gate False
base_model.model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.model.layers.38.input_layernorm.weight False
base_model.model.model.layers.38.mlp.gate_proj.weight False
base_model.model.model.layers.38.mlp.up_proj.weight False
base_model.model.model.layers.38.mlp.down_proj.weight False
base_model.model.model.layers.38.post_attention_layernorm.weight False
base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.k_proj.weight False
base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.o_proj.weight False
base_model.model.model.layers.39.mlp.gate_proj.weight False
base_model.model.model.layers.39.mlp.up_proj.weight False
base_model.model.model.layers.39.mlp.down_proj.weight False
base_model.model.model.layers.39.input_layernorm.weight False
base_model.model.model.layers.39.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.lm_head.weight False
base_model.model.vision_model.class_embedding False
base_model.model.vision_model.patch_embedding.weight False
base_model.model.vision_model.gated_positional_embedding.gate False
base_model.model.vision_model.gated_positional_embedding.embedding False
base_model.model.vision_model.gated_positional_embedding.tile_embedding.weight False
base_model.model.vision_model.pre_tile_positional_embedding.gate False
base_model.model.vision_model.pre_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.post_tile_positional_embedding.gate False
base_model.model.vision_model.post_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.layernorm_pre.weight False
base_model.model.vision_model.layernorm_pre.bias False
base_model.model.vision_model.layernorm_post.weight False
base_model.model.vision_model.layernorm_post.bias False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.8.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.9.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.10.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.11.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.12.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.13.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.14.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.15.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.16.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.17.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.18.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.19.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.20.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.21.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.22.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.23.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.24.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.25.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.26.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.27.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.28.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.29.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.30.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.31.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.gate_attn False
base_model.model.vision_model.global_transformer.layers.0.gate_ffn False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.gate_attn False
base_model.model.vision_model.global_transformer.layers.1.gate_ffn False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.gate_attn False
base_model.model.vision_model.global_transformer.layers.2.gate_ffn False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.gate_attn False
base_model.model.vision_model.global_transformer.layers.3.gate_ffn False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.gate_attn False
base_model.model.vision_model.global_transformer.layers.4.gate_ffn False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.gate_attn False
base_model.model.vision_model.global_transformer.layers.5.gate_ffn False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.gate_attn False
base_model.model.vision_model.global_transformer.layers.6.gate_ffn False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.gate_attn False
base_model.model.vision_model.global_transformer.layers.7.gate_ffn False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.bias False
base_model.model.language_model.model.embed_tokens.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.0.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.0.mlp.up_proj.weight False
base_model.model.language_model.model.layers.0.mlp.down_proj.weight False
base_model.model.language_model.model.layers.0.input_layernorm.weight False
base_model.model.language_model.model.layers.0.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.1.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.1.mlp.up_proj.weight False
base_model.model.language_model.model.layers.1.mlp.down_proj.weight False
base_model.model.language_model.model.layers.1.input_layernorm.weight False
base_model.model.language_model.model.layers.1.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.2.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.2.mlp.up_proj.weight False
base_model.model.language_model.model.layers.2.mlp.down_proj.weight False
base_model.model.language_model.model.layers.2.input_layernorm.weight False
base_model.model.language_model.model.layers.2.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.3.cross_attn_attn_gate False
base_model.model.language_model.model.layers.3.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.3.input_layernorm.weight False
base_model.model.language_model.model.layers.3.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.3.mlp.up_proj.weight False
base_model.model.language_model.model.layers.3.mlp.down_proj.weight False
base_model.model.language_model.model.layers.3.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.4.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.4.mlp.up_proj.weight False
base_model.model.language_model.model.layers.4.mlp.down_proj.weight False
base_model.model.language_model.model.layers.4.input_layernorm.weight False
base_model.model.language_model.model.layers.4.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.5.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.5.mlp.up_proj.weight False
base_model.model.language_model.model.layers.5.mlp.down_proj.weight False
base_model.model.language_model.model.layers.5.input_layernorm.weight False
base_model.model.language_model.model.layers.5.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.6.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.6.mlp.up_proj.weight False
base_model.model.language_model.model.layers.6.mlp.down_proj.weight False
base_model.model.language_model.model.layers.6.input_layernorm.weight False
base_model.model.language_model.model.layers.6.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.7.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.7.mlp.up_proj.weight False
base_model.model.language_model.model.layers.7.mlp.down_proj.weight False
base_model.model.language_model.model.layers.7.input_layernorm.weight False
base_model.model.language_model.model.layers.7.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.8.cross_attn_attn_gate False
base_model.model.language_model.model.layers.8.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.8.input_layernorm.weight False
base_model.model.language_model.model.layers.8.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.8.mlp.up_proj.weight False
base_model.model.language_model.model.layers.8.mlp.down_proj.weight False
base_model.model.language_model.model.layers.8.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.9.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.9.mlp.up_proj.weight False
base_model.model.language_model.model.layers.9.mlp.down_proj.weight False
base_model.model.language_model.model.layers.9.input_layernorm.weight False
base_model.model.language_model.model.layers.9.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.10.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.10.mlp.up_proj.weight False
base_model.model.language_model.model.layers.10.mlp.down_proj.weight False
base_model.model.language_model.model.layers.10.input_layernorm.weight False
base_model.model.language_model.model.layers.10.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.11.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.11.mlp.up_proj.weight False
base_model.model.language_model.model.layers.11.mlp.down_proj.weight False
base_model.model.language_model.model.layers.11.input_layernorm.weight False
base_model.model.language_model.model.layers.11.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.12.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.12.mlp.up_proj.weight False
base_model.model.language_model.model.layers.12.mlp.down_proj.weight False
base_model.model.language_model.model.layers.12.input_layernorm.weight False
base_model.model.language_model.model.layers.12.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.13.cross_attn_attn_gate False
base_model.model.language_model.model.layers.13.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.13.input_layernorm.weight False
base_model.model.language_model.model.layers.13.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.13.mlp.up_proj.weight False
base_model.model.language_model.model.layers.13.mlp.down_proj.weight False
base_model.model.language_model.model.layers.13.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.14.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.14.mlp.up_proj.weight False
base_model.model.language_model.model.layers.14.mlp.down_proj.weight False
base_model.model.language_model.model.layers.14.input_layernorm.weight False
base_model.model.language_model.model.layers.14.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.15.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.15.mlp.up_proj.weight False
base_model.model.language_model.model.layers.15.mlp.down_proj.weight False
base_model.model.language_model.model.layers.15.input_layernorm.weight False
base_model.model.language_model.model.layers.15.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.16.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.16.mlp.up_proj.weight False
base_model.model.language_model.model.layers.16.mlp.down_proj.weight False
base_model.model.language_model.model.layers.16.input_layernorm.weight False
base_model.model.language_model.model.layers.16.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.17.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.17.mlp.up_proj.weight False
base_model.model.language_model.model.layers.17.mlp.down_proj.weight False
base_model.model.language_model.model.layers.17.input_layernorm.weight False
base_model.model.language_model.model.layers.17.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.18.cross_attn_attn_gate False
base_model.model.language_model.model.layers.18.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.18.input_layernorm.weight False
base_model.model.language_model.model.layers.18.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.18.mlp.up_proj.weight False
base_model.model.language_model.model.layers.18.mlp.down_proj.weight False
base_model.model.language_model.model.layers.18.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.19.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.19.mlp.up_proj.weight False
base_model.model.language_model.model.layers.19.mlp.down_proj.weight False
base_model.model.language_model.model.layers.19.input_layernorm.weight False
base_model.model.language_model.model.layers.19.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.20.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.20.mlp.up_proj.weight False
base_model.model.language_model.model.layers.20.mlp.down_proj.weight False
base_model.model.language_model.model.layers.20.input_layernorm.weight False
base_model.model.language_model.model.layers.20.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.21.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.21.mlp.up_proj.weight False
base_model.model.language_model.model.layers.21.mlp.down_proj.weight False
base_model.model.language_model.model.layers.21.input_layernorm.weight False
base_model.model.language_model.model.layers.21.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.22.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.22.mlp.up_proj.weight False
base_model.model.language_model.model.layers.22.mlp.down_proj.weight False
base_model.model.language_model.model.layers.22.input_layernorm.weight False
base_model.model.language_model.model.layers.22.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.23.cross_attn_attn_gate False
base_model.model.language_model.model.layers.23.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.23.input_layernorm.weight False
base_model.model.language_model.model.layers.23.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.23.mlp.up_proj.weight False
base_model.model.language_model.model.layers.23.mlp.down_proj.weight False
base_model.model.language_model.model.layers.23.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.24.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.24.mlp.up_proj.weight False
base_model.model.language_model.model.layers.24.mlp.down_proj.weight False
base_model.model.language_model.model.layers.24.input_layernorm.weight False
base_model.model.language_model.model.layers.24.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.25.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.25.mlp.up_proj.weight False
base_model.model.language_model.model.layers.25.mlp.down_proj.weight False
base_model.model.language_model.model.layers.25.input_layernorm.weight False
base_model.model.language_model.model.layers.25.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.26.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.26.mlp.up_proj.weight False
base_model.model.language_model.model.layers.26.mlp.down_proj.weight False
base_model.model.language_model.model.layers.26.input_layernorm.weight False
base_model.model.language_model.model.layers.26.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.27.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.27.mlp.up_proj.weight False
base_model.model.language_model.model.layers.27.mlp.down_proj.weight False
base_model.model.language_model.model.layers.27.input_layernorm.weight False
base_model.model.language_model.model.layers.27.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.28.cross_attn_attn_gate False
base_model.model.language_model.model.layers.28.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.28.input_layernorm.weight False
base_model.model.language_model.model.layers.28.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.28.mlp.up_proj.weight False
base_model.model.language_model.model.layers.28.mlp.down_proj.weight False
base_model.model.language_model.model.layers.28.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.29.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.29.mlp.up_proj.weight False
base_model.model.language_model.model.layers.29.mlp.down_proj.weight False
base_model.model.language_model.model.layers.29.input_layernorm.weight False
base_model.model.language_model.model.layers.29.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.30.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.30.mlp.up_proj.weight False
base_model.model.language_model.model.layers.30.mlp.down_proj.weight False
base_model.model.language_model.model.layers.30.input_layernorm.weight False
base_model.model.language_model.model.layers.30.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.31.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.31.mlp.up_proj.weight False
base_model.model.language_model.model.layers.31.mlp.down_proj.weight False
base_model.model.language_model.model.layers.31.input_layernorm.weight False
base_model.model.language_model.model.layers.31.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.32.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.32.mlp.up_proj.weight False
base_model.model.language_model.model.layers.32.mlp.down_proj.weight False
base_model.model.language_model.model.layers.32.input_layernorm.weight False
base_model.model.language_model.model.layers.32.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.33.cross_attn_attn_gate False
base_model.model.language_model.model.layers.33.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.33.input_layernorm.weight False
base_model.model.language_model.model.layers.33.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.33.mlp.up_proj.weight False
base_model.model.language_model.model.layers.33.mlp.down_proj.weight False
base_model.model.language_model.model.layers.33.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.34.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.34.mlp.up_proj.weight False
base_model.model.language_model.model.layers.34.mlp.down_proj.weight False
base_model.model.language_model.model.layers.34.input_layernorm.weight False
base_model.model.language_model.model.layers.34.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.35.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.35.mlp.up_proj.weight False
base_model.model.language_model.model.layers.35.mlp.down_proj.weight False
base_model.model.language_model.model.layers.35.input_layernorm.weight False
base_model.model.language_model.model.layers.35.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.36.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.36.mlp.up_proj.weight False
base_model.model.language_model.model.layers.36.mlp.down_proj.weight False
base_model.model.language_model.model.layers.36.input_layernorm.weight False
base_model.model.language_model.model.layers.36.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.37.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.37.mlp.up_proj.weight False
base_model.model.language_model.model.layers.37.mlp.down_proj.weight False
base_model.model.language_model.model.layers.37.input_layernorm.weight False
base_model.model.language_model.model.layers.37.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.38.cross_attn_attn_gate False
base_model.model.language_model.model.layers.38.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.38.input_layernorm.weight False
base_model.model.language_model.model.layers.38.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.38.mlp.up_proj.weight False
base_model.model.language_model.model.layers.38.mlp.down_proj.weight False
base_model.model.language_model.model.layers.38.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.39.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.39.mlp.up_proj.weight False
base_model.model.language_model.model.layers.39.mlp.down_proj.weight False
base_model.model.language_model.model.layers.39.input_layernorm.weight False
base_model.model.language_model.model.layers.39.post_attention_layernorm.weight False
base_model.model.language_model.model.norm.weight False
base_model.model.language_model.lm_head.weight False
base_model.model.multi_modal_projector.weight False
base_model.model.multi_modal_projector.bias False
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.10.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.11.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.12.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.13.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.14.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.15.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.16.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.17.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.4.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.5.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.6.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.7.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.8.cross_attn.v_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.9.self_attn.v_proj.lora_B.default.weight matches: True
MISMATCH: model.layers.0.self_attn.q_proj.lora_A.default.weight
Difference: 0.4782595932483673
MISMATCH: model.layers.0.self_attn.q_proj.lora_B.default.weight
Difference: 0.04695240408182144
MISMATCH: model.layers.0.self_attn.v_proj.lora_A.default.weight
Difference: 1.6793581247329712
MISMATCH: model.layers.0.self_attn.v_proj.lora_B.default.weight
Difference: 0.023460516706109047
MISMATCH: model.layers.1.self_attn.q_proj.lora_A.default.weight
Difference: 0.0670790821313858
MISMATCH: model.layers.1.self_attn.q_proj.lora_B.default.weight
Difference: 0.028232689946889877
MISMATCH: model.layers.1.self_attn.v_proj.lora_A.default.weight
Difference: 0.2821320593357086
MISMATCH: model.layers.1.self_attn.v_proj.lora_B.default.weight
Difference: 0.022568367421627045
MISMATCH: model.layers.2.self_attn.q_proj.lora_A.default.weight
Difference: 0.05406986176967621
MISMATCH: model.layers.2.self_attn.q_proj.lora_B.default.weight
Difference: 0.028164591640233994
MISMATCH: model.layers.2.self_attn.v_proj.lora_A.default.weight
Difference: 0.06212577596306801
MISMATCH: model.layers.2.self_attn.v_proj.lora_B.default.weight
Difference: 0.021822841838002205
MISMATCH: model.layers.3.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031044231727719307
Matched: model.layers.3.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.3.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03111746907234192
Matched: model.layers.3.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.4.self_attn.q_proj.lora_A.default.weight
Difference: 0.0488395169377327
MISMATCH: model.layers.4.self_attn.q_proj.lora_B.default.weight
Difference: 0.03781513124704361
MISMATCH: model.layers.4.self_attn.v_proj.lora_A.default.weight
Difference: 0.07874839007854462
MISMATCH: model.layers.4.self_attn.v_proj.lora_B.default.weight
Difference: 0.022797834128141403
MISMATCH: model.layers.5.self_attn.q_proj.lora_A.default.weight
Difference: 0.05057792365550995
MISMATCH: model.layers.5.self_attn.q_proj.lora_B.default.weight
Difference: 0.029393337666988373
MISMATCH: model.layers.5.self_attn.v_proj.lora_A.default.weight
Difference: 0.058024581521749496
MISMATCH: model.layers.5.self_attn.v_proj.lora_B.default.weight
Difference: 0.020101753994822502
MISMATCH: model.layers.6.self_attn.q_proj.lora_A.default.weight
Difference: 0.05588126555085182
MISMATCH: model.layers.6.self_attn.q_proj.lora_B.default.weight
Difference: 0.027180176228284836
MISMATCH: model.layers.6.self_attn.v_proj.lora_A.default.weight
Difference: 0.05848442763090134
MISMATCH: model.layers.6.self_attn.v_proj.lora_B.default.weight
Difference: 0.021435540169477463
MISMATCH: model.layers.7.self_attn.q_proj.lora_A.default.weight
Difference: 0.05083751305937767
MISMATCH: model.layers.7.self_attn.q_proj.lora_B.default.weight
Difference: 0.03000328689813614
MISMATCH: model.layers.7.self_attn.v_proj.lora_A.default.weight
Difference: 0.06316694617271423
MISMATCH: model.layers.7.self_attn.v_proj.lora_B.default.weight
Difference: 0.022067034617066383
MISMATCH: model.layers.8.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031116731464862823
Matched: model.layers.8.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.8.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031214585527777672
Matched: model.layers.8.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.9.self_attn.q_proj.lora_A.default.weight
Difference: 0.05416996031999588
MISMATCH: model.layers.9.self_attn.q_proj.lora_B.default.weight
Difference: 0.02994222566485405
MISMATCH: model.layers.9.self_attn.v_proj.lora_A.default.weight
Difference: 0.06427434086799622
MISMATCH: model.layers.9.self_attn.v_proj.lora_B.default.weight
Difference: 0.01972036436200142
MISMATCH: model.layers.10.self_attn.q_proj.lora_A.default.weight
Difference: 0.054422713816165924
MISMATCH: model.layers.10.self_attn.q_proj.lora_B.default.weight
Difference: 0.031508881598711014
MISMATCH: model.layers.10.self_attn.v_proj.lora_A.default.weight
Difference: 0.06632694602012634
MISMATCH: model.layers.10.self_attn.v_proj.lora_B.default.weight
Difference: 0.0231583621352911
MISMATCH: model.layers.11.self_attn.q_proj.lora_A.default.weight
Difference: 0.05685538053512573
MISMATCH: model.layers.11.self_attn.q_proj.lora_B.default.weight
Difference: 0.030590632930397987
MISMATCH: model.layers.11.self_attn.v_proj.lora_A.default.weight
Difference: 0.0798254907131195
MISMATCH: model.layers.11.self_attn.v_proj.lora_B.default.weight
Difference: 0.02785596437752247
MISMATCH: model.layers.12.self_attn.q_proj.lora_A.default.weight
Difference: 0.057685598731040955
MISMATCH: model.layers.12.self_attn.q_proj.lora_B.default.weight
Difference: 0.028563421219587326
MISMATCH: model.layers.12.self_attn.v_proj.lora_A.default.weight
Difference: 0.0701470896601677
MISMATCH: model.layers.12.self_attn.v_proj.lora_B.default.weight
Difference: 0.020120324566960335
MISMATCH: model.layers.13.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03116220235824585
Matched: model.layers.13.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.13.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03101229853928089
Matched: model.layers.13.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.14.self_attn.q_proj.lora_A.default.weight
Difference: 0.0580408051609993
MISMATCH: model.layers.14.self_attn.q_proj.lora_B.default.weight
Difference: 0.03896832466125488
MISMATCH: model.layers.14.self_attn.v_proj.lora_A.default.weight
Difference: 0.06726343184709549
MISMATCH: model.layers.14.self_attn.v_proj.lora_B.default.weight
Difference: 0.019899873062968254
MISMATCH: model.layers.15.self_attn.q_proj.lora_A.default.weight
Difference: 0.059807538986206055
MISMATCH: model.layers.15.self_attn.q_proj.lora_B.default.weight
Difference: 0.03234405443072319
MISMATCH: model.layers.15.self_attn.v_proj.lora_A.default.weight
Difference: 0.07019481062889099
MISMATCH: model.layers.15.self_attn.v_proj.lora_B.default.weight
Difference: 0.021429510787129402
MISMATCH: model.layers.16.self_attn.q_proj.lora_A.default.weight
Difference: 0.06829380989074707
MISMATCH: model.layers.16.self_attn.q_proj.lora_B.default.weight
Difference: 0.03260485827922821
MISMATCH: model.layers.16.self_attn.v_proj.lora_A.default.weight
Difference: 0.06997436285018921
MISMATCH: model.layers.16.self_attn.v_proj.lora_B.default.weight
Difference: 0.022144200280308723
MISMATCH: model.layers.17.self_attn.q_proj.lora_A.default.weight
Difference: 0.05988272279500961
MISMATCH: model.layers.17.self_attn.q_proj.lora_B.default.weight
Difference: 0.03169916570186615
MISMATCH: model.layers.17.self_attn.v_proj.lora_A.default.weight
Difference: 0.07227243483066559
MISMATCH: model.layers.17.self_attn.v_proj.lora_B.default.weight
Difference: 0.029613321647047997
MISMATCH: model.layers.18.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031120553612709045
Matched: model.layers.18.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.18.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031112100929021835
Matched: model.layers.18.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.19.self_attn.q_proj.lora_A.default.weight
Difference: 0.0639999657869339
MISMATCH: model.layers.19.self_attn.q_proj.lora_B.default.weight
Difference: 0.034627579152584076
MISMATCH: model.layers.19.self_attn.v_proj.lora_A.default.weight
Difference: 0.08355491608381271
MISMATCH: model.layers.19.self_attn.v_proj.lora_B.default.weight
Difference: 0.023317307233810425
MISMATCH: model.layers.20.self_attn.q_proj.lora_A.default.weight
Difference: 0.05706201493740082
MISMATCH: model.layers.20.self_attn.q_proj.lora_B.default.weight
Difference: 0.054310742765665054
MISMATCH: model.layers.20.self_attn.v_proj.lora_A.default.weight
Difference: 0.07863113284111023
MISMATCH: model.layers.20.self_attn.v_proj.lora_B.default.weight
Difference: 0.0246605072170496
MISMATCH: model.layers.21.self_attn.q_proj.lora_A.default.weight
Difference: 0.06150897964835167
MISMATCH: model.layers.21.self_attn.q_proj.lora_B.default.weight
Difference: 0.0333738774061203
MISMATCH: model.layers.21.self_attn.v_proj.lora_A.default.weight
Difference: 0.07645251601934433
MISMATCH: model.layers.21.self_attn.v_proj.lora_B.default.weight
Difference: 0.022458020597696304
MISMATCH: model.layers.22.self_attn.q_proj.lora_A.default.weight
Difference: 0.06147034093737602
MISMATCH: model.layers.22.self_attn.q_proj.lora_B.default.weight
Difference: 0.06507500261068344
MISMATCH: model.layers.22.self_attn.v_proj.lora_A.default.weight
Difference: 0.07115888595581055
MISMATCH: model.layers.22.self_attn.v_proj.lora_B.default.weight
Difference: 0.02196865901350975
MISMATCH: model.layers.23.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031177865341305733
Matched: model.layers.23.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.23.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03113369457423687
Matched: model.layers.23.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.24.self_attn.q_proj.lora_A.default.weight
Difference: 0.06013406813144684
MISMATCH: model.layers.24.self_attn.q_proj.lora_B.default.weight
Difference: 0.039557166397571564
MISMATCH: model.layers.24.self_attn.v_proj.lora_A.default.weight
Difference: 0.08143454045057297
MISMATCH: model.layers.24.self_attn.v_proj.lora_B.default.weight
Difference: 0.019417639821767807
MISMATCH: model.layers.25.self_attn.q_proj.lora_A.default.weight
Difference: 0.07279325276613235
MISMATCH: model.layers.25.self_attn.q_proj.lora_B.default.weight
Difference: 0.04665140062570572
MISMATCH: model.layers.25.self_attn.v_proj.lora_A.default.weight
Difference: 0.07480034232139587
MISMATCH: model.layers.25.self_attn.v_proj.lora_B.default.weight
Difference: 0.021046016365289688
MISMATCH: model.layers.26.self_attn.q_proj.lora_A.default.weight
Difference: 0.061151355504989624
MISMATCH: model.layers.26.self_attn.q_proj.lora_B.default.weight
Difference: 0.07576151192188263
MISMATCH: model.layers.26.self_attn.v_proj.lora_A.default.weight
Difference: 0.08247270435094833
MISMATCH: model.layers.26.self_attn.v_proj.lora_B.default.weight
Difference: 0.023631084710359573
MISMATCH: model.layers.27.self_attn.q_proj.lora_A.default.weight
Difference: 0.07037743926048279
MISMATCH: model.layers.27.self_attn.q_proj.lora_B.default.weight
Difference: 0.051984477788209915
MISMATCH: model.layers.27.self_attn.v_proj.lora_A.default.weight
Difference: 0.08692701160907745
MISMATCH: model.layers.27.self_attn.v_proj.lora_B.default.weight
Difference: 0.0231477040797472
MISMATCH: model.layers.28.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031233858317136765
Matched: model.layers.28.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.28.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031187446787953377
Matched: model.layers.28.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.29.self_attn.q_proj.lora_A.default.weight
Difference: 0.06985719501972198
MISMATCH: model.layers.29.self_attn.q_proj.lora_B.default.weight
Difference: 0.04849151894450188
MISMATCH: model.layers.29.self_attn.v_proj.lora_A.default.weight
Difference: 0.07898418605327606
MISMATCH: model.layers.29.self_attn.v_proj.lora_B.default.weight
Difference: 0.02336476556956768
MISMATCH: model.layers.30.self_attn.q_proj.lora_A.default.weight
Difference: 0.05491962283849716
MISMATCH: model.layers.30.self_attn.q_proj.lora_B.default.weight
Difference: 0.036576785147190094
MISMATCH: model.layers.30.self_attn.v_proj.lora_A.default.weight
Difference: 0.07134759426116943
MISMATCH: model.layers.30.self_attn.v_proj.lora_B.default.weight
Difference: 0.023211682215332985
MISMATCH: model.layers.31.self_attn.q_proj.lora_A.default.weight
Difference: 0.06184609234333038
MISMATCH: model.layers.31.self_attn.q_proj.lora_B.default.weight
Difference: 0.03524459898471832
MISMATCH: model.layers.31.self_attn.v_proj.lora_A.default.weight
Difference: 0.09106993675231934
MISMATCH: model.layers.31.self_attn.v_proj.lora_B.default.weight
Difference: 0.02254106104373932
MISMATCH: model.layers.32.self_attn.q_proj.lora_A.default.weight
Difference: 0.06071522831916809
MISMATCH: model.layers.32.self_attn.q_proj.lora_B.default.weight
Difference: 0.04070692136883736
MISMATCH: model.layers.32.self_attn.v_proj.lora_A.default.weight
Difference: 0.06804405152797699
MISMATCH: model.layers.32.self_attn.v_proj.lora_B.default.weight
Difference: 0.025932766497135162
MISMATCH: model.layers.33.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031047740951180458
Matched: model.layers.33.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.33.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031217867508530617
Matched: model.layers.33.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.34.self_attn.q_proj.lora_A.default.weight
Difference: 0.059330105781555176
MISMATCH: model.layers.34.self_attn.q_proj.lora_B.default.weight
Difference: 0.06335432827472687
MISMATCH: model.layers.34.self_attn.v_proj.lora_A.default.weight
Difference: 0.08412164449691772
MISMATCH: model.layers.34.self_attn.v_proj.lora_B.default.weight
Difference: 0.025377722457051277
MISMATCH: model.layers.35.self_attn.q_proj.lora_A.default.weight
Difference: 0.0598839707672596
MISMATCH: model.layers.35.self_attn.q_proj.lora_B.default.weight
Difference: 0.05941809341311455
MISMATCH: model.layers.35.self_attn.v_proj.lora_A.default.weight
Difference: 0.09162171185016632
MISMATCH: model.layers.35.self_attn.v_proj.lora_B.default.weight
Difference: 0.023711536079645157
MISMATCH: model.layers.36.self_attn.q_proj.lora_A.default.weight
Difference: 0.05831557512283325
MISMATCH: model.layers.36.self_attn.q_proj.lora_B.default.weight
Difference: 0.054739031940698624
MISMATCH: model.layers.36.self_attn.v_proj.lora_A.default.weight
Difference: 0.08235085755586624
MISMATCH: model.layers.36.self_attn.v_proj.lora_B.default.weight
Difference: 0.02249295637011528
MISMATCH: model.layers.37.self_attn.q_proj.lora_A.default.weight
Difference: 0.07014326006174088
MISMATCH: model.layers.37.self_attn.q_proj.lora_B.default.weight
Difference: 0.03575053811073303
MISMATCH: model.layers.37.self_attn.v_proj.lora_A.default.weight
Difference: 0.07931266725063324
MISMATCH: model.layers.37.self_attn.v_proj.lora_B.default.weight
Difference: 0.036374129354953766
MISMATCH: model.layers.38.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031216749921441078
Matched: model.layers.38.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.38.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031115401536226273
Matched: model.layers.38.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.39.self_attn.q_proj.lora_A.default.weight
Difference: 0.1046404168009758
MISMATCH: model.layers.39.self_attn.q_proj.lora_B.default.weight
Difference: 0.19028238952159882
MISMATCH: model.layers.39.self_attn.v_proj.lora_A.default.weight
Difference: 0.0961131602525711
MISMATCH: model.layers.39.self_attn.v_proj.lora_B.default.weight
Difference: 0.03365113586187363
Some LoRA layers did not match.
bbbbb
cuda:0
Length of the updated dataset: 560
Traceback (most recent call last):
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/omar.py", line 573, in <module>
    generated_code = generate_tikz_code(image, caption)
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/omar.py", line 463, in generate_tikz_code
    output = model.generate(**inputs, max_new_tokens=1000)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/peft_model.py", line 817, in generate
    return self.get_base_model().generate(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/models/mllama/modeling_mllama.py", line 2098, in forward
    vision_outputs = self.vision_model(
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/transformers/models/mllama/modeling_mllama.py", line 1489, in forward
    intermediate_hidden_states = torch.stack(all_intermediate_hidden_states, dim=-1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.01 GiB. GPU 0 has a total capacity of 79.15 GiB of which 619.25 MiB is free. Including non-PyTorch memory, this process has 78.53 GiB memory in use. Of the allocated memory 77.57 GiB is allocated by PyTorch, and 479.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
