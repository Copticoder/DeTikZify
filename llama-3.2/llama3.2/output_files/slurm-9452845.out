Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:07,  1.90s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:02,  1.17it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:02<00:01,  1.90it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:02<00:00,  2.70it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:02<00:00,  3.64it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]
Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]Loading checkpoint shards:  11%|█         | 1/9 [00:22<02:57, 22.15s/it]Loading checkpoint shards:  22%|██▏       | 2/9 [00:43<02:32, 21.72s/it]Loading checkpoint shards:  33%|███▎      | 3/9 [01:33<03:27, 34.58s/it]Loading checkpoint shards:  44%|████▍     | 4/9 [01:55<02:27, 29.49s/it]Loading checkpoint shards:  56%|█████▌    | 5/9 [02:15<01:45, 26.36s/it]Loading checkpoint shards:  67%|██████▋   | 6/9 [02:37<01:14, 24.75s/it]Loading checkpoint shards:  78%|███████▊  | 7/9 [04:07<01:32, 46.20s/it]Loading checkpoint shards:  89%|████████▉ | 8/9 [07:31<01:36, 96.45s/it]Loading checkpoint shards: 100%|██████████| 9/9 [09:31<00:00, 103.51s/it]Loading checkpoint shards: 100%|██████████| 9/9 [09:31<00:00, 63.45s/it] 
Some weights of the model checkpoint at /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant were not used when initializing MllamaForCausalLM: ['model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.13.cross_attn.q_proj.base_layer.weight', 'model.layers.13.cross_attn.q_proj.lora_A.default.weight', 'model.layers.13.cross_attn.q_proj.lora_B.default.weight', 'model.layers.13.cross_attn.v_proj.base_layer.weight', 'model.layers.13.cross_attn.v_proj.lora_A.default.weight', 'model.layers.13.cross_attn.v_proj.lora_B.default.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.cross_attn.q_proj.base_layer.weight', 'model.layers.18.cross_attn.q_proj.lora_A.default.weight', 'model.layers.18.cross_attn.q_proj.lora_B.default.weight', 'model.layers.18.cross_attn.v_proj.base_layer.weight', 'model.layers.18.cross_attn.v_proj.lora_A.default.weight', 'model.layers.18.cross_attn.v_proj.lora_B.default.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.cross_attn.q_proj.base_layer.weight', 'model.layers.23.cross_attn.q_proj.lora_A.default.weight', 'model.layers.23.cross_attn.q_proj.lora_B.default.weight', 'model.layers.23.cross_attn.v_proj.base_layer.weight', 'model.layers.23.cross_attn.v_proj.lora_A.default.weight', 'model.layers.23.cross_attn.v_proj.lora_B.default.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.cross_attn.q_proj.base_layer.weight', 'model.layers.28.cross_attn.q_proj.lora_A.default.weight', 'model.layers.28.cross_attn.q_proj.lora_B.default.weight', 'model.layers.28.cross_attn.v_proj.base_layer.weight', 'model.layers.28.cross_attn.v_proj.lora_A.default.weight', 'model.layers.28.cross_attn.v_proj.lora_B.default.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.3.cross_attn.q_proj.base_layer.weight', 'model.layers.3.cross_attn.q_proj.lora_A.default.weight', 'model.layers.3.cross_attn.q_proj.lora_B.default.weight', 'model.layers.3.cross_attn.v_proj.base_layer.weight', 'model.layers.3.cross_attn.v_proj.lora_A.default.weight', 'model.layers.3.cross_attn.v_proj.lora_B.default.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.lora_A.default.weight', 'model.layers.32.self_attn.q_proj.lora_B.default.weight', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.lora_A.default.weight', 'model.layers.32.self_attn.v_proj.lora_B.default.weight', 'model.layers.33.cross_attn.q_proj.base_layer.weight', 'model.layers.33.cross_attn.q_proj.lora_A.default.weight', 'model.layers.33.cross_attn.q_proj.lora_B.default.weight', 'model.layers.33.cross_attn.v_proj.base_layer.weight', 'model.layers.33.cross_attn.v_proj.lora_A.default.weight', 'model.layers.33.cross_attn.v_proj.lora_B.default.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.lora_A.default.weight', 'model.layers.34.self_attn.q_proj.lora_B.default.weight', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.lora_A.default.weight', 'model.layers.34.self_attn.v_proj.lora_B.default.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.lora_A.default.weight', 'model.layers.35.self_attn.q_proj.lora_B.default.weight', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.lora_A.default.weight', 'model.layers.35.self_attn.v_proj.lora_B.default.weight', 'model.layers.36.self_attn.q_proj.base_layer.weight', 'model.layers.36.self_attn.q_proj.lora_A.default.weight', 'model.layers.36.self_attn.q_proj.lora_B.default.weight', 'model.layers.36.self_attn.v_proj.base_layer.weight', 'model.layers.36.self_attn.v_proj.lora_A.default.weight', 'model.layers.36.self_attn.v_proj.lora_B.default.weight', 'model.layers.37.self_attn.q_proj.base_layer.weight', 'model.layers.37.self_attn.q_proj.lora_A.default.weight', 'model.layers.37.self_attn.q_proj.lora_B.default.weight', 'model.layers.37.self_attn.v_proj.base_layer.weight', 'model.layers.37.self_attn.v_proj.lora_A.default.weight', 'model.layers.37.self_attn.v_proj.lora_B.default.weight', 'model.layers.38.cross_attn.q_proj.base_layer.weight', 'model.layers.38.cross_attn.q_proj.lora_A.default.weight', 'model.layers.38.cross_attn.q_proj.lora_B.default.weight', 'model.layers.38.cross_attn.v_proj.base_layer.weight', 'model.layers.38.cross_attn.v_proj.lora_A.default.weight', 'model.layers.38.cross_attn.v_proj.lora_B.default.weight', 'model.layers.39.self_attn.q_proj.base_layer.weight', 'model.layers.39.self_attn.q_proj.lora_A.default.weight', 'model.layers.39.self_attn.q_proj.lora_B.default.weight', 'model.layers.39.self_attn.v_proj.base_layer.weight', 'model.layers.39.self_attn.v_proj.lora_A.default.weight', 'model.layers.39.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.8.cross_attn.q_proj.base_layer.weight', 'model.layers.8.cross_attn.q_proj.lora_A.default.weight', 'model.layers.8.cross_attn.q_proj.lora_B.default.weight', 'model.layers.8.cross_attn.v_proj.base_layer.weight', 'model.layers.8.cross_attn.v_proj.lora_A.default.weight', 'model.layers.8.cross_attn.v_proj.lora_B.default.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight']
- This IS expected if you are initializing MllamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MllamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of MllamaForCausalLM were not initialized from the model checkpoint at /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant and are newly initialized: ['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.cross_attn.q_proj.weight', 'model.layers.13.cross_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.cross_attn.q_proj.weight', 'model.layers.18.cross_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.cross_attn.q_proj.weight', 'model.layers.23.cross_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.cross_attn.q_proj.weight', 'model.layers.28.cross_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.cross_attn.q_proj.weight', 'model.layers.3.cross_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.cross_attn.q_proj.weight', 'model.layers.33.cross_attn.v_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.cross_attn.q_proj.weight', 'model.layers.38.cross_attn.v_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.cross_attn.q_proj.weight', 'model.layers.8.cross_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/mapping.py:172: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from '/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant' to 'mylesgoose/Llama-3.2-11B-Vision-Instruct'. Please ensure that the correct base model is loaded when loading this checkpoint.
  warnings.warn(
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.cross_attn_attn_gate False
base_model.model.model.layers.3.cross_attn_mlp_gate False
base_model.model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.cross_attn_attn_gate False
base_model.model.model.layers.8.cross_attn_mlp_gate False
base_model.model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.cross_attn_attn_gate False
base_model.model.model.layers.13.cross_attn_mlp_gate False
base_model.model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.cross_attn_attn_gate False
base_model.model.model.layers.18.cross_attn_mlp_gate False
base_model.model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.cross_attn_attn_gate False
base_model.model.model.layers.23.cross_attn_mlp_gate False
base_model.model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.cross_attn_attn_gate False
base_model.model.model.layers.28.cross_attn_mlp_gate False
base_model.model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.k_proj.weight False
base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.o_proj.weight False
base_model.model.model.layers.32.mlp.gate_proj.weight False
base_model.model.model.layers.32.mlp.up_proj.weight False
base_model.model.model.layers.32.mlp.down_proj.weight False
base_model.model.model.layers.32.input_layernorm.weight False
base_model.model.model.layers.32.post_attention_layernorm.weight False
base_model.model.model.layers.33.cross_attn_attn_gate False
base_model.model.model.layers.33.cross_attn_mlp_gate False
base_model.model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.model.layers.33.input_layernorm.weight False
base_model.model.model.layers.33.mlp.gate_proj.weight False
base_model.model.model.layers.33.mlp.up_proj.weight False
base_model.model.model.layers.33.mlp.down_proj.weight False
base_model.model.model.layers.33.post_attention_layernorm.weight False
base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.k_proj.weight False
base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.o_proj.weight False
base_model.model.model.layers.34.mlp.gate_proj.weight False
base_model.model.model.layers.34.mlp.up_proj.weight False
base_model.model.model.layers.34.mlp.down_proj.weight False
base_model.model.model.layers.34.input_layernorm.weight False
base_model.model.model.layers.34.post_attention_layernorm.weight False
base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.k_proj.weight False
base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.o_proj.weight False
base_model.model.model.layers.35.mlp.gate_proj.weight False
base_model.model.model.layers.35.mlp.up_proj.weight False
base_model.model.model.layers.35.mlp.down_proj.weight False
base_model.model.model.layers.35.input_layernorm.weight False
base_model.model.model.layers.35.post_attention_layernorm.weight False
base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.k_proj.weight False
base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.o_proj.weight False
base_model.model.model.layers.36.mlp.gate_proj.weight False
base_model.model.model.layers.36.mlp.up_proj.weight False
base_model.model.model.layers.36.mlp.down_proj.weight False
base_model.model.model.layers.36.input_layernorm.weight False
base_model.model.model.layers.36.post_attention_layernorm.weight False
base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.k_proj.weight False
base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.o_proj.weight False
base_model.model.model.layers.37.mlp.gate_proj.weight False
base_model.model.model.layers.37.mlp.up_proj.weight False
base_model.model.model.layers.37.mlp.down_proj.weight False
base_model.model.model.layers.37.input_layernorm.weight False
base_model.model.model.layers.37.post_attention_layernorm.weight False
base_model.model.model.layers.38.cross_attn_attn_gate False
base_model.model.model.layers.38.cross_attn_mlp_gate False
base_model.model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.model.layers.38.input_layernorm.weight False
base_model.model.model.layers.38.mlp.gate_proj.weight False
base_model.model.model.layers.38.mlp.up_proj.weight False
base_model.model.model.layers.38.mlp.down_proj.weight False
base_model.model.model.layers.38.post_attention_layernorm.weight False
base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.k_proj.weight False
base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.o_proj.weight False
base_model.model.model.layers.39.mlp.gate_proj.weight False
base_model.model.model.layers.39.mlp.up_proj.weight False
base_model.model.model.layers.39.mlp.down_proj.weight False
base_model.model.model.layers.39.input_layernorm.weight False
base_model.model.model.layers.39.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.lm_head.weight False
base_model.model.vision_model.class_embedding False
base_model.model.vision_model.patch_embedding.weight False
base_model.model.vision_model.gated_positional_embedding.gate False
base_model.model.vision_model.gated_positional_embedding.embedding False
base_model.model.vision_model.gated_positional_embedding.tile_embedding.weight False
base_model.model.vision_model.pre_tile_positional_embedding.gate False
base_model.model.vision_model.pre_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.post_tile_positional_embedding.gate False
base_model.model.vision_model.post_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.layernorm_pre.weight False
base_model.model.vision_model.layernorm_pre.bias False
base_model.model.vision_model.layernorm_post.weight False
base_model.model.vision_model.layernorm_post.bias False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.8.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.9.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.10.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.11.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.12.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.13.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.14.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.15.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.16.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.17.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.18.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.19.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.20.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.21.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.22.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.23.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.24.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.25.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.26.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.27.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.28.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.29.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.30.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.31.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.gate_attn False
base_model.model.vision_model.global_transformer.layers.0.gate_ffn False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.gate_attn False
base_model.model.vision_model.global_transformer.layers.1.gate_ffn False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.gate_attn False
base_model.model.vision_model.global_transformer.layers.2.gate_ffn False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.gate_attn False
base_model.model.vision_model.global_transformer.layers.3.gate_ffn False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.gate_attn False
base_model.model.vision_model.global_transformer.layers.4.gate_ffn False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.gate_attn False
base_model.model.vision_model.global_transformer.layers.5.gate_ffn False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.gate_attn False
base_model.model.vision_model.global_transformer.layers.6.gate_ffn False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.gate_attn False
base_model.model.vision_model.global_transformer.layers.7.gate_ffn False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.bias False
base_model.model.language_model.model.embed_tokens.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.0.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.0.mlp.up_proj.weight False
base_model.model.language_model.model.layers.0.mlp.down_proj.weight False
base_model.model.language_model.model.layers.0.input_layernorm.weight False
base_model.model.language_model.model.layers.0.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.1.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.1.mlp.up_proj.weight False
base_model.model.language_model.model.layers.1.mlp.down_proj.weight False
base_model.model.language_model.model.layers.1.input_layernorm.weight False
base_model.model.language_model.model.layers.1.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.2.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.2.mlp.up_proj.weight False
base_model.model.language_model.model.layers.2.mlp.down_proj.weight False
base_model.model.language_model.model.layers.2.input_layernorm.weight False
base_model.model.language_model.model.layers.2.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.3.cross_attn_attn_gate False
base_model.model.language_model.model.layers.3.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.3.input_layernorm.weight False
base_model.model.language_model.model.layers.3.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.3.mlp.up_proj.weight False
base_model.model.language_model.model.layers.3.mlp.down_proj.weight False
base_model.model.language_model.model.layers.3.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.4.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.4.mlp.up_proj.weight False
base_model.model.language_model.model.layers.4.mlp.down_proj.weight False
base_model.model.language_model.model.layers.4.input_layernorm.weight False
base_model.model.language_model.model.layers.4.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.5.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.5.mlp.up_proj.weight False
base_model.model.language_model.model.layers.5.mlp.down_proj.weight False
base_model.model.language_model.model.layers.5.input_layernorm.weight False
base_model.model.language_model.model.layers.5.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.6.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.6.mlp.up_proj.weight False
base_model.model.language_model.model.layers.6.mlp.down_proj.weight False
base_model.model.language_model.model.layers.6.input_layernorm.weight False
base_model.model.language_model.model.layers.6.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.7.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.7.mlp.up_proj.weight False
base_model.model.language_model.model.layers.7.mlp.down_proj.weight False
base_model.model.language_model.model.layers.7.input_layernorm.weight False
base_model.model.language_model.model.layers.7.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.8.cross_attn_attn_gate False
base_model.model.language_model.model.layers.8.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.8.input_layernorm.weight False
base_model.model.language_model.model.layers.8.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.8.mlp.up_proj.weight False
base_model.model.language_model.model.layers.8.mlp.down_proj.weight False
base_model.model.language_model.model.layers.8.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.9.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.9.mlp.up_proj.weight False
base_model.model.language_model.model.layers.9.mlp.down_proj.weight False
base_model.model.language_model.model.layers.9.input_layernorm.weight False
base_model.model.language_model.model.layers.9.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.10.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.10.mlp.up_proj.weight False
base_model.model.language_model.model.layers.10.mlp.down_proj.weight False
base_model.model.language_model.model.layers.10.input_layernorm.weight False
base_model.model.language_model.model.layers.10.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.11.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.11.mlp.up_proj.weight False
base_model.model.language_model.model.layers.11.mlp.down_proj.weight False
base_model.model.language_model.model.layers.11.input_layernorm.weight False
base_model.model.language_model.model.layers.11.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.12.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.12.mlp.up_proj.weight False
base_model.model.language_model.model.layers.12.mlp.down_proj.weight False
base_model.model.language_model.model.layers.12.input_layernorm.weight False
base_model.model.language_model.model.layers.12.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.13.cross_attn_attn_gate False
base_model.model.language_model.model.layers.13.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.13.input_layernorm.weight False
base_model.model.language_model.model.layers.13.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.13.mlp.up_proj.weight False
base_model.model.language_model.model.layers.13.mlp.down_proj.weight False
base_model.model.language_model.model.layers.13.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.14.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.14.mlp.up_proj.weight False
base_model.model.language_model.model.layers.14.mlp.down_proj.weight False
base_model.model.language_model.model.layers.14.input_layernorm.weight False
base_model.model.language_model.model.layers.14.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.15.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.15.mlp.up_proj.weight False
base_model.model.language_model.model.layers.15.mlp.down_proj.weight False
base_model.model.language_model.model.layers.15.input_layernorm.weight False
base_model.model.language_model.model.layers.15.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.16.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.16.mlp.up_proj.weight False
base_model.model.language_model.model.layers.16.mlp.down_proj.weight False
base_model.model.language_model.model.layers.16.input_layernorm.weight False
base_model.model.language_model.model.layers.16.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.17.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.17.mlp.up_proj.weight False
base_model.model.language_model.model.layers.17.mlp.down_proj.weight False
base_model.model.language_model.model.layers.17.input_layernorm.weight False
base_model.model.language_model.model.layers.17.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.18.cross_attn_attn_gate False
base_model.model.language_model.model.layers.18.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.18.input_layernorm.weight False
base_model.model.language_model.model.layers.18.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.18.mlp.up_proj.weight False
base_model.model.language_model.model.layers.18.mlp.down_proj.weight False
base_model.model.language_model.model.layers.18.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.19.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.19.mlp.up_proj.weight False
base_model.model.language_model.model.layers.19.mlp.down_proj.weight False
base_model.model.language_model.model.layers.19.input_layernorm.weight False
base_model.model.language_model.model.layers.19.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.20.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.20.mlp.up_proj.weight False
base_model.model.language_model.model.layers.20.mlp.down_proj.weight False
base_model.model.language_model.model.layers.20.input_layernorm.weight False
base_model.model.language_model.model.layers.20.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.21.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.21.mlp.up_proj.weight False
base_model.model.language_model.model.layers.21.mlp.down_proj.weight False
base_model.model.language_model.model.layers.21.input_layernorm.weight False
base_model.model.language_model.model.layers.21.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.22.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.22.mlp.up_proj.weight False
base_model.model.language_model.model.layers.22.mlp.down_proj.weight False
base_model.model.language_model.model.layers.22.input_layernorm.weight False
base_model.model.language_model.model.layers.22.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.23.cross_attn_attn_gate False
base_model.model.language_model.model.layers.23.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.23.input_layernorm.weight False
base_model.model.language_model.model.layers.23.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.23.mlp.up_proj.weight False
base_model.model.language_model.model.layers.23.mlp.down_proj.weight False
base_model.model.language_model.model.layers.23.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.24.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.24.mlp.up_proj.weight False
base_model.model.language_model.model.layers.24.mlp.down_proj.weight False
base_model.model.language_model.model.layers.24.input_layernorm.weight False
base_model.model.language_model.model.layers.24.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.25.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.25.mlp.up_proj.weight False
base_model.model.language_model.model.layers.25.mlp.down_proj.weight False
base_model.model.language_model.model.layers.25.input_layernorm.weight False
base_model.model.language_model.model.layers.25.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.26.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.26.mlp.up_proj.weight False
base_model.model.language_model.model.layers.26.mlp.down_proj.weight False
base_model.model.language_model.model.layers.26.input_layernorm.weight False
base_model.model.language_model.model.layers.26.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.27.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.27.mlp.up_proj.weight False
base_model.model.language_model.model.layers.27.mlp.down_proj.weight False
base_model.model.language_model.model.layers.27.input_layernorm.weight False
base_model.model.language_model.model.layers.27.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.28.cross_attn_attn_gate False
base_model.model.language_model.model.layers.28.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.28.input_layernorm.weight False
base_model.model.language_model.model.layers.28.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.28.mlp.up_proj.weight False
base_model.model.language_model.model.layers.28.mlp.down_proj.weight False
base_model.model.language_model.model.layers.28.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.29.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.29.mlp.up_proj.weight False
base_model.model.language_model.model.layers.29.mlp.down_proj.weight False
base_model.model.language_model.model.layers.29.input_layernorm.weight False
base_model.model.language_model.model.layers.29.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.30.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.30.mlp.up_proj.weight False
base_model.model.language_model.model.layers.30.mlp.down_proj.weight False
base_model.model.language_model.model.layers.30.input_layernorm.weight False
base_model.model.language_model.model.layers.30.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.31.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.31.mlp.up_proj.weight False
base_model.model.language_model.model.layers.31.mlp.down_proj.weight False
base_model.model.language_model.model.layers.31.input_layernorm.weight False
base_model.model.language_model.model.layers.31.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.32.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.32.mlp.up_proj.weight False
base_model.model.language_model.model.layers.32.mlp.down_proj.weight False
base_model.model.language_model.model.layers.32.input_layernorm.weight False
base_model.model.language_model.model.layers.32.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.33.cross_attn_attn_gate False
base_model.model.language_model.model.layers.33.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.33.input_layernorm.weight False
base_model.model.language_model.model.layers.33.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.33.mlp.up_proj.weight False
base_model.model.language_model.model.layers.33.mlp.down_proj.weight False
base_model.model.language_model.model.layers.33.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.34.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.34.mlp.up_proj.weight False
base_model.model.language_model.model.layers.34.mlp.down_proj.weight False
base_model.model.language_model.model.layers.34.input_layernorm.weight False
base_model.model.language_model.model.layers.34.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.35.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.35.mlp.up_proj.weight False
base_model.model.language_model.model.layers.35.mlp.down_proj.weight False
base_model.model.language_model.model.layers.35.input_layernorm.weight False
base_model.model.language_model.model.layers.35.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.36.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.36.mlp.up_proj.weight False
base_model.model.language_model.model.layers.36.mlp.down_proj.weight False
base_model.model.language_model.model.layers.36.input_layernorm.weight False
base_model.model.language_model.model.layers.36.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.37.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.37.mlp.up_proj.weight False
base_model.model.language_model.model.layers.37.mlp.down_proj.weight False
base_model.model.language_model.model.layers.37.input_layernorm.weight False
base_model.model.language_model.model.layers.37.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.38.cross_attn_attn_gate False
base_model.model.language_model.model.layers.38.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.38.input_layernorm.weight False
base_model.model.language_model.model.layers.38.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.38.mlp.up_proj.weight False
base_model.model.language_model.model.layers.38.mlp.down_proj.weight False
base_model.model.language_model.model.layers.38.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.39.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.39.mlp.up_proj.weight False
base_model.model.language_model.model.layers.39.mlp.down_proj.weight False
base_model.model.language_model.model.layers.39.input_layernorm.weight False
base_model.model.language_model.model.layers.39.post_attention_layernorm.weight False
base_model.model.language_model.model.norm.weight False
base_model.model.language_model.lm_head.weight False
base_model.model.multi_modal_projector.weight False
base_model.model.multi_modal_projector.bias False
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00001-of-00009.safetensors
Loading weights for: base_model.model.model.embed_tokens.weight
Loading weights for: base_model.model.model.layers.0.input_layernorm.weight
Loading weights for: base_model.model.model.layers.0.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.0.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.0.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.0.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.0.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.0.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.1.input_layernorm.weight
Loading weights for: base_model.model.model.layers.1.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.1.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.1.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.1.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.1.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.1.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.2.input_layernorm.weight
Loading weights for: base_model.model.model.layers.2.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.2.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.2.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.2.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.2.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.2.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.3.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.3.input_layernorm.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00002-of-00009.safetensors
Loading weights for: base_model.model.model.layers.3.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.3.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.3.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.3.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.4.input_layernorm.weight
Loading weights for: base_model.model.model.layers.4.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.4.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.4.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.4.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.4.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.4.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.5.input_layernorm.weight
Loading weights for: base_model.model.model.layers.5.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.5.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.5.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.5.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.5.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.5.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.6.input_layernorm.weight
Loading weights for: base_model.model.model.layers.6.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.6.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.6.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.6.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.6.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.6.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.7.input_layernorm.weight
Loading weights for: base_model.model.model.layers.7.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.7.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.7.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.7.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.7.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.7.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.8.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.8.input_layernorm.weight
Loading weights for: base_model.model.model.layers.8.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.8.mlp.up_proj.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00003-of-00009.safetensors
Loading weights for: base_model.model.model.layers.10.input_layernorm.weight
Loading weights for: base_model.model.model.layers.10.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.10.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.10.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.10.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.10.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.10.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.11.input_layernorm.weight
Loading weights for: base_model.model.model.layers.11.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.11.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.11.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.11.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.11.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.11.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.12.input_layernorm.weight
Loading weights for: base_model.model.model.layers.12.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.12.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.12.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.12.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.12.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.12.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.13.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.13.input_layernorm.weight
Loading weights for: base_model.model.model.layers.13.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.13.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.13.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.13.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.14.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.14.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.8.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.9.input_layernorm.weight
Loading weights for: base_model.model.model.layers.9.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.9.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.9.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.9.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.9.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.9.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00004-of-00009.safetensors
Loading weights for: base_model.model.model.layers.14.input_layernorm.weight
Loading weights for: base_model.model.model.layers.14.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.14.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.14.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.14.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.15.input_layernorm.weight
Loading weights for: base_model.model.model.layers.15.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.15.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.15.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.15.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.15.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.15.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.16.input_layernorm.weight
Loading weights for: base_model.model.model.layers.16.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.16.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.16.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.16.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.16.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.16.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.17.input_layernorm.weight
Loading weights for: base_model.model.model.layers.17.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.17.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.17.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.17.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.17.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.17.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.18.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.18.input_layernorm.weight
Loading weights for: base_model.model.model.layers.18.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.18.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.18.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.18.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.19.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.19.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.19.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.19.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00005-of-00009.safetensors
Loading weights for: base_model.model.model.layers.19.input_layernorm.weight
Loading weights for: base_model.model.model.layers.19.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.19.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.20.input_layernorm.weight
Loading weights for: base_model.model.model.layers.20.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.20.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.20.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.20.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.20.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.20.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.21.input_layernorm.weight
Loading weights for: base_model.model.model.layers.21.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.21.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.21.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.21.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.21.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.21.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.22.input_layernorm.weight
Loading weights for: base_model.model.model.layers.22.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.22.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.22.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.22.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.22.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.22.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.23.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.23.input_layernorm.weight
Loading weights for: base_model.model.model.layers.23.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.23.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.23.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.23.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.24.input_layernorm.weight
Loading weights for: base_model.model.model.layers.24.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.24.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.24.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.24.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.24.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.24.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.25.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00006-of-00009.safetensors
Loading weights for: base_model.model.model.layers.25.input_layernorm.weight
Loading weights for: base_model.model.model.layers.25.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.25.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.25.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.25.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.26.input_layernorm.weight
Loading weights for: base_model.model.model.layers.26.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.26.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.26.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.26.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.26.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.26.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.27.input_layernorm.weight
Loading weights for: base_model.model.model.layers.27.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.27.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.27.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.27.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.27.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.27.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.28.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.28.input_layernorm.weight
Loading weights for: base_model.model.model.layers.28.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.28.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.28.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.28.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.29.input_layernorm.weight
Loading weights for: base_model.model.model.layers.29.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.29.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.29.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.29.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.29.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.29.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.30.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.30.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.30.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.30.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00007-of-00009.safetensors
Loading weights for: base_model.model.model.layers.30.input_layernorm.weight
Loading weights for: base_model.model.model.layers.30.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.30.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.31.input_layernorm.weight
Loading weights for: base_model.model.model.layers.31.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.31.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.31.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.31.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.31.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.31.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.32.input_layernorm.weight
Loading weights for: base_model.model.model.layers.32.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.32.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.32.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.32.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.32.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.32.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.33.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.33.input_layernorm.weight
Loading weights for: base_model.model.model.layers.33.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.33.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.33.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.33.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.34.input_layernorm.weight
Loading weights for: base_model.model.model.layers.34.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.34.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.34.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.34.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.34.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.34.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.35.input_layernorm.weight
Loading weights for: base_model.model.model.layers.35.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.35.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.35.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.35.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.35.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.35.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.36.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00008-of-00009.safetensors
Loading weights for: base_model.model.model.layers.36.input_layernorm.weight
Loading weights for: base_model.model.model.layers.36.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.36.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.36.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.36.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.37.input_layernorm.weight
Loading weights for: base_model.model.model.layers.37.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.37.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.37.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.37.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.37.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.37.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.k_norm.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_norm.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn_attn_gate
Loading weights for: base_model.model.model.layers.38.cross_attn_mlp_gate
Loading weights for: base_model.model.model.layers.38.input_layernorm.weight
Loading weights for: base_model.model.model.layers.38.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.38.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.38.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.38.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.39.input_layernorm.weight
Loading weights for: base_model.model.model.layers.39.mlp.down_proj.weight
Loading weights for: base_model.model.model.layers.39.mlp.gate_proj.weight
Loading weights for: base_model.model.model.layers.39.mlp.up_proj.weight
Loading weights for: base_model.model.model.layers.39.post_attention_layernorm.weight
Loading weights for: base_model.model.model.layers.39.self_attn.k_proj.weight
Loading weights for: base_model.model.model.layers.39.self_attn.o_proj.weight
Loading weights for: base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight
Loading weights for: base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.norm.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_captions_noquant/model-00009-of-00009.safetensors
Loading weights for: base_model.model.lm_head.weight
Missing in checkpoint: vision_model.class_embedding
Missing in checkpoint: vision_model.patch_embedding.weight
Missing in checkpoint: vision_model.gated_positional_embedding.gate
Missing in checkpoint: vision_model.gated_positional_embedding.embedding
Missing in checkpoint: vision_model.gated_positional_embedding.tile_embedding.weight
Missing in checkpoint: vision_model.pre_tile_positional_embedding.gate
Missing in checkpoint: vision_model.pre_tile_positional_embedding.embedding.weight
Missing in checkpoint: vision_model.post_tile_positional_embedding.gate
Missing in checkpoint: vision_model.post_tile_positional_embedding.embedding.weight
Missing in checkpoint: vision_model.layernorm_pre.weight
Missing in checkpoint: vision_model.layernorm_pre.bias
Missing in checkpoint: vision_model.layernorm_post.weight
Missing in checkpoint: vision_model.layernorm_post.bias
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.0.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.0.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.0.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.0.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.0.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.0.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.0.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.0.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.0.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.1.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.1.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.1.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.1.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.1.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.1.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.1.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.1.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.1.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.2.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.2.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.2.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.2.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.2.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.2.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.2.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.2.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.2.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.3.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.3.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.3.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.3.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.3.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.3.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.3.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.3.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.3.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.4.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.4.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.4.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.4.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.4.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.4.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.4.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.4.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.4.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.5.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.5.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.5.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.5.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.5.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.5.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.5.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.5.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.5.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.6.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.6.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.6.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.6.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.6.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.6.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.6.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.6.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.6.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.7.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.7.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.7.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.7.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.7.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.7.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.7.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.7.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.7.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.8.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.8.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.8.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.8.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.8.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.8.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.8.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.8.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.8.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.9.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.9.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.9.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.9.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.9.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.9.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.9.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.9.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.9.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.10.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.10.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.10.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.10.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.10.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.10.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.10.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.10.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.10.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.11.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.11.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.11.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.11.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.11.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.11.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.11.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.11.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.11.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.12.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.12.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.12.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.12.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.12.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.12.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.12.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.12.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.12.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.13.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.13.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.13.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.13.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.13.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.13.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.13.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.13.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.13.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.14.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.14.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.14.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.14.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.14.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.14.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.14.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.14.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.14.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.15.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.15.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.15.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.15.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.15.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.15.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.15.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.15.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.15.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.16.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.16.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.16.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.16.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.16.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.16.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.16.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.16.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.16.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.17.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.17.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.17.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.17.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.17.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.17.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.17.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.17.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.17.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.18.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.18.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.18.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.18.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.18.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.18.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.18.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.18.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.18.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.19.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.19.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.19.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.19.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.19.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.19.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.19.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.19.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.19.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.20.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.20.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.20.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.20.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.20.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.20.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.20.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.20.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.20.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.21.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.21.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.21.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.21.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.21.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.21.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.21.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.21.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.21.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.22.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.22.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.22.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.22.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.22.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.22.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.22.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.22.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.22.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.23.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.23.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.23.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.23.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.23.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.23.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.23.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.23.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.23.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.24.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.24.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.24.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.24.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.24.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.24.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.24.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.24.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.24.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.25.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.25.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.25.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.25.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.25.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.25.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.25.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.25.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.25.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.26.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.26.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.26.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.26.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.26.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.26.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.26.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.26.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.26.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.27.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.27.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.27.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.27.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.27.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.27.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.27.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.27.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.27.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.28.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.28.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.28.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.28.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.28.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.28.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.28.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.28.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.28.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.29.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.29.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.29.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.29.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.29.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.29.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.29.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.29.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.29.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.30.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.30.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.30.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.30.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.30.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.30.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.30.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.30.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.30.post_attention_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.k_proj.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.transformer.layers.31.self_attn.o_proj.weight
Missing in checkpoint: vision_model.transformer.layers.31.mlp.fc1.weight
Missing in checkpoint: vision_model.transformer.layers.31.mlp.fc1.bias
Missing in checkpoint: vision_model.transformer.layers.31.mlp.fc2.weight
Missing in checkpoint: vision_model.transformer.layers.31.mlp.fc2.bias
Missing in checkpoint: vision_model.transformer.layers.31.input_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.31.input_layernorm.bias
Missing in checkpoint: vision_model.transformer.layers.31.post_attention_layernorm.weight
Missing in checkpoint: vision_model.transformer.layers.31.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.0.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.0.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.0.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.0.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.0.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.0.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.1.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.1.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.1.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.1.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.1.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.1.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.2.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.2.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.2.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.2.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.2.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.2.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.3.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.3.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.3.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.3.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.3.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.3.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.4.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.4.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.4.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.4.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.4.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.4.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.5.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.5.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.5.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.5.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.5.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.5.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.6.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.6.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.6.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.6.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.6.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.6.post_attention_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.7.gate_attn
Missing in checkpoint: vision_model.global_transformer.layers.7.gate_ffn
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.q_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.q_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.q_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.k_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.v_proj.base_layer.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.v_proj.lora_A.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.v_proj.lora_B.default.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.self_attn.o_proj.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.mlp.fc1.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.mlp.fc1.bias
Missing in checkpoint: vision_model.global_transformer.layers.7.mlp.fc2.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.mlp.fc2.bias
Missing in checkpoint: vision_model.global_transformer.layers.7.input_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.input_layernorm.bias
Missing in checkpoint: vision_model.global_transformer.layers.7.post_attention_layernorm.weight
Missing in checkpoint: vision_model.global_transformer.layers.7.post_attention_layernorm.bias
Traceback (most recent call last):
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/eval_normal.py", line 460, in <module>
    compare_and_replace_all_layers(full_model.base_model.model, model.base_model.model)
  File "/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/eval_normal.py", line 425, in compare_and_replace_all_layers
    if torch.allclose(full_model_tensor, checkpoint_tensor, atol=1e-6):
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 502.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 285.94 MiB is free. Including non-PyTorch memory, this process has 39.10 GiB memory in use. Of the allocated memory 38.16 GiB is allocated by PyTorch, and 475.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
