Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:01,  2.19it/s]Loading checkpoint shards:  40%|████      | 2/5 [00:00<00:00,  3.78it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:00<00:00,  4.93it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:00<00:00,  5.73it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  6.66it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  5.24it/s]
Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_compute_dtype', 'bnb_8bit_use_double_quant']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]Loading checkpoint shards:  11%|█         | 1/9 [00:47<06:21, 47.63s/it]Loading checkpoint shards:  22%|██▏       | 2/9 [01:17<04:19, 37.02s/it]Loading checkpoint shards:  33%|███▎      | 3/9 [03:22<07:43, 77.32s/it]Loading checkpoint shards:  44%|████▍     | 4/9 [04:10<05:28, 65.67s/it]Loading checkpoint shards:  56%|█████▌    | 5/9 [05:07<04:11, 62.77s/it]Loading checkpoint shards:  67%|██████▋   | 6/9 [05:54<02:51, 57.33s/it]Loading checkpoint shards:  78%|███████▊  | 7/9 [06:41<01:47, 53.77s/it]Loading checkpoint shards:  89%|████████▉ | 8/9 [08:15<01:06, 66.59s/it]Loading checkpoint shards: 100%|██████████| 9/9 [08:33<00:00, 51.39s/it]Loading checkpoint shards: 100%|██████████| 9/9 [08:33<00:00, 57.03s/it]
Some weights of the model checkpoint at /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant were not used when initializing MllamaForCausalLM: ['model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.13.cross_attn.q_proj.base_layer.weight', 'model.layers.13.cross_attn.q_proj.lora_A.default.weight', 'model.layers.13.cross_attn.q_proj.lora_B.default.weight', 'model.layers.13.cross_attn.v_proj.base_layer.weight', 'model.layers.13.cross_attn.v_proj.lora_A.default.weight', 'model.layers.13.cross_attn.v_proj.lora_B.default.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.cross_attn.q_proj.base_layer.weight', 'model.layers.18.cross_attn.q_proj.lora_A.default.weight', 'model.layers.18.cross_attn.q_proj.lora_B.default.weight', 'model.layers.18.cross_attn.v_proj.base_layer.weight', 'model.layers.18.cross_attn.v_proj.lora_A.default.weight', 'model.layers.18.cross_attn.v_proj.lora_B.default.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.cross_attn.q_proj.base_layer.weight', 'model.layers.23.cross_attn.q_proj.lora_A.default.weight', 'model.layers.23.cross_attn.q_proj.lora_B.default.weight', 'model.layers.23.cross_attn.v_proj.base_layer.weight', 'model.layers.23.cross_attn.v_proj.lora_A.default.weight', 'model.layers.23.cross_attn.v_proj.lora_B.default.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.cross_attn.q_proj.base_layer.weight', 'model.layers.28.cross_attn.q_proj.lora_A.default.weight', 'model.layers.28.cross_attn.q_proj.lora_B.default.weight', 'model.layers.28.cross_attn.v_proj.base_layer.weight', 'model.layers.28.cross_attn.v_proj.lora_A.default.weight', 'model.layers.28.cross_attn.v_proj.lora_B.default.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.3.cross_attn.q_proj.base_layer.weight', 'model.layers.3.cross_attn.q_proj.lora_A.default.weight', 'model.layers.3.cross_attn.q_proj.lora_B.default.weight', 'model.layers.3.cross_attn.v_proj.base_layer.weight', 'model.layers.3.cross_attn.v_proj.lora_A.default.weight', 'model.layers.3.cross_attn.v_proj.lora_B.default.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.lora_A.default.weight', 'model.layers.32.self_attn.q_proj.lora_B.default.weight', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.lora_A.default.weight', 'model.layers.32.self_attn.v_proj.lora_B.default.weight', 'model.layers.33.cross_attn.q_proj.base_layer.weight', 'model.layers.33.cross_attn.q_proj.lora_A.default.weight', 'model.layers.33.cross_attn.q_proj.lora_B.default.weight', 'model.layers.33.cross_attn.v_proj.base_layer.weight', 'model.layers.33.cross_attn.v_proj.lora_A.default.weight', 'model.layers.33.cross_attn.v_proj.lora_B.default.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.lora_A.default.weight', 'model.layers.34.self_attn.q_proj.lora_B.default.weight', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.lora_A.default.weight', 'model.layers.34.self_attn.v_proj.lora_B.default.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.lora_A.default.weight', 'model.layers.35.self_attn.q_proj.lora_B.default.weight', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.lora_A.default.weight', 'model.layers.35.self_attn.v_proj.lora_B.default.weight', 'model.layers.36.self_attn.q_proj.base_layer.weight', 'model.layers.36.self_attn.q_proj.lora_A.default.weight', 'model.layers.36.self_attn.q_proj.lora_B.default.weight', 'model.layers.36.self_attn.v_proj.base_layer.weight', 'model.layers.36.self_attn.v_proj.lora_A.default.weight', 'model.layers.36.self_attn.v_proj.lora_B.default.weight', 'model.layers.37.self_attn.q_proj.base_layer.weight', 'model.layers.37.self_attn.q_proj.lora_A.default.weight', 'model.layers.37.self_attn.q_proj.lora_B.default.weight', 'model.layers.37.self_attn.v_proj.base_layer.weight', 'model.layers.37.self_attn.v_proj.lora_A.default.weight', 'model.layers.37.self_attn.v_proj.lora_B.default.weight', 'model.layers.38.cross_attn.q_proj.base_layer.weight', 'model.layers.38.cross_attn.q_proj.lora_A.default.weight', 'model.layers.38.cross_attn.q_proj.lora_B.default.weight', 'model.layers.38.cross_attn.v_proj.base_layer.weight', 'model.layers.38.cross_attn.v_proj.lora_A.default.weight', 'model.layers.38.cross_attn.v_proj.lora_B.default.weight', 'model.layers.39.self_attn.q_proj.base_layer.weight', 'model.layers.39.self_attn.q_proj.lora_A.default.weight', 'model.layers.39.self_attn.q_proj.lora_B.default.weight', 'model.layers.39.self_attn.v_proj.base_layer.weight', 'model.layers.39.self_attn.v_proj.lora_A.default.weight', 'model.layers.39.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.8.cross_attn.q_proj.base_layer.weight', 'model.layers.8.cross_attn.q_proj.lora_A.default.weight', 'model.layers.8.cross_attn.q_proj.lora_B.default.weight', 'model.layers.8.cross_attn.v_proj.base_layer.weight', 'model.layers.8.cross_attn.v_proj.lora_A.default.weight', 'model.layers.8.cross_attn.v_proj.lora_B.default.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight']
- This IS expected if you are initializing MllamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing MllamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of MllamaForCausalLM were not initialized from the model checkpoint at /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant and are newly initialized: ['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.cross_attn.q_proj.weight', 'model.layers.13.cross_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.cross_attn.q_proj.weight', 'model.layers.18.cross_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.cross_attn.q_proj.weight', 'model.layers.23.cross_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.cross_attn.q_proj.weight', 'model.layers.28.cross_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.cross_attn.q_proj.weight', 'model.layers.3.cross_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.cross_attn.q_proj.weight', 'model.layers.33.cross_attn.v_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.cross_attn.q_proj.weight', 'model.layers.38.cross_attn.v_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.cross_attn.q_proj.weight', 'model.layers.8.cross_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/peft/mapping.py:172: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from '/scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant' to 'mylesgoose/Llama-3.2-11B-Vision-Instruct'. Please ensure that the correct base model is loaded when loading this checkpoint.
  warnings.warn(
/scratch/oe2015/conda-envs/greedy/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)  # noqa: B028
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
base_model.model.model.embed_tokens.weight False
base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.k_proj.weight False
base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.0.self_attn.o_proj.weight False
base_model.model.model.layers.0.mlp.gate_proj.weight False
base_model.model.model.layers.0.mlp.up_proj.weight False
base_model.model.model.layers.0.mlp.down_proj.weight False
base_model.model.model.layers.0.input_layernorm.weight False
base_model.model.model.layers.0.post_attention_layernorm.weight False
base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.k_proj.weight False
base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.1.self_attn.o_proj.weight False
base_model.model.model.layers.1.mlp.gate_proj.weight False
base_model.model.model.layers.1.mlp.up_proj.weight False
base_model.model.model.layers.1.mlp.down_proj.weight False
base_model.model.model.layers.1.input_layernorm.weight False
base_model.model.model.layers.1.post_attention_layernorm.weight False
base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.k_proj.weight False
base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.2.self_attn.o_proj.weight False
base_model.model.model.layers.2.mlp.gate_proj.weight False
base_model.model.model.layers.2.mlp.up_proj.weight False
base_model.model.model.layers.2.mlp.down_proj.weight False
base_model.model.model.layers.2.input_layernorm.weight False
base_model.model.model.layers.2.post_attention_layernorm.weight False
base_model.model.model.layers.3.cross_attn_attn_gate False
base_model.model.model.layers.3.cross_attn_mlp_gate False
base_model.model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.model.layers.3.input_layernorm.weight False
base_model.model.model.layers.3.mlp.gate_proj.weight False
base_model.model.model.layers.3.mlp.up_proj.weight False
base_model.model.model.layers.3.mlp.down_proj.weight False
base_model.model.model.layers.3.post_attention_layernorm.weight False
base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.k_proj.weight False
base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.4.self_attn.o_proj.weight False
base_model.model.model.layers.4.mlp.gate_proj.weight False
base_model.model.model.layers.4.mlp.up_proj.weight False
base_model.model.model.layers.4.mlp.down_proj.weight False
base_model.model.model.layers.4.input_layernorm.weight False
base_model.model.model.layers.4.post_attention_layernorm.weight False
base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.k_proj.weight False
base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.5.self_attn.o_proj.weight False
base_model.model.model.layers.5.mlp.gate_proj.weight False
base_model.model.model.layers.5.mlp.up_proj.weight False
base_model.model.model.layers.5.mlp.down_proj.weight False
base_model.model.model.layers.5.input_layernorm.weight False
base_model.model.model.layers.5.post_attention_layernorm.weight False
base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.k_proj.weight False
base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.6.self_attn.o_proj.weight False
base_model.model.model.layers.6.mlp.gate_proj.weight False
base_model.model.model.layers.6.mlp.up_proj.weight False
base_model.model.model.layers.6.mlp.down_proj.weight False
base_model.model.model.layers.6.input_layernorm.weight False
base_model.model.model.layers.6.post_attention_layernorm.weight False
base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.k_proj.weight False
base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.7.self_attn.o_proj.weight False
base_model.model.model.layers.7.mlp.gate_proj.weight False
base_model.model.model.layers.7.mlp.up_proj.weight False
base_model.model.model.layers.7.mlp.down_proj.weight False
base_model.model.model.layers.7.input_layernorm.weight False
base_model.model.model.layers.7.post_attention_layernorm.weight False
base_model.model.model.layers.8.cross_attn_attn_gate False
base_model.model.model.layers.8.cross_attn_mlp_gate False
base_model.model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.model.layers.8.input_layernorm.weight False
base_model.model.model.layers.8.mlp.gate_proj.weight False
base_model.model.model.layers.8.mlp.up_proj.weight False
base_model.model.model.layers.8.mlp.down_proj.weight False
base_model.model.model.layers.8.post_attention_layernorm.weight False
base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.k_proj.weight False
base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.9.self_attn.o_proj.weight False
base_model.model.model.layers.9.mlp.gate_proj.weight False
base_model.model.model.layers.9.mlp.up_proj.weight False
base_model.model.model.layers.9.mlp.down_proj.weight False
base_model.model.model.layers.9.input_layernorm.weight False
base_model.model.model.layers.9.post_attention_layernorm.weight False
base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.k_proj.weight False
base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.10.self_attn.o_proj.weight False
base_model.model.model.layers.10.mlp.gate_proj.weight False
base_model.model.model.layers.10.mlp.up_proj.weight False
base_model.model.model.layers.10.mlp.down_proj.weight False
base_model.model.model.layers.10.input_layernorm.weight False
base_model.model.model.layers.10.post_attention_layernorm.weight False
base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.k_proj.weight False
base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.11.self_attn.o_proj.weight False
base_model.model.model.layers.11.mlp.gate_proj.weight False
base_model.model.model.layers.11.mlp.up_proj.weight False
base_model.model.model.layers.11.mlp.down_proj.weight False
base_model.model.model.layers.11.input_layernorm.weight False
base_model.model.model.layers.11.post_attention_layernorm.weight False
base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.k_proj.weight False
base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.12.self_attn.o_proj.weight False
base_model.model.model.layers.12.mlp.gate_proj.weight False
base_model.model.model.layers.12.mlp.up_proj.weight False
base_model.model.model.layers.12.mlp.down_proj.weight False
base_model.model.model.layers.12.input_layernorm.weight False
base_model.model.model.layers.12.post_attention_layernorm.weight False
base_model.model.model.layers.13.cross_attn_attn_gate False
base_model.model.model.layers.13.cross_attn_mlp_gate False
base_model.model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.model.layers.13.input_layernorm.weight False
base_model.model.model.layers.13.mlp.gate_proj.weight False
base_model.model.model.layers.13.mlp.up_proj.weight False
base_model.model.model.layers.13.mlp.down_proj.weight False
base_model.model.model.layers.13.post_attention_layernorm.weight False
base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.k_proj.weight False
base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.14.self_attn.o_proj.weight False
base_model.model.model.layers.14.mlp.gate_proj.weight False
base_model.model.model.layers.14.mlp.up_proj.weight False
base_model.model.model.layers.14.mlp.down_proj.weight False
base_model.model.model.layers.14.input_layernorm.weight False
base_model.model.model.layers.14.post_attention_layernorm.weight False
base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.k_proj.weight False
base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.15.self_attn.o_proj.weight False
base_model.model.model.layers.15.mlp.gate_proj.weight False
base_model.model.model.layers.15.mlp.up_proj.weight False
base_model.model.model.layers.15.mlp.down_proj.weight False
base_model.model.model.layers.15.input_layernorm.weight False
base_model.model.model.layers.15.post_attention_layernorm.weight False
base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.k_proj.weight False
base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.16.self_attn.o_proj.weight False
base_model.model.model.layers.16.mlp.gate_proj.weight False
base_model.model.model.layers.16.mlp.up_proj.weight False
base_model.model.model.layers.16.mlp.down_proj.weight False
base_model.model.model.layers.16.input_layernorm.weight False
base_model.model.model.layers.16.post_attention_layernorm.weight False
base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.k_proj.weight False
base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.17.self_attn.o_proj.weight False
base_model.model.model.layers.17.mlp.gate_proj.weight False
base_model.model.model.layers.17.mlp.up_proj.weight False
base_model.model.model.layers.17.mlp.down_proj.weight False
base_model.model.model.layers.17.input_layernorm.weight False
base_model.model.model.layers.17.post_attention_layernorm.weight False
base_model.model.model.layers.18.cross_attn_attn_gate False
base_model.model.model.layers.18.cross_attn_mlp_gate False
base_model.model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.model.layers.18.input_layernorm.weight False
base_model.model.model.layers.18.mlp.gate_proj.weight False
base_model.model.model.layers.18.mlp.up_proj.weight False
base_model.model.model.layers.18.mlp.down_proj.weight False
base_model.model.model.layers.18.post_attention_layernorm.weight False
base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.k_proj.weight False
base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.19.self_attn.o_proj.weight False
base_model.model.model.layers.19.mlp.gate_proj.weight False
base_model.model.model.layers.19.mlp.up_proj.weight False
base_model.model.model.layers.19.mlp.down_proj.weight False
base_model.model.model.layers.19.input_layernorm.weight False
base_model.model.model.layers.19.post_attention_layernorm.weight False
base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.k_proj.weight False
base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.20.self_attn.o_proj.weight False
base_model.model.model.layers.20.mlp.gate_proj.weight False
base_model.model.model.layers.20.mlp.up_proj.weight False
base_model.model.model.layers.20.mlp.down_proj.weight False
base_model.model.model.layers.20.input_layernorm.weight False
base_model.model.model.layers.20.post_attention_layernorm.weight False
base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.k_proj.weight False
base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.21.self_attn.o_proj.weight False
base_model.model.model.layers.21.mlp.gate_proj.weight False
base_model.model.model.layers.21.mlp.up_proj.weight False
base_model.model.model.layers.21.mlp.down_proj.weight False
base_model.model.model.layers.21.input_layernorm.weight False
base_model.model.model.layers.21.post_attention_layernorm.weight False
base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.k_proj.weight False
base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.22.self_attn.o_proj.weight False
base_model.model.model.layers.22.mlp.gate_proj.weight False
base_model.model.model.layers.22.mlp.up_proj.weight False
base_model.model.model.layers.22.mlp.down_proj.weight False
base_model.model.model.layers.22.input_layernorm.weight False
base_model.model.model.layers.22.post_attention_layernorm.weight False
base_model.model.model.layers.23.cross_attn_attn_gate False
base_model.model.model.layers.23.cross_attn_mlp_gate False
base_model.model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.model.layers.23.input_layernorm.weight False
base_model.model.model.layers.23.mlp.gate_proj.weight False
base_model.model.model.layers.23.mlp.up_proj.weight False
base_model.model.model.layers.23.mlp.down_proj.weight False
base_model.model.model.layers.23.post_attention_layernorm.weight False
base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.k_proj.weight False
base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.24.self_attn.o_proj.weight False
base_model.model.model.layers.24.mlp.gate_proj.weight False
base_model.model.model.layers.24.mlp.up_proj.weight False
base_model.model.model.layers.24.mlp.down_proj.weight False
base_model.model.model.layers.24.input_layernorm.weight False
base_model.model.model.layers.24.post_attention_layernorm.weight False
base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.k_proj.weight False
base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.25.self_attn.o_proj.weight False
base_model.model.model.layers.25.mlp.gate_proj.weight False
base_model.model.model.layers.25.mlp.up_proj.weight False
base_model.model.model.layers.25.mlp.down_proj.weight False
base_model.model.model.layers.25.input_layernorm.weight False
base_model.model.model.layers.25.post_attention_layernorm.weight False
base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.k_proj.weight False
base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.26.self_attn.o_proj.weight False
base_model.model.model.layers.26.mlp.gate_proj.weight False
base_model.model.model.layers.26.mlp.up_proj.weight False
base_model.model.model.layers.26.mlp.down_proj.weight False
base_model.model.model.layers.26.input_layernorm.weight False
base_model.model.model.layers.26.post_attention_layernorm.weight False
base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.k_proj.weight False
base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.27.self_attn.o_proj.weight False
base_model.model.model.layers.27.mlp.gate_proj.weight False
base_model.model.model.layers.27.mlp.up_proj.weight False
base_model.model.model.layers.27.mlp.down_proj.weight False
base_model.model.model.layers.27.input_layernorm.weight False
base_model.model.model.layers.27.post_attention_layernorm.weight False
base_model.model.model.layers.28.cross_attn_attn_gate False
base_model.model.model.layers.28.cross_attn_mlp_gate False
base_model.model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.model.layers.28.input_layernorm.weight False
base_model.model.model.layers.28.mlp.gate_proj.weight False
base_model.model.model.layers.28.mlp.up_proj.weight False
base_model.model.model.layers.28.mlp.down_proj.weight False
base_model.model.model.layers.28.post_attention_layernorm.weight False
base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.k_proj.weight False
base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.29.self_attn.o_proj.weight False
base_model.model.model.layers.29.mlp.gate_proj.weight False
base_model.model.model.layers.29.mlp.up_proj.weight False
base_model.model.model.layers.29.mlp.down_proj.weight False
base_model.model.model.layers.29.input_layernorm.weight False
base_model.model.model.layers.29.post_attention_layernorm.weight False
base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.k_proj.weight False
base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.30.self_attn.o_proj.weight False
base_model.model.model.layers.30.mlp.gate_proj.weight False
base_model.model.model.layers.30.mlp.up_proj.weight False
base_model.model.model.layers.30.mlp.down_proj.weight False
base_model.model.model.layers.30.input_layernorm.weight False
base_model.model.model.layers.30.post_attention_layernorm.weight False
base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.k_proj.weight False
base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.31.self_attn.o_proj.weight False
base_model.model.model.layers.31.mlp.gate_proj.weight False
base_model.model.model.layers.31.mlp.up_proj.weight False
base_model.model.model.layers.31.mlp.down_proj.weight False
base_model.model.model.layers.31.input_layernorm.weight False
base_model.model.model.layers.31.post_attention_layernorm.weight False
base_model.model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.k_proj.weight False
base_model.model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.32.self_attn.o_proj.weight False
base_model.model.model.layers.32.mlp.gate_proj.weight False
base_model.model.model.layers.32.mlp.up_proj.weight False
base_model.model.model.layers.32.mlp.down_proj.weight False
base_model.model.model.layers.32.input_layernorm.weight False
base_model.model.model.layers.32.post_attention_layernorm.weight False
base_model.model.model.layers.33.cross_attn_attn_gate False
base_model.model.model.layers.33.cross_attn_mlp_gate False
base_model.model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.model.layers.33.input_layernorm.weight False
base_model.model.model.layers.33.mlp.gate_proj.weight False
base_model.model.model.layers.33.mlp.up_proj.weight False
base_model.model.model.layers.33.mlp.down_proj.weight False
base_model.model.model.layers.33.post_attention_layernorm.weight False
base_model.model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.k_proj.weight False
base_model.model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.34.self_attn.o_proj.weight False
base_model.model.model.layers.34.mlp.gate_proj.weight False
base_model.model.model.layers.34.mlp.up_proj.weight False
base_model.model.model.layers.34.mlp.down_proj.weight False
base_model.model.model.layers.34.input_layernorm.weight False
base_model.model.model.layers.34.post_attention_layernorm.weight False
base_model.model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.k_proj.weight False
base_model.model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.35.self_attn.o_proj.weight False
base_model.model.model.layers.35.mlp.gate_proj.weight False
base_model.model.model.layers.35.mlp.up_proj.weight False
base_model.model.model.layers.35.mlp.down_proj.weight False
base_model.model.model.layers.35.input_layernorm.weight False
base_model.model.model.layers.35.post_attention_layernorm.weight False
base_model.model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.k_proj.weight False
base_model.model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.36.self_attn.o_proj.weight False
base_model.model.model.layers.36.mlp.gate_proj.weight False
base_model.model.model.layers.36.mlp.up_proj.weight False
base_model.model.model.layers.36.mlp.down_proj.weight False
base_model.model.model.layers.36.input_layernorm.weight False
base_model.model.model.layers.36.post_attention_layernorm.weight False
base_model.model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.k_proj.weight False
base_model.model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.37.self_attn.o_proj.weight False
base_model.model.model.layers.37.mlp.gate_proj.weight False
base_model.model.model.layers.37.mlp.up_proj.weight False
base_model.model.model.layers.37.mlp.down_proj.weight False
base_model.model.model.layers.37.input_layernorm.weight False
base_model.model.model.layers.37.post_attention_layernorm.weight False
base_model.model.model.layers.38.cross_attn_attn_gate False
base_model.model.model.layers.38.cross_attn_mlp_gate False
base_model.model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.model.layers.38.input_layernorm.weight False
base_model.model.model.layers.38.mlp.gate_proj.weight False
base_model.model.model.layers.38.mlp.up_proj.weight False
base_model.model.model.layers.38.mlp.down_proj.weight False
base_model.model.model.layers.38.post_attention_layernorm.weight False
base_model.model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.k_proj.weight False
base_model.model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.model.layers.39.self_attn.o_proj.weight False
base_model.model.model.layers.39.mlp.gate_proj.weight False
base_model.model.model.layers.39.mlp.up_proj.weight False
base_model.model.model.layers.39.mlp.down_proj.weight False
base_model.model.model.layers.39.input_layernorm.weight False
base_model.model.model.layers.39.post_attention_layernorm.weight False
base_model.model.model.norm.weight False
base_model.model.lm_head.weight False
base_model.model.vision_model.class_embedding False
base_model.model.vision_model.patch_embedding.weight False
base_model.model.vision_model.gated_positional_embedding.gate False
base_model.model.vision_model.gated_positional_embedding.embedding False
base_model.model.vision_model.gated_positional_embedding.tile_embedding.weight False
base_model.model.vision_model.pre_tile_positional_embedding.gate False
base_model.model.vision_model.pre_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.post_tile_positional_embedding.gate False
base_model.model.vision_model.post_tile_positional_embedding.embedding.weight False
base_model.model.vision_model.layernorm_pre.weight False
base_model.model.vision_model.layernorm_pre.bias False
base_model.model.vision_model.layernorm_post.weight False
base_model.model.vision_model.layernorm_post.bias False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.7.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.8.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.8.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.8.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.8.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.9.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.9.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.9.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.9.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.10.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.10.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.10.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.10.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.11.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.11.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.11.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.11.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.12.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.12.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.12.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.12.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.13.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.13.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.13.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.13.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.14.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.14.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.14.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.14.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.15.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.15.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.15.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.15.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.16.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.16.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.16.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.16.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.17.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.17.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.17.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.17.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.18.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.18.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.18.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.18.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.19.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.19.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.19.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.19.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.20.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.20.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.20.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.20.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.21.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.21.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.21.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.21.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.22.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.22.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.22.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.22.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.23.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.23.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.23.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.23.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.24.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.24.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.24.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.24.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.25.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.25.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.25.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.25.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.26.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.26.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.26.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.26.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.27.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.27.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.27.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.27.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.28.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.28.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.28.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.28.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.29.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.29.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.29.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.29.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.30.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.30.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.30.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.30.post_attention_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.k_proj.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.transformer.layers.31.self_attn.o_proj.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc1.bias False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.weight False
base_model.model.vision_model.transformer.layers.31.mlp.fc2.bias False
base_model.model.vision_model.transformer.layers.31.input_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.input_layernorm.bias False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.weight False
base_model.model.vision_model.transformer.layers.31.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.gate_attn False
base_model.model.vision_model.global_transformer.layers.0.gate_ffn False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.0.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.0.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.0.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.gate_attn False
base_model.model.vision_model.global_transformer.layers.1.gate_ffn False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.1.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.1.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.1.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.gate_attn False
base_model.model.vision_model.global_transformer.layers.2.gate_ffn False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.2.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.2.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.2.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.gate_attn False
base_model.model.vision_model.global_transformer.layers.3.gate_ffn False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.3.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.3.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.3.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.gate_attn False
base_model.model.vision_model.global_transformer.layers.4.gate_ffn False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.4.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.4.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.4.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.gate_attn False
base_model.model.vision_model.global_transformer.layers.5.gate_ffn False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.5.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.5.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.5.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.gate_attn False
base_model.model.vision_model.global_transformer.layers.6.gate_ffn False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.6.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.6.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.6.post_attention_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.gate_attn False
base_model.model.vision_model.global_transformer.layers.7.gate_ffn False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.k_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.vision_model.global_transformer.layers.7.self_attn.o_proj.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc1.bias False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.weight False
base_model.model.vision_model.global_transformer.layers.7.mlp.fc2.bias False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.input_layernorm.bias False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.weight False
base_model.model.vision_model.global_transformer.layers.7.post_attention_layernorm.bias False
base_model.model.language_model.model.embed_tokens.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.0.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.0.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.0.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.0.mlp.up_proj.weight False
base_model.model.language_model.model.layers.0.mlp.down_proj.weight False
base_model.model.language_model.model.layers.0.input_layernorm.weight False
base_model.model.language_model.model.layers.0.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.1.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.1.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.1.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.1.mlp.up_proj.weight False
base_model.model.language_model.model.layers.1.mlp.down_proj.weight False
base_model.model.language_model.model.layers.1.input_layernorm.weight False
base_model.model.language_model.model.layers.1.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.2.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.2.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.2.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.2.mlp.up_proj.weight False
base_model.model.language_model.model.layers.2.mlp.down_proj.weight False
base_model.model.language_model.model.layers.2.input_layernorm.weight False
base_model.model.language_model.model.layers.2.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.3.cross_attn_attn_gate False
base_model.model.language_model.model.layers.3.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.3.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.3.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.3.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.3.input_layernorm.weight False
base_model.model.language_model.model.layers.3.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.3.mlp.up_proj.weight False
base_model.model.language_model.model.layers.3.mlp.down_proj.weight False
base_model.model.language_model.model.layers.3.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.4.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.4.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.4.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.4.mlp.up_proj.weight False
base_model.model.language_model.model.layers.4.mlp.down_proj.weight False
base_model.model.language_model.model.layers.4.input_layernorm.weight False
base_model.model.language_model.model.layers.4.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.5.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.5.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.5.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.5.mlp.up_proj.weight False
base_model.model.language_model.model.layers.5.mlp.down_proj.weight False
base_model.model.language_model.model.layers.5.input_layernorm.weight False
base_model.model.language_model.model.layers.5.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.6.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.6.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.6.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.6.mlp.up_proj.weight False
base_model.model.language_model.model.layers.6.mlp.down_proj.weight False
base_model.model.language_model.model.layers.6.input_layernorm.weight False
base_model.model.language_model.model.layers.6.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.7.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.7.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.7.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.7.mlp.up_proj.weight False
base_model.model.language_model.model.layers.7.mlp.down_proj.weight False
base_model.model.language_model.model.layers.7.input_layernorm.weight False
base_model.model.language_model.model.layers.7.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.8.cross_attn_attn_gate False
base_model.model.language_model.model.layers.8.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.8.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.8.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.8.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.8.input_layernorm.weight False
base_model.model.language_model.model.layers.8.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.8.mlp.up_proj.weight False
base_model.model.language_model.model.layers.8.mlp.down_proj.weight False
base_model.model.language_model.model.layers.8.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.9.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.9.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.9.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.9.mlp.up_proj.weight False
base_model.model.language_model.model.layers.9.mlp.down_proj.weight False
base_model.model.language_model.model.layers.9.input_layernorm.weight False
base_model.model.language_model.model.layers.9.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.10.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.10.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.10.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.10.mlp.up_proj.weight False
base_model.model.language_model.model.layers.10.mlp.down_proj.weight False
base_model.model.language_model.model.layers.10.input_layernorm.weight False
base_model.model.language_model.model.layers.10.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.11.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.11.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.11.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.11.mlp.up_proj.weight False
base_model.model.language_model.model.layers.11.mlp.down_proj.weight False
base_model.model.language_model.model.layers.11.input_layernorm.weight False
base_model.model.language_model.model.layers.11.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.12.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.12.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.12.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.12.mlp.up_proj.weight False
base_model.model.language_model.model.layers.12.mlp.down_proj.weight False
base_model.model.language_model.model.layers.12.input_layernorm.weight False
base_model.model.language_model.model.layers.12.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.13.cross_attn_attn_gate False
base_model.model.language_model.model.layers.13.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.13.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.13.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.13.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.13.input_layernorm.weight False
base_model.model.language_model.model.layers.13.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.13.mlp.up_proj.weight False
base_model.model.language_model.model.layers.13.mlp.down_proj.weight False
base_model.model.language_model.model.layers.13.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.14.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.14.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.14.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.14.mlp.up_proj.weight False
base_model.model.language_model.model.layers.14.mlp.down_proj.weight False
base_model.model.language_model.model.layers.14.input_layernorm.weight False
base_model.model.language_model.model.layers.14.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.15.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.15.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.15.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.15.mlp.up_proj.weight False
base_model.model.language_model.model.layers.15.mlp.down_proj.weight False
base_model.model.language_model.model.layers.15.input_layernorm.weight False
base_model.model.language_model.model.layers.15.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.16.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.16.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.16.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.16.mlp.up_proj.weight False
base_model.model.language_model.model.layers.16.mlp.down_proj.weight False
base_model.model.language_model.model.layers.16.input_layernorm.weight False
base_model.model.language_model.model.layers.16.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.17.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.17.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.17.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.17.mlp.up_proj.weight False
base_model.model.language_model.model.layers.17.mlp.down_proj.weight False
base_model.model.language_model.model.layers.17.input_layernorm.weight False
base_model.model.language_model.model.layers.17.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.18.cross_attn_attn_gate False
base_model.model.language_model.model.layers.18.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.18.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.18.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.18.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.18.input_layernorm.weight False
base_model.model.language_model.model.layers.18.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.18.mlp.up_proj.weight False
base_model.model.language_model.model.layers.18.mlp.down_proj.weight False
base_model.model.language_model.model.layers.18.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.19.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.19.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.19.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.19.mlp.up_proj.weight False
base_model.model.language_model.model.layers.19.mlp.down_proj.weight False
base_model.model.language_model.model.layers.19.input_layernorm.weight False
base_model.model.language_model.model.layers.19.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.20.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.20.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.20.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.20.mlp.up_proj.weight False
base_model.model.language_model.model.layers.20.mlp.down_proj.weight False
base_model.model.language_model.model.layers.20.input_layernorm.weight False
base_model.model.language_model.model.layers.20.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.21.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.21.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.21.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.21.mlp.up_proj.weight False
base_model.model.language_model.model.layers.21.mlp.down_proj.weight False
base_model.model.language_model.model.layers.21.input_layernorm.weight False
base_model.model.language_model.model.layers.21.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.22.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.22.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.22.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.22.mlp.up_proj.weight False
base_model.model.language_model.model.layers.22.mlp.down_proj.weight False
base_model.model.language_model.model.layers.22.input_layernorm.weight False
base_model.model.language_model.model.layers.22.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.23.cross_attn_attn_gate False
base_model.model.language_model.model.layers.23.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.23.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.23.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.23.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.23.input_layernorm.weight False
base_model.model.language_model.model.layers.23.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.23.mlp.up_proj.weight False
base_model.model.language_model.model.layers.23.mlp.down_proj.weight False
base_model.model.language_model.model.layers.23.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.24.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.24.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.24.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.24.mlp.up_proj.weight False
base_model.model.language_model.model.layers.24.mlp.down_proj.weight False
base_model.model.language_model.model.layers.24.input_layernorm.weight False
base_model.model.language_model.model.layers.24.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.25.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.25.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.25.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.25.mlp.up_proj.weight False
base_model.model.language_model.model.layers.25.mlp.down_proj.weight False
base_model.model.language_model.model.layers.25.input_layernorm.weight False
base_model.model.language_model.model.layers.25.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.26.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.26.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.26.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.26.mlp.up_proj.weight False
base_model.model.language_model.model.layers.26.mlp.down_proj.weight False
base_model.model.language_model.model.layers.26.input_layernorm.weight False
base_model.model.language_model.model.layers.26.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.27.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.27.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.27.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.27.mlp.up_proj.weight False
base_model.model.language_model.model.layers.27.mlp.down_proj.weight False
base_model.model.language_model.model.layers.27.input_layernorm.weight False
base_model.model.language_model.model.layers.27.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.28.cross_attn_attn_gate False
base_model.model.language_model.model.layers.28.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.28.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.28.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.28.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.28.input_layernorm.weight False
base_model.model.language_model.model.layers.28.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.28.mlp.up_proj.weight False
base_model.model.language_model.model.layers.28.mlp.down_proj.weight False
base_model.model.language_model.model.layers.28.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.29.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.29.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.29.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.29.mlp.up_proj.weight False
base_model.model.language_model.model.layers.29.mlp.down_proj.weight False
base_model.model.language_model.model.layers.29.input_layernorm.weight False
base_model.model.language_model.model.layers.29.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.30.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.30.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.30.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.30.mlp.up_proj.weight False
base_model.model.language_model.model.layers.30.mlp.down_proj.weight False
base_model.model.language_model.model.layers.30.input_layernorm.weight False
base_model.model.language_model.model.layers.30.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.31.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.31.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.31.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.31.mlp.up_proj.weight False
base_model.model.language_model.model.layers.31.mlp.down_proj.weight False
base_model.model.language_model.model.layers.31.input_layernorm.weight False
base_model.model.language_model.model.layers.31.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.32.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.32.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.32.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.32.mlp.up_proj.weight False
base_model.model.language_model.model.layers.32.mlp.down_proj.weight False
base_model.model.language_model.model.layers.32.input_layernorm.weight False
base_model.model.language_model.model.layers.32.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.33.cross_attn_attn_gate False
base_model.model.language_model.model.layers.33.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.33.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.33.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.33.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.33.input_layernorm.weight False
base_model.model.language_model.model.layers.33.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.33.mlp.up_proj.weight False
base_model.model.language_model.model.layers.33.mlp.down_proj.weight False
base_model.model.language_model.model.layers.33.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.34.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.34.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.34.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.34.mlp.up_proj.weight False
base_model.model.language_model.model.layers.34.mlp.down_proj.weight False
base_model.model.language_model.model.layers.34.input_layernorm.weight False
base_model.model.language_model.model.layers.34.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.35.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.35.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.35.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.35.mlp.up_proj.weight False
base_model.model.language_model.model.layers.35.mlp.down_proj.weight False
base_model.model.language_model.model.layers.35.input_layernorm.weight False
base_model.model.language_model.model.layers.35.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.36.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.36.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.36.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.36.mlp.up_proj.weight False
base_model.model.language_model.model.layers.36.mlp.down_proj.weight False
base_model.model.language_model.model.layers.36.input_layernorm.weight False
base_model.model.language_model.model.layers.36.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.37.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.37.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.37.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.37.mlp.up_proj.weight False
base_model.model.language_model.model.layers.37.mlp.down_proj.weight False
base_model.model.language_model.model.layers.37.input_layernorm.weight False
base_model.model.language_model.model.layers.37.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.38.cross_attn_attn_gate False
base_model.model.language_model.model.layers.38.cross_attn_mlp_gate False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.k_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.38.cross_attn.o_proj.weight False
base_model.model.language_model.model.layers.38.cross_attn.q_norm.weight False
base_model.model.language_model.model.layers.38.cross_attn.k_norm.weight False
base_model.model.language_model.model.layers.38.input_layernorm.weight False
base_model.model.language_model.model.layers.38.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.38.mlp.up_proj.weight False
base_model.model.language_model.model.layers.38.mlp.down_proj.weight False
base_model.model.language_model.model.layers.38.post_attention_layernorm.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.q_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.k_proj.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.base_layer.weight False
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_A.default.weight True
base_model.model.language_model.model.layers.39.self_attn.v_proj.lora_B.default.weight True
base_model.model.language_model.model.layers.39.self_attn.o_proj.weight False
base_model.model.language_model.model.layers.39.mlp.gate_proj.weight False
base_model.model.language_model.model.layers.39.mlp.up_proj.weight False
base_model.model.language_model.model.layers.39.mlp.down_proj.weight False
base_model.model.language_model.model.layers.39.input_layernorm.weight False
base_model.model.language_model.model.layers.39.post_attention_layernorm.weight False
base_model.model.language_model.model.norm.weight False
base_model.model.language_model.lm_head.weight False
base_model.model.multi_modal_projector.weight False
base_model.model.multi_modal_projector.bias False
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00001-of-00009.safetensors
Loading weights for: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.3.cross_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00002-of-00009.safetensors
Loading weights for: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.8.cross_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00003-of-00009.safetensors
Loading weights for: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.13.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00004-of-00009.safetensors
Loading weights for: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.18.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00005-of-00009.safetensors
Loading weights for: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.23.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00006-of-00009.safetensors
Loading weights for: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.28.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00007-of-00009.safetensors
Loading weights for: base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.33.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00008-of-00009.safetensors
Loading weights for: base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.38.cross_attn.v_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight
Loading weights for: base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight
Loading shard: /scratch/oe2015/ai_project/DeTikZify/detikzify/evaluate/final_model_checkpoint_2048_noquant/model-00009-of-00009.safetensors
model.layers.0.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.0.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.1.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.q_proj.lora_B.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_A.default.weight matches: True
model.layers.2.self_attn.v_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.q_proj.lora_B.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_A.default.weight matches: True
model.layers.3.cross_attn.v_proj.lora_B.default.weight matches: True
MISMATCH: model.layers.0.self_attn.q_proj.lora_A.default.weight
Difference: 0.3285108804702759
MISMATCH: model.layers.0.self_attn.q_proj.lora_B.default.weight
Difference: 0.04547516629099846
MISMATCH: model.layers.0.self_attn.v_proj.lora_A.default.weight
Difference: 1.8389307260513306
MISMATCH: model.layers.0.self_attn.v_proj.lora_B.default.weight
Difference: 0.021513009443879128
MISMATCH: model.layers.1.self_attn.q_proj.lora_A.default.weight
Difference: 0.07840707898139954
MISMATCH: model.layers.1.self_attn.q_proj.lora_B.default.weight
Difference: 0.029552964493632317
MISMATCH: model.layers.1.self_attn.v_proj.lora_A.default.weight
Difference: 0.3345932066440582
MISMATCH: model.layers.1.self_attn.v_proj.lora_B.default.weight
Difference: 0.024300124496221542
MISMATCH: model.layers.2.self_attn.q_proj.lora_A.default.weight
Difference: 0.05498123541474342
MISMATCH: model.layers.2.self_attn.q_proj.lora_B.default.weight
Difference: 0.038736484944820404
MISMATCH: model.layers.2.self_attn.v_proj.lora_A.default.weight
Difference: 0.12210294604301453
MISMATCH: model.layers.2.self_attn.v_proj.lora_B.default.weight
Difference: 0.02213912084698677
MISMATCH: model.layers.3.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031124236062169075
Matched: model.layers.3.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.3.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031106336042284966
Matched: model.layers.3.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.4.self_attn.q_proj.lora_A.default.weight
Difference: 0.04936448112130165
MISMATCH: model.layers.4.self_attn.q_proj.lora_B.default.weight
Difference: 0.03637254238128662
MISMATCH: model.layers.4.self_attn.v_proj.lora_A.default.weight
Difference: 0.07225207984447479
MISMATCH: model.layers.4.self_attn.v_proj.lora_B.default.weight
Difference: 0.02176925353705883
MISMATCH: model.layers.5.self_attn.q_proj.lora_A.default.weight
Difference: 0.04731450602412224
MISMATCH: model.layers.5.self_attn.q_proj.lora_B.default.weight
Difference: 0.031523335725069046
MISMATCH: model.layers.5.self_attn.v_proj.lora_A.default.weight
Difference: 0.05525278300046921
MISMATCH: model.layers.5.self_attn.v_proj.lora_B.default.weight
Difference: 0.019891686737537384
MISMATCH: model.layers.6.self_attn.q_proj.lora_A.default.weight
Difference: 0.05215972661972046
MISMATCH: model.layers.6.self_attn.q_proj.lora_B.default.weight
Difference: 0.02618734911084175
MISMATCH: model.layers.6.self_attn.v_proj.lora_A.default.weight
Difference: 0.05202287435531616
MISMATCH: model.layers.6.self_attn.v_proj.lora_B.default.weight
Difference: 0.019498547539114952
MISMATCH: model.layers.7.self_attn.q_proj.lora_A.default.weight
Difference: 0.0500979907810688
MISMATCH: model.layers.7.self_attn.q_proj.lora_B.default.weight
Difference: 0.029165351763367653
MISMATCH: model.layers.7.self_attn.v_proj.lora_A.default.weight
Difference: 0.059820689260959625
MISMATCH: model.layers.7.self_attn.v_proj.lora_B.default.weight
Difference: 0.024354511871933937
MISMATCH: model.layers.8.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03110610321164131
Matched: model.layers.8.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.8.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031220506876707077
Matched: model.layers.8.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.9.self_attn.q_proj.lora_A.default.weight
Difference: 0.05609562247991562
MISMATCH: model.layers.9.self_attn.q_proj.lora_B.default.weight
Difference: 0.03132356330752373
MISMATCH: model.layers.9.self_attn.v_proj.lora_A.default.weight
Difference: 0.05669547989964485
MISMATCH: model.layers.9.self_attn.v_proj.lora_B.default.weight
Difference: 0.019587744027376175
MISMATCH: model.layers.10.self_attn.q_proj.lora_A.default.weight
Difference: 0.051277536898851395
MISMATCH: model.layers.10.self_attn.q_proj.lora_B.default.weight
Difference: 0.035850122570991516
MISMATCH: model.layers.10.self_attn.v_proj.lora_A.default.weight
Difference: 0.06305383145809174
MISMATCH: model.layers.10.self_attn.v_proj.lora_B.default.weight
Difference: 0.019277077168226242
MISMATCH: model.layers.11.self_attn.q_proj.lora_A.default.weight
Difference: 0.05092725530266762
MISMATCH: model.layers.11.self_attn.q_proj.lora_B.default.weight
Difference: 0.03334677219390869
MISMATCH: model.layers.11.self_attn.v_proj.lora_A.default.weight
Difference: 0.06309734284877777
MISMATCH: model.layers.11.self_attn.v_proj.lora_B.default.weight
Difference: 0.021792657673358917
MISMATCH: model.layers.12.self_attn.q_proj.lora_A.default.weight
Difference: 0.057257093489170074
MISMATCH: model.layers.12.self_attn.q_proj.lora_B.default.weight
Difference: 0.034554384648799896
MISMATCH: model.layers.12.self_attn.v_proj.lora_A.default.weight
Difference: 0.05983610823750496
MISMATCH: model.layers.12.self_attn.v_proj.lora_B.default.weight
Difference: 0.022101640701293945
MISMATCH: model.layers.13.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03104359097778797
Matched: model.layers.13.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.13.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031229637563228607
Matched: model.layers.13.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.14.self_attn.q_proj.lora_A.default.weight
Difference: 0.05571804195642471
MISMATCH: model.layers.14.self_attn.q_proj.lora_B.default.weight
Difference: 0.03285849094390869
MISMATCH: model.layers.14.self_attn.v_proj.lora_A.default.weight
Difference: 0.06766949594020844
MISMATCH: model.layers.14.self_attn.v_proj.lora_B.default.weight
Difference: 0.019147925078868866
MISMATCH: model.layers.15.self_attn.q_proj.lora_A.default.weight
Difference: 0.054140374064445496
MISMATCH: model.layers.15.self_attn.q_proj.lora_B.default.weight
Difference: 0.02699071727693081
MISMATCH: model.layers.15.self_attn.v_proj.lora_A.default.weight
Difference: 0.06736941635608673
MISMATCH: model.layers.15.self_attn.v_proj.lora_B.default.weight
Difference: 0.025355199351906776
MISMATCH: model.layers.16.self_attn.q_proj.lora_A.default.weight
Difference: 0.056042999029159546
MISMATCH: model.layers.16.self_attn.q_proj.lora_B.default.weight
Difference: 0.03287215158343315
MISMATCH: model.layers.16.self_attn.v_proj.lora_A.default.weight
Difference: 0.07042248547077179
MISMATCH: model.layers.16.self_attn.v_proj.lora_B.default.weight
Difference: 0.023918073624372482
MISMATCH: model.layers.17.self_attn.q_proj.lora_A.default.weight
Difference: 0.05791900306940079
MISMATCH: model.layers.17.self_attn.q_proj.lora_B.default.weight
Difference: 0.035473983734846115
MISMATCH: model.layers.17.self_attn.v_proj.lora_A.default.weight
Difference: 0.07827810943126678
MISMATCH: model.layers.17.self_attn.v_proj.lora_B.default.weight
Difference: 0.02027452550828457
MISMATCH: model.layers.18.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031184084713459015
Matched: model.layers.18.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.18.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03106493316590786
Matched: model.layers.18.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.19.self_attn.q_proj.lora_A.default.weight
Difference: 0.057394541800022125
MISMATCH: model.layers.19.self_attn.q_proj.lora_B.default.weight
Difference: 0.03628101199865341
MISMATCH: model.layers.19.self_attn.v_proj.lora_A.default.weight
Difference: 0.06882954388856888
MISMATCH: model.layers.19.self_attn.v_proj.lora_B.default.weight
Difference: 0.022227933630347252
MISMATCH: model.layers.20.self_attn.q_proj.lora_A.default.weight
Difference: 0.056590404361486435
MISMATCH: model.layers.20.self_attn.q_proj.lora_B.default.weight
Difference: 0.0387718640267849
MISMATCH: model.layers.20.self_attn.v_proj.lora_A.default.weight
Difference: 0.06896807253360748
MISMATCH: model.layers.20.self_attn.v_proj.lora_B.default.weight
Difference: 0.027507655322551727
MISMATCH: model.layers.21.self_attn.q_proj.lora_A.default.weight
Difference: 0.056753773242235184
MISMATCH: model.layers.21.self_attn.q_proj.lora_B.default.weight
Difference: 0.03859185799956322
MISMATCH: model.layers.21.self_attn.v_proj.lora_A.default.weight
Difference: 0.06982149183750153
MISMATCH: model.layers.21.self_attn.v_proj.lora_B.default.weight
Difference: 0.02163580060005188
MISMATCH: model.layers.22.self_attn.q_proj.lora_A.default.weight
Difference: 0.05496200919151306
MISMATCH: model.layers.22.self_attn.q_proj.lora_B.default.weight
Difference: 0.03000660240650177
MISMATCH: model.layers.22.self_attn.v_proj.lora_A.default.weight
Difference: 0.07620833814144135
MISMATCH: model.layers.22.self_attn.v_proj.lora_B.default.weight
Difference: 0.02174432948231697
MISMATCH: model.layers.23.cross_attn.q_proj.lora_A.default.weight
Difference: 0.0311755258589983
Matched: model.layers.23.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.23.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031194770708680153
Matched: model.layers.23.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.24.self_attn.q_proj.lora_A.default.weight
Difference: 0.05467890948057175
MISMATCH: model.layers.24.self_attn.q_proj.lora_B.default.weight
Difference: 0.03201845660805702
MISMATCH: model.layers.24.self_attn.v_proj.lora_A.default.weight
Difference: 0.06364895403385162
MISMATCH: model.layers.24.self_attn.v_proj.lora_B.default.weight
Difference: 0.02080996334552765
MISMATCH: model.layers.25.self_attn.q_proj.lora_A.default.weight
Difference: 0.052938614040613174
MISMATCH: model.layers.25.self_attn.q_proj.lora_B.default.weight
Difference: 0.03679414466023445
MISMATCH: model.layers.25.self_attn.v_proj.lora_A.default.weight
Difference: 0.07504494488239288
MISMATCH: model.layers.25.self_attn.v_proj.lora_B.default.weight
Difference: 0.021687593311071396
MISMATCH: model.layers.26.self_attn.q_proj.lora_A.default.weight
Difference: 0.05265143886208534
MISMATCH: model.layers.26.self_attn.q_proj.lora_B.default.weight
Difference: 0.03319144621491432
MISMATCH: model.layers.26.self_attn.v_proj.lora_A.default.weight
Difference: 0.06915880739688873
MISMATCH: model.layers.26.self_attn.v_proj.lora_B.default.weight
Difference: 0.02195844054222107
MISMATCH: model.layers.27.self_attn.q_proj.lora_A.default.weight
Difference: 0.05512189865112305
MISMATCH: model.layers.27.self_attn.q_proj.lora_B.default.weight
Difference: 0.034028228372335434
MISMATCH: model.layers.27.self_attn.v_proj.lora_A.default.weight
Difference: 0.07593506574630737
MISMATCH: model.layers.27.self_attn.v_proj.lora_B.default.weight
Difference: 0.021349379792809486
MISMATCH: model.layers.28.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03115582838654518
Matched: model.layers.28.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.28.cross_attn.v_proj.lora_A.default.weight
Difference: 0.03123527206480503
Matched: model.layers.28.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.29.self_attn.q_proj.lora_A.default.weight
Difference: 0.05583088472485542
MISMATCH: model.layers.29.self_attn.q_proj.lora_B.default.weight
Difference: 0.03130609169602394
MISMATCH: model.layers.29.self_attn.v_proj.lora_A.default.weight
Difference: 0.07488398253917694
MISMATCH: model.layers.29.self_attn.v_proj.lora_B.default.weight
Difference: 0.02109551429748535
MISMATCH: model.layers.30.self_attn.q_proj.lora_A.default.weight
Difference: 0.0564102865755558
MISMATCH: model.layers.30.self_attn.q_proj.lora_B.default.weight
Difference: 0.03265886753797531
MISMATCH: model.layers.30.self_attn.v_proj.lora_A.default.weight
Difference: 0.06738367676734924
MISMATCH: model.layers.30.self_attn.v_proj.lora_B.default.weight
Difference: 0.026020683348178864
MISMATCH: model.layers.31.self_attn.q_proj.lora_A.default.weight
Difference: 0.05522812530398369
MISMATCH: model.layers.31.self_attn.q_proj.lora_B.default.weight
Difference: 0.03175691142678261
MISMATCH: model.layers.31.self_attn.v_proj.lora_A.default.weight
Difference: 0.07092057168483734
MISMATCH: model.layers.31.self_attn.v_proj.lora_B.default.weight
Difference: 0.02397371269762516
MISMATCH: model.layers.32.self_attn.q_proj.lora_A.default.weight
Difference: 0.05271364003419876
MISMATCH: model.layers.32.self_attn.q_proj.lora_B.default.weight
Difference: 0.0309064332395792
MISMATCH: model.layers.32.self_attn.v_proj.lora_A.default.weight
Difference: 0.07313111424446106
MISMATCH: model.layers.32.self_attn.v_proj.lora_B.default.weight
Difference: 0.02057211473584175
MISMATCH: model.layers.33.cross_attn.q_proj.lora_A.default.weight
Difference: 0.03115953877568245
Matched: model.layers.33.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.33.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031100837513804436
Matched: model.layers.33.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.34.self_attn.q_proj.lora_A.default.weight
Difference: 0.05542733147740364
MISMATCH: model.layers.34.self_attn.q_proj.lora_B.default.weight
Difference: 0.03588492050766945
MISMATCH: model.layers.34.self_attn.v_proj.lora_A.default.weight
Difference: 0.06657284498214722
MISMATCH: model.layers.34.self_attn.v_proj.lora_B.default.weight
Difference: 0.02409064956009388
MISMATCH: model.layers.35.self_attn.q_proj.lora_A.default.weight
Difference: 0.05436292663216591
MISMATCH: model.layers.35.self_attn.q_proj.lora_B.default.weight
Difference: 0.03016229160130024
MISMATCH: model.layers.35.self_attn.v_proj.lora_A.default.weight
Difference: 0.07965952903032303
MISMATCH: model.layers.35.self_attn.v_proj.lora_B.default.weight
Difference: 0.019780777394771576
MISMATCH: model.layers.36.self_attn.q_proj.lora_A.default.weight
Difference: 0.055453334003686905
MISMATCH: model.layers.36.self_attn.q_proj.lora_B.default.weight
Difference: 0.03395471349358559
MISMATCH: model.layers.36.self_attn.v_proj.lora_A.default.weight
Difference: 0.06786611676216125
MISMATCH: model.layers.36.self_attn.v_proj.lora_B.default.weight
Difference: 0.020324870944023132
MISMATCH: model.layers.37.self_attn.q_proj.lora_A.default.weight
Difference: 0.06028502434492111
MISMATCH: model.layers.37.self_attn.q_proj.lora_B.default.weight
Difference: 0.03377046808600426
MISMATCH: model.layers.37.self_attn.v_proj.lora_A.default.weight
Difference: 0.07749291509389877
MISMATCH: model.layers.37.self_attn.v_proj.lora_B.default.weight
Difference: 0.0432426817715168
MISMATCH: model.layers.38.cross_attn.q_proj.lora_A.default.weight
Difference: 0.031035492196679115
Matched: model.layers.38.cross_attn.q_proj.lora_B.default.weight
MISMATCH: model.layers.38.cross_attn.v_proj.lora_A.default.weight
Difference: 0.031099166721105576
Matched: model.layers.38.cross_attn.v_proj.lora_B.default.weight
MISMATCH: model.layers.39.self_attn.q_proj.lora_A.default.weight
Difference: 0.0499216690659523
MISMATCH: model.layers.39.self_attn.q_proj.lora_B.default.weight
Difference: 0.03149039298295975
MISMATCH: model.layers.39.self_attn.v_proj.lora_A.default.weight
Difference: 0.0791531428694725
MISMATCH: model.layers.39.self_attn.v_proj.lora_B.default.weight
Difference: 0.030921366065740585
Some LoRA layers did not match.
bbbbb
cuda:0
Length of the updated dataset: 560

system

Today Date: 17 Nov 2024

You are a helpful AI that can generate tikz code from images.
user

This is a picture of a scientific figure Generate LaTeX code that draws this scientific figure using TikZ. Ensure that the LaTeX code is self-contained and does not require any packages except TikZ-related imports. Don't forget to include \usepackage{tikz}! I understand that this is a challenging task, so do your best. Return your result in a ```latex code block.
assistant

\begin{tikzpicture}[scale=1.5]
\draw[->, thick] (-1.5,0) -- (1.5,0);
\draw[->, thick] (0,-1.5) -- (0,1.5);
\draw[->, thick] (0,0) -- (0.5,0.5) -- (0.5,1.5) -- (0,1.5) -- (-0.5,1.5) -- (-0.5,0.5) -- (-0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-0.5) -- (-0.5,-1.5) -- (0,-1.5) -- (0.5,-1.5) -- (0.5,-0.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-1.5) -- (-0.5,-2.5) -- (0,-2.5) -- (0.5,-2.5) -- (0.5,-1.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-2.5) -- (-0.5,-3.5) -- (0,-3.5) -- (0.5,-3.5) -- (0.5,-2.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-3.5) -- (-0.5,-4.5) -- (0,-4.5) -- (0.5,-4.5) -- (0.5,-3.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-4.5) -- (-0.5,-5.5) -- (0,-5.5) -- (0.5,-5.5) -- (0.5,-4.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-5.5) -- (-0.5,-6.5) -- (0,-6.5) -- (0.5,-6.5) -- (0.5,-5.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-6.5) -- (-0.5,-7.5) -- (0,-7.5) -- (0.5,-7.5) -- (0.5,-6.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-7.5) -- (-0.5,-8.5) -- (0,-8.5) -- (0.5,-8.5) -- (0.5,-7.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-8.5) -- (-0.5,-9.5) -- (0,-9.5) -- (0.5,-9.5) -- (0.5,-8.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-9.5) -- (-0.5,-10.5) -- (0,-10.5) -- (0.5,-10.5) -- (0.5,-9.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-10.5) -- (-0.5,-11.5) -- (0,-11.5) -- (0.5,-11.5) -- (0.5,-10.5) -- (0.5,0) -- (0,0) -- cycle;
\draw[->, thick] (0,0) -- (-0.5,-11
########################################################
Error: Could not locate LaTeX code markers.
Processing sample 1/560 - Caption: The image depicts a segmented line representing a discretized interval from \( x = 0 \) to \( x = 1 \). The interval is divided into \( N \) segments, each of length \( \Delta x = 1/N \). The points along the line are labeled with their corresponding positions \( x = m \Delta x \) for \( m = 0, 1, 2, \ldots, N \). Below the line, two rows of indices are shown: the global index \( j \) and the interior index \( k \). The global index \( j \) ranges from 1 to \( N+1 \), while the interior index \( k \) ranges from 1 to \( N-1 \). The correspondence between the global and interior indices is indicated, with specific points highlighted such as \( x = 0 \) (global index \( j = 1 \)), \( x = \Delta x \) (global index \( j = 2 \), interior index \( k = 1 \)), and so on, up to \( x = 1 \) (global index \( j = N+1 \)).
TEX Edit Distance for sample 1: 0.8007503747940063
CrystalBLEU Score for sample 1: 0
Sample 1 processing time: 129.92 seconds

Processing sample 2/560 - Caption: This image depicts a directed graph with six nodes and various directed edges, including both solid and dashed lines. The nodes are labeled as follows: \( V_1 (H, a) \), \( V_2 (x) \), \( V_3 (\tilde{x}) \), \( V_4 (L) \), \( V_5 (L) \), and \( V_6 (G, \tilde{c}) \). The edges are as follows:

1. A solid edge from \( V_1 \) to \( V_2 \).
2. A solid edge from \( V_1 \) to \( V_3 \).
3. A solid edge from \( V_2 \) to \( V_4 \).
4. A solid edge from \( V_3 \) to \( V_4 \).
5. A solid edge from \( V_4 \) to \( V_6 \).
6. A solid edge from \( V_5 \) to \( V_6 \).
7. A dashed edge from \( V_1 \) to \( V_4 \).
8. A dashed edge from \( V_2 \) to \( V_5 \).
9. A dashed edge from \( V_3 \) to \( V_6 \).
10. A dashed edge from \( V_4 \) to \( V_5 \).

The nodes are arranged in a roughly horizontal layout, with \( V_1 \) on the left, \( V_6 \) on the right, and the other nodes positioned between them. The edges are directed and some are curved to avoid overlapping with other edges.
TEX Edit Distance for sample 2: 0.8213337063789368
CrystalBLEU Score for sample 2: 0
Sample 2 processing time: 56.63 seconds

Processing sample 3/560 - Caption: This image is a line plot with three datasets: Multi-News, SamSUM, and CNN/DM. The x-axis represents the dataset size on a logarithmic scale, ranging from \(10^3\) to \(10^5\). The y-axis represents the average value, ranging from 0.5 to 0.7. The plot includes three lines: a blue line with square markers for Multi-News, a red line with triangle markers for SamSUM, and a green line with star markers for CNN/DM. The legend is located inside the plot area, towards the right side. The grid lines are visible for better readability.
TEX Edit Distance for sample 3: 0.6039854288101196
CrystalBLEU Score for sample 3: 0.0034535291172925297
Sample 3 processing time: 155.15 seconds

Processing sample 4/560 - Caption: The image shows a graphical representation of the operation on two structures, Σ(z₁) and Σ(z₂), resulting in a combined structure Σ(z₁) ⊕ Σ(z₁). On the left side, there are two separate structures, each consisting of a circle connected to a smaller circle above it, labeled Σ(z₁) and Σ(z₂) respectively. These structures are combined using the ⊕ operator. On the right side, the resulting structure is shown, which is a larger structure with three levels of circles. The bottom level has two circles, each connected to a smaller circle above it, and these two smaller circles are connected to a single circle at the top. The label Σ(z₁) ⊕ Σ(z₁) is placed below the combined structure.
TEX Edit Distance for sample 4: 0.8098483085632324
CrystalBLEU Score for sample 4: 0.00013054500194862516
Sample 4 processing time: 227.33 seconds

Processing sample 5/560 - Caption: The image shows a two-panel plot comparing simulated and theoretical coalescence times under weak and strong selection. The left panel is titled "Coalescence times" and is divided into two regions: weak selection on the left and strong selection on the right. The x-axis is labeled with the selection coefficient (α), ranging from 0 to 1, while the y-axis is labeled with the expected coalescence time (E[T2]) ranging from 0 to 15. The black dots represent simulated data (N = 10^3), and the green curve represents the theoretical values. The right panel, partially visible, seems to follow a similar structure but with different y-axis values.
TEX Edit Distance for sample 5: 0.8362126350402832
CrystalBLEU Score for sample 5: 1.3506255606654391e-10
Sample 5 processing time: 308.73 seconds

Processing sample 6/560 - Caption: This image consists of two Hasse diagrams side by side. The diagram on the left, labeled \( P \), is a diamond-shaped poset with four elements: \( a \) at the bottom, \( b \) and \( c \) in the middle, and \( d \) at the top. The elements are connected by lines indicating the partial order: \( a \leq b \), \( a \leq c \), \( b \leq d \), and \( c \leq d \).

The diagram on the right, labeled \( \text{Int} \, P \), represents the interval poset of \( P \). It has nine elements, each representing an interval in \( P \): \([a,a]\), \([a,b]\), \([a,c]\), \([b,b]\), \([b,d]\), \([c,c]\), \([c,d]\), \([d,d]\), and \([a,d]\). These intervals are connected by lines indicating the partial order among them. The structure forms a more complex lattice with multiple levels, reflecting the intervals' relationships.
TEX Edit Distance for sample 6: 0.7183455228805542
CrystalBLEU Score for sample 6: 1.3512403779306646e-15
Sample 6 processing time: 77.50 seconds

Processing sample 7/560 - Caption: The figure is a line plot showing the impact of batch size on inference speedups. The x-axis represents the batch size, ranging from 1 to 16, while the y-axis represents the speedup, ranging from 1 to 5. Multiple lines, each with different colors and markers, represent different configurations or models. A legend on the top right corner identifies these configurations. A vertical dashed line at batch size 8 highlights a specific point of interest.
TEX Edit Distance for sample 7: 0.7904283404350281
CrystalBLEU Score for sample 7: 1.3307112556663067e-15
Sample 7 processing time: 205.21 seconds

Processing sample 8/560 - Caption: The image illustrates a sequence of transformations of intersecting lines. 

1. The top part shows a set of horizontal and vertical lines labeled with numbers. The horizontal lines are labeled "n", "n-2", "n-4", ..., "1" from top to bottom, and the vertical lines are labeled "1".
2. An arrow points downward to the middle part, where the lines are rotated to form an "X" pattern. The lines are labeled similarly, with horizontal lines labeled "1" and "n-2", and vertical lines labeled "1" and "n-6".
3. Another arrow points downward to the bottom part, where the lines are further transformed into a symmetric "X" pattern. The lines are labeled "1" and "1", with the horizontal lines in black and the diagonal lines in red.

The image can be described in TikZ with the following elements:
- Horizontal and vertical lines with labels.
- Rotated lines forming an "X" pattern.
- Symmetric "X" pattern with different colors for the lines.
- Arrows indicating the transformation steps.
TEX Edit Distance for sample 8: 0.6787763833999634
CrystalBLEU Score for sample 8: 6.540043399862905e-14
Sample 8 processing time: 25.71 seconds

Processing sample 9/560 - Caption: This image depicts a triangular plot contained within a rectangular frame. The plot consists of two diagonal lines forming an inverted "V" shape, with tick marks and labels along both lines. The labels are positioned at regular intervals along the lines, indicating specific values. The entire plot is enclosed within a smaller rectangle, which is centered within a larger rectangular border. The larger rectangle appears to be the boundary of the entire figure, while the smaller rectangle serves as the frame for the triangular plot.
TEX Edit Distance for sample 9: 0.8106427192687988
CrystalBLEU Score for sample 9: 6.70633381045537e-14
Sample 9 processing time: 183.71 seconds

Processing sample 10/560 - Caption: The image depicts a geometric representation of complex numbers. It shows a series of ellipses increasing in size along the positive real axis, labeled as \(|z|^2\). The ellipses are aligned along a line starting from the origin (0), which is marked by a solid black dot. The x-axis is labeled with \(|z|^2\) to indicate the squared magnitude of the complex number \(z\). The ellipses are positioned at regular intervals along this axis, with their major axes increasing linearly.
TEX Edit Distance for sample 10: 0.6644829511642456
CrystalBLEU Score for sample 10: 9.417849811277802e-12
Sample 10 processing time: 111.10 seconds

Processing sample 11/560 - Caption: This image is a line plot depicting the relationship between sentence length and two performance metrics: "Matched Words" and "Exact Sentences." The x-axis represents sentence length, ranging from 0 to 60, while the y-axis represents the proportion, ranging from 0 to 1. Two lines are plotted: a blue line for "Matched Words" and a red line for "Exact Sentences." The blue line starts near the top of the y-axis and remains relatively high, showing a slight downward trend as sentence length increases. The red line starts high but decreases sharply as sentence length increases, approaching zero around a sentence length of 50. A legend in the bottom left corner identifies the blue and red lines. The plot has a title "Performance Metrics vs. Sentence Length" and includes grid lines for better readability.
TEX Edit Distance for sample 11: 0.8341665863990784
CrystalBLEU Score for sample 11: 8.740905378399632e-12
Sample 11 processing time: 185.44 seconds

Processing sample 12/560 - Caption: The image consists of three distinct diagrams, each depicting a different colored path with labeled points and segments. 

1. The leftmost diagram is in red and shows a path with points labeled \(a\) and \(b\). The path has a horizontal dashed line segment labeled \(H\) connecting the points. The path starts from a point labeled \(R\) and ends at \(b\).

2. The middle diagram is in black and shows a similar path with points labeled \(a\) and \(b\). The path has a horizontal dashed line segment labeled \(\bar{H}\) connecting the points. The path starts from a point labeled \(\bar{R}\) and ends at \(b\).

3. The rightmost diagram is in blue and shows a path with points labeled \(t(a)\) and \(t(b)\). The path starts from a point labeled \(B'\) and ends at \(t(a)\).

Each diagram features a combination of straight and angled lines, with specific points marked by colored dots. The dashed lines in each diagram indicate a horizontal connection between the points \(a\) and \(b\).
TEX Edit Distance for sample 12: 0.4707052707672119
CrystalBLEU Score for sample 12: 1.0465121429985566e-08
Sample 12 processing time: 134.13 seconds

Processing sample 13/560 - Caption: This image contains a series of graph transformations labeled \( F_1(n) \) through \( F_{11}(n) \). Each transformation shows a different configuration of nodes and edges, with some nodes labeled with letters (e.g., X, Y) and others with numbers (e.g., 1, 2, 3). The transformations illustrate the progression of the graph structure through various stages:

1. \( F_1(n) \) shows a triangle with nodes 1, 2, and 3 connected in a cycle, and a separate node X connected to node 1.
2. \( F_2(n) \) shows node X connected to a triangle formed by nodes 1, 2, and 3.
3. \( F_3(n) \) shows node X connected to a cycle of three nodes labeled 1, 2, and 3.
4. \( F_4(n) \) shows node X connected to a path of three nodes labeled 1, 2, and 3.
5. \( F_5(n) \) shows node X connected to a path of four nodes labeled 1, 2, 3, and 4.
6. \( F_6(n) \) shows node X connected to a path of five nodes labeled 1, 2, 3, 4, and 5.
7. \( F_7(n) \) shows node X connected to a path of six nodes labeled 1, 2, 3, 4, 5, and 6.
8. \( F_8(n) \) shows node X connected to a path of seven nodes labeled 1, 2, 3, 4, 5, 6, and 7.
9. \( F_9(n) \) shows node X connected to a path of eight nodes labeled 1, 2, 3, 4, 5, 6, 7, and 8.
10. \( F_{10}(n) \) shows node X connected to a path of nine nodes labeled 1, 2, 3, 4, 5, 6, 7, 8, and 9.
11. \( F_{11}(n) \) shows node X connected to a path of ten nodes labeled 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10.

Each graph transformation is enclosed in an oval or circle, indicating the scope of the transformation. The nodes and edges are clearly labeled to show the progression from one stage to the next.
TEX Edit Distance for sample 13: 0.851285457611084
CrystalBLEU Score for sample 13: 3.2777100755867335e-10
Sample 13 processing time: 282.84 seconds

Processing sample 14/560 - Caption: The image is a bar chart displaying the number of students on the y-axis and a range of scores on the x-axis. The x-axis is labeled with score intervals, each represented by a blue bar. Two specific score intervals are highlighted with different colors: one in red and one in green. The chart includes a legend at the bottom indicating that the green bar represents "ChatGPT," the red bar represents "BingChat," and the blue bars represent "Estudiantes evaluados." The y-axis is labeled with a logarithmic scale (10^0 to 10^4), and each bar has a numerical value displayed at its top.
TEX Edit Distance for sample 14: 0.6412129402160645
CrystalBLEU Score for sample 14: 1.924646100996935e-08
Sample 14 processing time: 195.88 seconds

Processing sample 15/560 - Caption: The image depicts a graph with 10 vertices arranged in a decagon. Each vertex on the decagon is connected to its adjacent vertices with black edges. Additionally, there is a central vertex connected to all vertices of the decagon with red edges. The vertices are represented by black-filled circles.

This description should help you write the TikZ code for the figure.
TEX Edit Distance for sample 15: 0.6863536834716797
CrystalBLEU Score for sample 15: 3.288396827468642e-08
Sample 15 processing time: 102.59 seconds

Processing sample 16/560 - Caption: This image depicts a complex plane diagram with two semicircles centered at the origin. The horizontal axis represents the real part of the complex plane, marked with a "0" at the origin. There are two semicircles with different radii, both centered at the origin and extending upwards. The smaller semicircle is labeled with "it_n" at its highest point, and there are two dots vertically aligned along the imaginary axis, one at the origin and the other at the label "it_n".
TEX Edit Distance for sample 16: 0.7919646501541138
CrystalBLEU Score for sample 16: 2.8606342735391267e-08
Sample 16 processing time: 220.33 seconds

Processing sample 17/560 - Caption: This image depicts a sequence of sets \( V_1, V_2, \ldots, V_{\beta+1} \) represented by ellipses. Each set contains points labeled \( v, x_\beta, y_\beta, y_1, x_1, u \). There are directed arrows between these points indicating transitions or connections. A red path labeled \( P_1 \) and a blue dashed path labeled \( P_2 \) connect these points across the sets. The red path \( P_1 \) seems to form a continuous connection through the points \( v, x_\beta, y_\beta, y_1, x_1, u \), while the blue dashed path \( P_2 \) forms a similar connection but with a different trajectory. An arrow pointing to the right indicates progression from \( V_1 \) to \( V_{\beta+1} \).
TEX Edit Distance for sample 17: 0.6878848075866699
CrystalBLEU Score for sample 17: 3.006027721318485e-08
Sample 17 processing time: 97.07 seconds

Processing sample 18/560 - Caption: This image depicts a rectangular region in the \(u\)-\(T\) plane, labeled with boundaries and specific points. The vertical axis is labeled \(u\) and the horizontal axis is labeled \(T\). The rectangle is defined by the points \((1, \epsilon)\), \((T_0, \epsilon)\), \((T_0, A)\), and \((1, A)\). The boundaries of the rectangle are labeled as \(\Gamma_1\), \(\Gamma_2\), \(\Gamma_3\), and \(\Gamma_4\), with arrows indicating the direction along each boundary. The point \((1, \epsilon)\) is marked with dashed lines extending to the axes. The interior of the rectangle is labeled with \(u\).
TEX Edit Distance for sample 18: 0.8058077096939087
CrystalBLEU Score for sample 18: 2.4138450503229777e-08
Sample 18 processing time: 165.43 seconds

Processing sample 19/560 - Caption: The image consists of two parts. On the left, there is a diagram with vertical lines labeled "B" on both sides, and between them, there are horizontal lines labeled with numbers 3, 2, and dots representing "n+1". On the right, there is a graph with nodes labeled 1, 2, and 3. The central node labeled 3 is connected to nodes labeled 2, which are further connected to nodes labeled 1. The central node 3 is also connected to another node labeled 3, which is connected to nodes labeled 2 and 1, forming a symmetrical structure. An arrow points from the left diagram to the right graph, indicating a transformation from the left structure to the right structure.
TEX Edit Distance for sample 19: 0.8439515829086304
CrystalBLEU Score for sample 19: 1.0026631788871793e-08
Sample 19 processing time: 317.13 seconds

Processing sample 20/560 - Caption: This image depicts the architecture of a Gated Recurrent Unit (GRU) cell. The main components and their connections are as follows:

1. **Inputs and Outputs:**
   - Input \( x(t) \) enters from the bottom.
   - Previous hidden state \( h(t-1) \) enters from the left.
   - Current hidden state \( h(t) \) exits to the right.
   - Current output \( y(t) \) exits from the top.

2. **Components:**
   - Two fully connected (FC) layers, represented by blue rectangles.
   - Update gate \( z(t) \) and reset gate \( r(t) \).
   - Element-wise multiplication, represented by circles with a cross (×).
   - Element-wise addition, represented by circles with a plus (+).
   - Sigmoid activation functions, represented by the sigmoid curve symbol.

3. **Connections:**
   - \( x(t) \) and \( h(t-1) \) are inputs to both FC layers.
   - Outputs of the FC layers are used to compute \( r(t) \) and \( z(t) \).
   - \( r(t) \) is used to modulate \( h(t-1) \) before passing it to the next FC layer.
   - The result of the FC layer modulated by \( r(t) \) is combined with \( x(t) \) to compute the candidate hidden state.
   - The final hidden state \( h(t) \) is computed using a combination of the candidate hidden state and \( h(t-1) \), modulated by \( z(t) \).

This description should help in writing the TikZ code to accurately represent the GRU cell structure.
TEX Edit Distance for sample 20: 0.5068013072013855
CrystalBLEU Score for sample 20: 3.116287965136755e-08
Sample 20 processing time: 159.88 seconds

Processing sample 21/560 - Caption: This image depicts a 3D geometric shape resembling a crystal or diamond. The shape is composed of multiple triangular and quadrilateral faces. The edges of the shape are outlined in red, while the faces are filled with a light blue color. The overall structure is symmetrical along its vertical axis, with the top and bottom parts tapering to a point. The central section of the shape has a more complex arrangement of faces, creating a faceted appearance.
TEX Edit Distance for sample 21: 0.8196677565574646
CrystalBLEU Score for sample 21: 1.9491922001704487e-08
Sample 21 processing time: 315.43 seconds

Processing sample 22/560 - Caption: This image depicts a set of rays emanating from the origin in a coordinate plane. The rays are labeled with various mathematical expressions involving the function \( D \). The labels are positioned at the ends of the rays. The rays are distributed in the first and fourth quadrants, with some rays being solid lines and others being dotted lines. The axes are labeled with \( D(1) \) on the positive y-axis and \( D(2) \) on the positive x-axis. Additional labels include \( D\left(\frac{1}{2}\right) \), \( D\left(\frac{1}{22}\right) \), \( D(\tau^{-1}(2)) \), \( D\left(\frac{1}{2}(d, \lambda)\right) \), and \( D\left(\frac{11}{2}\right) \).

To create this figure using TikZ, you would need to:
1. Draw the x-axis and y-axis.
2. Draw multiple rays emanating from the origin at different angles.
3. Label the ends of the rays with the specified mathematical expressions.
4. Use solid and dotted lines for different rays as shown in the image.
TEX Edit Distance for sample 22: 0.8150118589401245
CrystalBLEU Score for sample 22: 1.613855560098807e-08
Sample 22 processing time: 228.44 seconds

Processing sample 23/560 - Caption: This image appears to be a grid of 4x4 spheres, each labeled with various variables and symbols. The spheres are color-coded and contain different mathematical notations. The first column contains spheres labeled with variables \(x\), \(y\), and \(z\) in red, blue, and cyan respectively. The second to fourth columns contain spheres with overlapping colored regions and additional labels such as \(a\), \(b\), \(g\), and \(f\). There are arrows pointing from the first column to the second column, indicating a transformation or mapping, with labels \(O_{0000}\) and \(O_{000}\). The symbols \( \subseteq \) are used between the columns to indicate inclusion or subset relationships. The entire grid is annotated with a number (1) on the right side.

To write the TikZ code for this figure, you would need to create a 4x4 grid of nodes, draw spheres at each node, label them appropriately, and use arrows and subset symbols to indicate the relationships between the spheres. The color coding and overlapping regions would also need to be replicated.
TEX Edit Distance for sample 23: 0.6610702872276306
CrystalBLEU Score for sample 23: 8.230747318337381e-08
Sample 23 processing time: 105.75 seconds

Processing sample 24/560 - Caption: The figure illustrates a positive consumption externality in the energy-efficient housing market. The x-axis represents the quantity of energy-efficient housing, while the y-axis represents the price, costs, and benefits in yen. The graph includes the following curves:

1. **MPB (Marginal Private Benefit)**: A downward-sloping red line.
2. **MSB (Marginal Social Benefit)**: A downward-sloping blue line, above the MPB curve.
3. **MPC (Marginal Private Cost) = MSC (Marginal Social Cost)**: An upward-sloping blue line.
4. **MEB (Marginal External Benefit)**: A vertical distance between the MPB and MSB curves, marked with an orange double arrow.

The equilibrium without externality (E1) is at the intersection of the MPB and MPC curves, with a corresponding quantity Qm and price Pm. The socially optimal equilibrium (Es) is at the intersection of the MSB and MSC curves, with a corresponding quantity Qopt and price Psot.

The welfare loss, represented by a green triangle, is the area between the MPB and MSB curves from Qm to Qopt.
TEX Edit Distance for sample 24: 0.5803923010826111
CrystalBLEU Score for sample 24: 3.908009591363652e-07
Sample 24 processing time: 52.19 seconds

Processing sample 25/560 - Caption: This image depicts a geometric configuration involving three vertical lines at positions \(x_{k-1}\), \(x_k\), and \(x_{k+1}\) labeled \(C_{k-1}\), \(C_k\), and \(C_{k+1}\) respectively. The line at \(x_k\) has several angles and vectors emanating from it. The vectors \(U_{\Gamma}^{(\tau)}\), \(U_{\Gamma}\), \(U_I\), and \(U_B\) are shown, with \(U_{\Gamma}^{(\tau)}\) and \(U_{\Gamma}\) drawn in blue. The angles \(\alpha_1\) and \(\beta_1\) are marked between these vectors. The top of the lines \(C_{k-1}\) and \(C_k\) are connected by a slanted line, and the top of \(C_k\) and \(C_{k+1}\) are connected similarly. The lines \(C_{k-1}\) and \(C_{k+1}\) have hatching patterns on the top sections.
TEX Edit Distance for sample 25: 0.6607410311698914
CrystalBLEU Score for sample 25: 4.467831083050078e-07
Sample 25 processing time: 8.87 seconds

Processing sample 26/560 - Caption: This image depicts a decision tree diagram used to model the process of claim settlement and payment. The diagram is divided into two main sections: "Settlement" and "Payment." 

1. The "Settlement" section has a single decision node labeled "1. settlement."
2. The "Payment" section is further divided into two branches based on the outcome of the settlement:
   - If "Yes," there are two decision nodes labeled "2. payment" and "3. pct_paid."
   - If "No," there are two decision nodes labeled "2. payment" and "3. increase_paid."

The diagram includes labels for "Initial claim characteristics" and "Updates" on the left side, indicating the factors influencing the decision process. The structure is organized in a tabular format with clear horizontal and vertical lines separating the different sections and decision nodes.

This description can help in writing the TikZ code by providing a clear understanding of the hierarchical structure and labeling of the decision nodes.
TEX Edit Distance for sample 26: 0.7035142779350281
CrystalBLEU Score for sample 26: 5.528716604073859e-07
Sample 26 processing time: 13.13 seconds

Processing sample 27/560 - Caption: This image depicts a coordinate system with the x1-axis and x2-axis, ranging from -2 to 2 on both axes. The background is divided into two regions: the left half is shaded in red and the right half in green. The x1-axis is labeled with points a(t_min) at -1 and a(t_max) at 1. There is a semicircular arc labeled Γ centered at the origin, spanning from a(t_min) to a(t_max). The axes are labeled with x1 and x2, and there are tick marks at each integer value on both axes.
TEX Edit Distance for sample 27: 0.8211050629615784
CrystalBLEU Score for sample 27: 4.7440561201515526e-07
Sample 27 processing time: 70.52 seconds

Processing sample 28/560 - Caption: This image is a plot of two probability density functions (PDFs) over the same range of values for "Feature Y" on the x-axis and "Count" on the y-axis. The first PDF is represented by a blue dashed line, peaking around 0, and the second PDF is represented by a red solid line, peaking around 1. The x-axis ranges from -2 to 3, and the y-axis ranges from 0 to 0.8. The plot includes axis labels for both the x-axis ("Feature Y") and the y-axis ("Count").
TEX Edit Distance for sample 28: 0.6827072501182556
CrystalBLEU Score for sample 28: 6.526465659155173e-07
Sample 28 processing time: 70.54 seconds

Processing sample 29/560 - Caption: The image depicts a horizontal number line centered at 0, extending from -2 to 2. The number line is labeled with tick marks at intervals of 0.5 units. The x-axis is denoted by \( x \) at the far right end. The tick marks are labeled with the corresponding values: -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, and 2. The arrow at the right end of the number line indicates the positive direction of the x-axis.
TEX Edit Distance for sample 29: 0.5976349115371704
CrystalBLEU Score for sample 29: 1.2213991736084533e-06
Sample 29 processing time: 13.50 seconds

Processing sample 30/560 - Caption: This image depicts a block diagram with five rectangular blocks and labeled arrows. Four blocks are aligned vertically on the left side, each labeled with \( w(t-2) \), \( w(t-1) \), \( w(t+1) \), and \( w(t+2) \). Each of these blocks has an arrow pointing to a central block labeled "SUM". The central "SUM" block has an arrow pointing to a fifth block on the right side, labeled \( w(t) \). This diagram represents a summation process where the inputs from the four left blocks are combined in the SUM block to produce an output in the right block.
TEX Edit Distance for sample 30: 0.5965340733528137
CrystalBLEU Score for sample 30: 2.0311898476203833e-06
Sample 30 processing time: 15.98 seconds

Processing sample 31/560 - Caption: This scatter plot compares the probability bounds \( p \) obtained from a Program-Agnostic Neural ISM (x-axis) to those obtained from Farkas' Lemma (y-axis). The x-axis and y-axis are both on a logarithmic scale ranging from \( 10^{-3} \) to \( 10^0 \). The plot includes a dashed line representing \( y = x \) for reference. Data points are marked with red circles and red crosses, where circles indicate cases where Farkas' Lemma fails and crosses indicate cases where Farkas' Lemma succeeds. A legend in the plot explains the symbols used.
TEX Edit Distance for sample 31: 0.6683176755905151
CrystalBLEU Score for sample 31: 3.1034720226465525e-06
Sample 31 processing time: 26.23 seconds

Processing sample 32/560 - Caption: The image shows a circular diagram with two concentric circles. The outer circle is divided into 12 equal segments, each labeled with \(B_1\) to \(B_{12}\). The inner circle is divided into 8 equal segments, each labeled with \(B_1\) to \(B_8\). The segments are separated by radial lines extending from the center of the circles to their peripheries. The labels are placed near the outer edge of each segment.
TEX Edit Distance for sample 32: 0.6907451152801514
CrystalBLEU Score for sample 32: 4.064695061883094e-06
Sample 32 processing time: 15.44 seconds

Processing sample 33/560 - Caption: This image depicts a geometric configuration involving three vertical lines at positions \(x_{k-1}\), \(x_k\), and \(x_{k+1}\) labeled \(C_{k-1}\), \(C_k\), and \(C_{k+1}\) respectively. The line at \(x_k\) has several angles and vectors emanating from it. The vectors \(U_{\Gamma}^{(\tau)}\), \(U_{\Gamma}\), \(U_I\), and \(U_B\) are shown, with \(U_{\Gamma}^{(\tau)}\) and \(U_{\Gamma}\) drawn in blue. The angles \(\alpha_1\) and \(\beta_1\) are marked between these vectors. The top of the lines \(C_{k-1}\) and \(C_k\) are connected by a slanted line, and the top of \(C_k\) and \(C_{k+1}\) are connected similarly. The lines \(C_{k-1}\) and \(C_{k+1}\) have hatching patterns on the top sections.
TEX Edit Distance for sample 33: 0.8388916254043579
CrystalBLEU Score for sample 33: 3.264429088066524e-06
Sample 33 processing time: 70.57 seconds

Processing sample 34/560 - Caption: The image shows three small graphs with labeled vertices and edges. 

1. The first graph on the left has two vertices: \( y_3 \) (filled circle) at the top and \( z_1 \) (square) at the bottom. There is a vertical edge connecting \( y_3 \) and \( z_1 \). The coordinates \( (2,3) \) are written next to \( y_3 \).

2. The second graph in the middle has three vertices: \( y_5 \) (empty circle) at the top, \( y_4 \) (filled circle) in the middle, and \( y_1 \) (filled circle) at the bottom. There are vertical edges connecting \( y_5 \) to \( y_4 \) and \( y_4 \) to \( y_1 \). The coordinates \( (1,0) \) are written next to \( y_5 \), and \( (3,1) \) are written next to \( y_1 \).

3. The third graph on the right has two vertices: \( y_6 \) (empty circle) at the top and \( y_2 \) (filled circle) at the bottom. There is a vertical edge connecting \( y_6 \) and \( y_2 \). The coordinates \( (0,3) \) are written next to \( y_6 \).

All vertices and edges are aligned vertically, and the labels are positioned near the vertices.
TEX Edit Distance for sample 34: 0.6472383737564087
CrystalBLEU Score for sample 34: 5.229991636351347e-06
Sample 34 processing time: 17.38 seconds

Processing sample 35/560 - Caption: The image depicts a mathematical diagram with several elements:

1. **Background**: A rectangular grid with a light green background.
2. **Axes**: The center of the grid is marked with a black dot labeled "0".
3. **Curves**: 
   - A black curve passing through the center.
   - Two additional curves, one labeled \(\psi^+\) (in purple) and another labeled \(\psi^-\) (in blue), intersecting the black curve.
4. **Arrows**: 
   - Red arrows pointing upwards along vertical lines.
   - Purple and blue arrows along the curves \(\psi^+\) and \(\psi^-\), respectively, indicating direction.
5. **Labels**: 
   - The label \(\Psi_z(W_z) = [-1,1]^2\) on the left side.
   - The label \(\Psi_z(X \cap W_z)\) on the right side.
6. **Vertical Lines**: Red vertical lines spaced evenly across the grid.

This description should help in writing the TikZ code to replicate the figure.
TEX Edit Distance for sample 35: 0.834838330745697
CrystalBLEU Score for sample 35: 2.4149247436701585e-06
Sample 35 processing time: 70.84 seconds

Processing sample 36/560 - Caption: Caption: "The image depicts a logarithmic spiral created using a series of interconnected lines. The spiral starts from the center and expands outward, with the lines forming a mesh-like pattern. The color of the lines is a gradient of blue, becoming lighter as they move outward from the center."

This description should help you understand the structure and color gradient of the spiral for writing the TikZ code.
TEX Edit Distance for sample 36: 0.807107150554657
CrystalBLEU Score for sample 36: 2.175466577705691e-06
Sample 36 processing time: 70.47 seconds

Processing sample 37/560 - Caption: This image depicts a hierarchical tree structure with multiple levels of nodes and connections. At the top, there is a single node labeled \( \nu_c \) within an oval labeled \( \Omega_n \). This top node connects to a middle layer of nodes contained within a larger oval, labeled \( \Omega_g \cup \Omega_{nb} \). Each node in this middle layer is connected to several nodes in the bottom layer, which are grouped into three separate ovals labeled \( \Omega_p \). The nodes and connections are represented by black dots and lines, respectively. The structure illustrates a clear hierarchical relationship among the nodes, with the top node branching out to multiple nodes in the middle layer, which in turn branch out to multiple nodes in the bottom layer.
TEX Edit Distance for sample 37: 0.6579278707504272
CrystalBLEU Score for sample 37: 3.0028038546728454e-06
Sample 37 processing time: 14.18 seconds

Processing sample 38/560 - Caption: This bar chart compares the accuracy of five different methods: MLP, WL-Kernel, FEATHER, SLaq-LSD, and SLaq-VGNE. The y-axis represents accuracy, ranging from 0.00 to 1.00. Each bar is labeled with its corresponding accuracy value: MLP (0.8054), WL-Kernel (0.7053), FEATHER (0.8488), SLaq-LSD (0.7790), and SLaq-VGNE (0.5590). The bars are colored blue, and the x-axis labels are rotated for better readability.
TEX Edit Distance for sample 38: 0.6544362306594849
CrystalBLEU Score for sample 38: 3.936448142383988e-06
Sample 38 processing time: 14.39 seconds

Processing sample 39/560 - Caption: The image depicts a diagram consisting of two vertical columns of dots, each containing six dots. These columns are connected by various curved lines. The left column has three pairs of dots connected by semicircular arcs on the left side. The right column has three pairs of dots connected by semicircular arcs on the right side. Additionally, there are curved lines connecting dots between the two columns. One of these lines crosses over another. At the top right, there is a rectangular box labeled "2" connected to the second dot from the top in the right column. Below the diagram, the letter "D" is centered.
TEX Edit Distance for sample 39: 0.8088246583938599
CrystalBLEU Score for sample 39: 2.478872516990936e-06
Sample 39 processing time: 70.69 seconds

Processing sample 40/560 - Caption: The image displays a single red circle centered on a white background. There is a text "The alt" in blue located at the top left corner of the image. 

To create this in TikZ, you would need to:
1. Draw a red circle at the center of the canvas.
2. Place blue text "The alt" at the top left corner of the canvas.

Here is a sample caption for the image:
"A centered red circle with radius 1 unit on a white background. Blue text 'The alt' is positioned at the top left corner of the canvas."

This caption should help you write the corresponding TikZ code.
TEX Edit Distance for sample 40: 0.5776566863059998
CrystalBLEU Score for sample 40: 2.6433403440070066e-06
Sample 40 processing time: 8.11 seconds

Processing sample 41/560 - Caption: This image depicts a sequence of connected subgraphs, each represented by a rectangle labeled \( K_{n,n}^{(i)} - e \), where \( i \) ranges from 1 to \( n \). Each rectangle has a node at the top and bottom left corners, connected by an edge labeled "1". The rectangles are connected in a sequence by edges labeled "1" at the top nodes and by edges labeled "u" at the bottom nodes. The bottom nodes of the rectangles are connected to a central node at the bottom, which connects to the bottom left node of each rectangle. The sequence continues with ellipses indicating the continuation up to the \( n \)-th rectangle.
TEX Edit Distance for sample 41: 0.7972758412361145
CrystalBLEU Score for sample 41: 2.2466956623728272e-06
Sample 41 processing time: 70.64 seconds

Processing sample 42/560 - Caption: This image depicts three distinct graphs \( G \), \( H \), and \( K \) aligned horizontally along a common baseline. The graph \( G \) consists of a diamond shape at the top connected by a vertical path of three edges to the baseline. The edges of the diamond are colored alternately in blue and red. The vertical path connecting the diamond to the baseline consists of two edges labeled \( e_0 \) and \( e_1 \), with \( e_0 \) being the topmost edge. The graph \( H \) is a simple vertical path of three edges, with the top and bottom edges colored red and the middle edge colored blue. The graph \( K \) is a diamond shape similar to the one in \( G \), with alternating blue and red edges, but it is directly on the baseline. All vertices are represented by black dots.
TEX Edit Distance for sample 42: 0.8375917077064514
CrystalBLEU Score for sample 42: 2.0573243017046778e-06
Sample 42 processing time: 70.53 seconds

Processing sample 43/560 - Caption: The image depicts a mathematical operation involving three hexagonal graphs. The first hexagon on the left is labeled with zeros at each vertex and contains dashed lines forming smaller triangles within it. The vertex at the top is labeled as Δ_{1}(1). The middle hexagon is labeled similarly with zeros at each vertex, but it contains solid lines forming a more complex internal structure with additional labels M_{1}(2), M_{1}(4), M_{1}(5), and M_{1}(6) at specific vertices. The operation between the two hexagons is indicated by a multiplication sign (×). The resulting hexagon on the right, labeled with zeros at each vertex, shows a combination of the internal structures from the first two hexagons, forming a more intricate pattern of lines. An equality sign (=) connects the middle and right hexagons, indicating the result of the operation.
TEX Edit Distance for sample 43: 0.8437506556510925
CrystalBLEU Score for sample 43: 1.3456488101653219e-06
Sample 43 processing time: 70.68 seconds

Processing sample 44/560 - Caption: This image depicts a series of geometric transformations and movements. It shows a sequence of squares and circles along a horizontal axis. The squares are rotated 45 degrees and positioned above the circles, with arrows indicating upward movement. The circles are placed along the horizontal axis with dashed circles indicating intermediate positions. Additionally, there are curved arrows below the circles indicating rotational movement. The horizontal axis has tick marks and an arrow pointing to the right, suggesting a positive direction.

To create this image using TikZ, you would need to:
1. Draw the horizontal axis with tick marks and an arrow.
2. Position the circles along the axis, including dashed circles for intermediate positions.
3. Draw the squares rotated at 45 degrees above the circles, with arrows indicating upward movement.
4. Add curved arrows below the circles to indicate rotational movement.
TEX Edit Distance for sample 44: 0.4891134798526764
CrystalBLEU Score for sample 44: 2.6507711693722994e-06
Sample 44 processing time: 33.68 seconds

Processing sample 45/560 - Caption: This image depicts a series of nested and overlapping shapes, each labeled with different terms. Starting from the innermost shape, there are concentric ellipses labeled "stable" and "stable-c" in red. Surrounding these ellipses is a rectangle labeled "PO" and "optimal-c" in blue, and "optimal-cc" in blue. Outside of this rectangle, there is another larger rectangle with diagonal hatching, and outside of this, another rectangle labeled "SWC" on the left and "SWN" on the right, with "LS" at the bottom center. The outermost shape is an ellipse labeled "stable-cc" in red, and the largest rectangle is labeled "CTC" at the top. The labels are color-coded and positioned appropriately to indicate the regions they describe.
TEX Edit Distance for sample 45: 0.7225210070610046
CrystalBLEU Score for sample 45: 4.962564214109867e-06
Sample 45 processing time: 32.49 seconds

Processing sample 46/560 - Caption: This image depicts a flowchart of a neural network training process using automatic differentiation. The flowchart consists of the following components:

1. Two input nodes labeled \( x \) and \( t \) on the left.
2. Two arrows pointing from \( x \) and \( t \) to two separate boxes labeled \( A_u(\theta_u) \) and \( A_{\gamma}(\theta_{\gamma}) \), respectively.
3. The outputs of \( A_u(\theta_u) \) and \( A_{\gamma}(\theta_{\gamma}) \) are connected to a single box containing the equation \( \mathcal{L} = \mathcal{L}_N + \mathcal{L}_B + \mathcal{L}_L + \mathcal{L}_M \).
4. The box containing the loss function \( \mathcal{L} \) has arrows pointing back to the boxes \( A_u(\theta_u) \) and \( A_{\gamma}(\theta_{\gamma}) \) labeled with \( \nabla_{\theta_u} \mathcal{L} \) and \( \nabla_{\theta_{\gamma}} \mathcal{L} \), respectively.
5. The arrows indicating the gradients are labeled "automatic differentiation".

This description should help in writing the TikZ code to create a similar diagram.
TEX Edit Distance for sample 46: 0.803955614566803
CrystalBLEU Score for sample 46: 4.114628670642092e-06
Sample 46 processing time: 70.52 seconds

Processing sample 47/560 - Caption: The image shows three different bipartite graphs with 8 vertices each. Each graph is drawn with black vertices and edges, and red edges to highlight specific connections. The vertices are labeled from 1 to 8.

1. The first graph (left) has vertices arranged in two parallel vertical lines, with edges connecting corresponding vertices across the lines (1-2, 3-4, 5-6, 7-8).
2. The second graph (middle) has vertices arranged in two parallel vertical lines, with edges connecting vertices in a crisscross pattern (1-5, 2-6, 3-7, 4-8).
3. The third graph (right) has vertices arranged in a square grid pattern, with edges connecting vertices in a square and diagonal pattern (1-3, 2-4, 3-5, 4-6, 5-7, 6-8, 7-1, 8-2).

This description should help in writing the TikZ code to recreate these graphs.
TEX Edit Distance for sample 47: 0.8409516215324402
CrystalBLEU Score for sample 47: 2.0856568238375207e-06
Sample 47 processing time: 70.61 seconds

Processing sample 48/560 - Caption: This image depicts a schematic diagram of a computational domain divided into three types of cells: Normal Cell, Intermediate Cell, and Structure Cell. The cells are arranged horizontally and labeled as \(x_{i-2}\), \(x_{i-1}\), and \(x_i\) respectively. The height of the cells is denoted by \(h\). 

- The Normal Cell is on the left, shaded in light blue, and has a force \(F_{i-\frac{1}{2}}\) acting to the right.
- The Intermediate Cell is in the middle, shaded in a slightly darker blue, and has forces \(F_{i-\frac{1}{2}}\) and \(F_{i+\frac{1}{2}}\) acting to the right.
- The Structure Cell is on the right, shaded in the darkest blue, and has forces \(F_{i+\frac{1}{2}}\), \(F_{i+\frac{3}{2}}\), and \(F_{i+\frac{5}{2}}\) acting to the right.

Each force is represented by an arrow pointing to the right. The vertical dashed lines indicate the boundaries between the cells. The top and bottom boundaries of the cells are marked with dashed lines extending horizontally. The labels \(z_{i-2}\), \(z_{i-1}\), and \(z_i\) are positioned along the right side of the cells to indicate vertical positions.
TEX Edit Distance for sample 48: 0.8239015340805054
CrystalBLEU Score for sample 48: 1.6568471239243121e-06
Sample 48 processing time: 70.54 seconds

Processing sample 49/560 - Caption: This image is a plot showing the cumulative distribution function (CDF) of position error (err) in meters on a logarithmic scale for both random and directional estimations. The x-axis is labeled "err [m]" and ranges from \(10^{-2}\) to \(10^{-1}\). The y-axis is labeled "Pr(Position error < err)" and ranges from 0 to 1. There are four curves in the plot:

1. A red dashed line representing "random (Est.)".
2. A red solid line representing "random (PEB)".
3. A black dash-dotted line representing "directional (Est.)".
4. A black solid line representing "directional (PEB)".

A legend is present in the upper right corner of the plot, identifying each line style and color with its corresponding label.
TEX Edit Distance for sample 49: 0.9139338731765747
CrystalBLEU Score for sample 49: 1.1200694261342894e-06
Sample 49 processing time: 71.03 seconds

Processing sample 50/560 - Caption: The image depicts a mathematical diagram with a circle centered at the origin and intersecting the x-axis at two points. The x-axis is marked with several labeled points: \(a_1\), \(a_2\), \(b_1\), \(b_2\), \(c_1\), \(c_2\), \(d_1\), and \(d_2\). The points \(a_1\), \(a_2\), \(c_1\), and \(c_2\) are clustered near the origin, while \(b_1\), \(b_2\), \(d_1\), and \(d_2\) are further to the right. The y-axis is also present, intersecting the x-axis at the origin. There is an arrow indicating a counterclockwise direction around the circle. The points on the x-axis are represented as filled circles, and the circle and axes are drawn with solid lines.
TEX Edit Distance for sample 50: 0.8279967308044434
CrystalBLEU Score for sample 50: 9.984389225226145e-07
Sample 50 processing time: 70.47 seconds

Processing sample 51/560 - Caption: The image depicts a graph with three distinct vertical layers of nodes, each layer containing nodes of a different color. The top layer consists of orange nodes, the middle layer consists of blue nodes, and the bottom layer consists of red nodes. Nodes are connected by black edges, forming a network with connections primarily between adjacent layers. The connections include both vertical and diagonal edges, creating a structured yet interconnected graph.

This description can help in writing the TikZ code by specifying:
1. The positions and colors of the nodes.
2. The connections (edges) between the nodes.
3. The overall layout of the graph.

Here is a sample TikZ code snippet to create a similar graph:

```latex
\documentclass{standalone}
\usepackage{tikz}

\begin{document}
\begin{tikzpicture}

% Define node styles
\tikzstyle{orange node}=[circle, fill=orange, minimum size=6pt, inner sep=0pt]
\tikzstyle{blue node}=[circle, fill=blue, minimum size=6pt, inner sep=0pt]
\tikzstyle{red node}=[circle, fill=red, minimum size=6pt, inner sep=0pt]

% Draw nodes
\node[orange node] (o1) at (0, 6) {};
\node[orange node] (o2) at (0, 5) {};
\node[orange node] (o3) at (0, 4) {};
\node[orange node] (o4) at (0, 3) {};
\node[orange node] (o5) at (1, 4) {};

\node[blue node] (b1) at (0, 2) {};
\node[blue node] (b2) at (0, 1) {};
\node[blue node] (b3) at (1, 2) {};
\node[blue node] (b4) at (1, 1) {};

\node[red node] (r1) at (0, 0) {};
\node[red node] (r2) at (1, 0) {};

% Draw edges
\draw (o1) -- (o2);
\draw (o2) -- (o3);
\draw (o3) -- (o4);
\draw (o4) -- (b1);
\draw (b1) -- (b2);
\draw (b2) -- (r1);
\draw (b4) -- (r2);

\draw (o3) -- (b3);
\draw (o4) -- (b4);
\draw (b1) -- (b3);
\draw (b2) -- (b4);

\draw (o5) -- (b3);
\draw (o5) -- (b4);

\end{tikzpicture}
\end{document}
```

This code will generate a graph similar to the one in the image, with nodes and edges placed accordingly.
TEX Edit Distance for sample 51: 0.8306899070739746
CrystalBLEU Score for sample 51: 9.673412915640168e-07
Sample 51 processing time: 70.43 seconds

Processing sample 52/560 - Caption: The image depicts a circle with four angles labeled θ1, θ2, θ3, and θ4 at the center, denoted as Z. Four arrows labeled t1, t2, t3, and t4 radiate outward from the circle in different directions. The arrows t1 and t3 are aligned horizontally, pointing to the right and left respectively, while t2 and t4 are aligned vertically, pointing upwards and downwards respectively. The angles θ1, θ2, θ3, and θ4 are positioned around the center Z, indicating the directions of the arrows.
TEX Edit Distance for sample 52: 0.6520061492919922
CrystalBLEU Score for sample 52: 1.088275563942516e-06
Sample 52 processing time: 10.36 seconds

Processing sample 53/560 - Caption: This image depicts a decision flowchart with three decision nodes and three outcomes. The flowchart is structured as follows:

1. The first decision node is a rectangle with the question: "Has the number of observed unfavorable outcomes exceeded the pre-determined threshold?" 
   - If the answer is "no," the flowchart leads to the outcome "STOP" in red text.
   - If the answer is "yes," it leads to the next decision node.

2. The second decision node is a rectangle with the question: "Is there an acceptable probability that it matches the target product profile?"
   - If the answer is "no," it leads to the outcome "STOP" in red text.
   - If the answer is "yes," it leads to the next decision node.
   - If the evidence is inadequate, it leads to the outcome "Continue" in yellow text.

3. The third decision node is a dashed rectangle with the question: "Does it rank well?"
   - If the answer is "no," it loops back to the second decision node.
   - If the answer is "yes," it leads to the outcome "GO" in green text.

Arrows indicate the flow of decisions, with "yes" and "no" labels guiding the direction.
TEX Edit Distance for sample 53: 0.6105988621711731
CrystalBLEU Score for sample 53: 1.4892488250131653e-06
Sample 53 processing time: 14.06 seconds

Processing sample 54/560 - Caption: This image is a horizontal bar chart depicting the correlation coefficients (ρ) between a dependent variable (ε) and several independent variables (δ). The independent variables listed on the y-axis are "hours per week," "education-num," "Adm-Clerical (Occupation)," "Exec-managerial (Occupation)," "Craft-repair (Occupation)," and "Priv-house-serv (Occupation)." The corresponding correlation coefficients are displayed at the end of each bar: 0.57, 0.54, 0.52, 0.35, 0.31, and -0.29 respectively. The bars are color-coded in blue, with positive correlations extending to the right and the negative correlation extending to the left. The x-axis ranges from -1 to 1, indicating the possible values of the correlation coefficients.
TEX Edit Distance for sample 54: 0.7995284795761108
CrystalBLEU Score for sample 54: 1.4322483030216313e-06
Sample 54 processing time: 1.01 seconds

Processing sample 55/560 - Caption: The image depicts a graph with 12 vertices and 14 edges. The vertices are represented as black dots, and the edges are represented as black lines connecting the vertices. The graph has a central polygonal structure with additional vertices and edges extending outward, forming a complex, interconnected shape. The vertices and edges vary in length and orientation, creating an irregular, non-symmetric pattern. This graph could be used to represent a network or a complex geometric structure.
TEX Edit Distance for sample 55: 0.6391805410385132
CrystalBLEU Score for sample 55: 1.5526251282642284e-06
Sample 55 processing time: 11.83 seconds

Processing sample 56/560 - Caption: The image shows two identical matrices labeled \( M \). Each matrix is a 2x4 matrix with the following elements:

\[
M = \begin{bmatrix}
1 & 2 & 9 & 3 \\
1 & -3 & -6 & 3
\end{bmatrix}
\]

The matrices are displayed one below the other with some vertical spacing between them. The elements of the matrices are typeset in a standard mathematical font.
TEX Edit Distance for sample 56: 0.8089296817779541
CrystalBLEU Score for sample 56: 1.4953419455832272e-06
Sample 56 processing time: 70.41 seconds

Processing sample 57/560 - Caption: This image depicts a block diagram of an attention mechanism in a sequence-to-sequence model. The diagram includes the following components:

1. **Inputs**: 
   - \( A_1, I_1, \ldots, A_n, I_n \) are input pairs, where \( A_i \) and \( I_i \) are processed by a "TE" (presumably a Token Embedding) and "T" (presumably a Transformer) block respectively.
   - The outputs of these blocks are directed into the "attention" block, resulting in \( V_1, K_1, \ldots, V_n, K_n \).

2. **Attention Block**: 
   - The attention block processes the inputs and outputs the attention vectors.

3. **Decoder**:
   - The attention output is fed into a "TD" (presumably a Transformer Decoder) block.
   - The decoder also takes an initial input sequence \( \text{SOS}, a_1^Q, \ldots, a_{m-1}^Q \) and produces the output sequence \( a_1^Q, \ldots, a_m^Q \).

4. **Additional Inputs**:
   - An additional input \( I_Q \) is processed by a "T" block and fed into the attention block.

The diagram uses arrows to indicate the flow of data between these components, and the blocks are labeled with their respective functions.

This caption should help in writing the TikZ code by identifying the key components and their connections.
TEX Edit Distance for sample 57: 0.7020085453987122
CrystalBLEU Score for sample 57: 3.5104607302952513e-06
Sample 57 processing time: 72.21 seconds

Processing sample 58/560 - Caption: The image shows two hexagonal grids, one smaller and one larger, with labeled vertices. The smaller hexagon on the left is filled with a light green color and labeled "σp+1" at the bottom. Its vertices are labeled with the numbers 1 and 2. The larger hexagon on the right, labeled "σk'+p+1" at the bottom, is composed of multiple smaller hexagons. The central hexagon is also filled with light green and labeled with the number 2, while the surrounding hexagons are filled with light yellow and labeled with numbers in the form of "2k'-1", "2k'", "2k'+1", etc. An arrow labeled "k" points from the smaller hexagon to the larger hexagon, indicating a transformation or expansion process.
TEX Edit Distance for sample 58: 0.6051563024520874
CrystalBLEU Score for sample 58: 4.663153931239468e-06
Sample 58 processing time: 61.22 seconds

Processing sample 59/560 - Caption: The image consists of three squares labeled "A", "B", and "C" from left to right. Each square has a border and contains a letter centered within it. The squares labeled "A" and "C" have a yellow background, while the square labeled "B" has a white background. Each square has a vertical line on both the left and right sides, close to the borders. The squares are evenly spaced horizontally.
TEX Edit Distance for sample 59: 0.6281719207763672
CrystalBLEU Score for sample 59: 5.129162903043216e-06
Sample 59 processing time: 5.75 seconds

Processing sample 60/560 - Caption: The image shows two diamond-shaped graphs side by side. The graph on the left consists of five vertices labeled \(u_1\), \(u_2\), \(u_3\), \(v\), and \(w\). The vertices \(u_1\), \(u_2\), and \(u_3\) form a triangle with \(u_2\) at the top, and \(v\) and \(w\) are connected to \(u_2\) forming a diamond shape. The graph on the right consists of six vertices labeled \(u_1\), \(u_2\), \(u_3\), \(u_4\), \(v\), and \(w\). The vertices \(u_1\), \(u_2\), \(u_3\), and \(u_4\) form a quadrilateral with \(u_2\) and \(u_3\) in the middle, and \(v\) and \(w\) are connected to \(u_2\) and \(u_3\) forming a more complex diamond shape. Both graphs have thick edges.
TEX Edit Distance for sample 60: 0.8138434886932373
CrystalBLEU Score for sample 60: 3.672655375019602e-06
Sample 60 processing time: 70.52 seconds

Processing sample 61/560 - Caption: This image depicts a layered directed graph, commonly used to represent a network or a flowchart. The graph consists of multiple layers of nodes connected by directed edges. The structure is as follows:

1. **Nodes**:
   - There is a single starting node labeled "0" on the left.
   - Multiple layers of nodes follow, each layer containing nodes labeled with a combination of "X" and an index (e.g., X_1, X_2, etc.).
   - The final layer contains nodes labeled with "B" and an index (e.g., B_1, B_2, etc.).

2. **Edges**:
   - Directed edges connect nodes from one layer to the next.
   - The starting node "0" has directed edges to the first node in each subsequent layer.
   - Each node in the intermediate layers has directed edges to the next node in the same layer and possibly to nodes in other layers.

3. **Labels**:
   - Nodes are labeled with indices.
   - Edges are labeled with numbers indicating the order or weight of the connection.

4. **Layout**:
   - The graph is organized in a grid-like structure with nodes aligned vertically and horizontally.
   - The edges are mostly straight lines, with some curved or dashed lines indicating different types of connections.

This structure can be implemented in TikZ using nodes for the vertices and arrows for the directed edges, with appropriate labels for each node and edge.
TEX Edit Distance for sample 61: 0.7944754362106323
CrystalBLEU Score for sample 61: 3.32166874275474e-06
Sample 61 processing time: 70.37 seconds

Processing sample 62/560 - Caption: This image shows five arrows originating from a common point (the origin) and extending outward in different directions. Each arrow is a different color: blue, red, magenta, green, and yellow, arranged in increasing angles from the horizontal axis. The blue arrow is horizontal, the red arrow is at an angle above the blue, followed by the magenta, green, and yellow arrows, each at progressively larger angles from the horizontal axis. The arrows are evenly spaced in terms of their angles.
TEX Edit Distance for sample 62: 0.7163699269294739
CrystalBLEU Score for sample 62: 3.492812205150159e-06
Sample 62 processing time: 6.23 seconds

Processing sample 63/560 - Caption: The image consists of two distinct shapes on a white background. On the left side, there is a solid red circle with a black outline. On the right side, there is a red sector of a circle (a pie slice) with a black outline. The sector appears to be a quarter circle.

This description can help you write the TikZ code to recreate the image.
TEX Edit Distance for sample 63: 0.5679866075515747
CrystalBLEU Score for sample 63: 3.820836532728403e-06
Sample 63 processing time: 6.27 seconds

Processing sample 64/560 - Caption: This image depicts a factor graph with two variable nodes and two factor nodes. The variable nodes, labeled \(X_i\) and \(X_j\), are represented as circles, while the factor nodes, labeled \(C_1\) and \(C_2\), are represented as squares. The variable nodes are connected to the factor nodes by edges, forming a diamond-like shape. The factor nodes are shaded in gray, and the variable nodes are not shaded. The edges connecting the nodes are solid lines.

This description should help in writing the TikZ code to recreate this figure.
TEX Edit Distance for sample 64: 0.8046488761901855
CrystalBLEU Score for sample 64: 3.7366288731637407e-06
Sample 64 processing time: 70.17 seconds

Processing sample 65/560 - Caption: The image shows a semicircle with a black outline positioned above a red line. The semicircle is oriented with its flat edge on top and its curved edge on the bottom. The red line extends from the center of the semicircle's flat edge and continues downward at an angle to the left. The background is a light yellow color.

This description can help in writing the TikZ code by specifying the semicircle's position and orientation, the starting point and angle of the red line, and the background color.
TEX Edit Distance for sample 65: 0.5789473652839661
CrystalBLEU Score for sample 65: 4.290001812027095e-06
Sample 65 processing time: 14.11 seconds

Processing sample 66/560 - Caption: This image depicts a geometric representation of two vectors, \( \hat{A}_d \) and \( \hat{A}_u \), in a coordinate system with axes labeled \( \sigma_1 \) and \( \sigma_3 \). The vectors form two shaded regions: a blue region above the \( \hat{A}_d \) vector and an orange region below it. The angle between \( \hat{A}_d \) and \( \hat{A}_u \) is labeled \( \theta_d \), and the angle between the vector \( \hat{A}_d \times \hat{A}_u \) and the horizontal axis is labeled \( 2\theta_c \). The intersection of the vectors is labeled \( c_{1}\sigma_{2} \sim \hat{A}_d \times \hat{A}_u \). The points \( c_R \), \( X \), and the conditions \( |\Delta C| = 1 \) and \( |\Delta S| = 1 \) are also marked. The vectors and angles are clearly indicated, and the shaded regions are distinguished by different colors.
TEX Edit Distance for sample 66: 0.8095571398735046
CrystalBLEU Score for sample 66: 3.827722534232126e-06
Sample 66 processing time: 70.16 seconds

Processing sample 67/560 - Caption: This image depicts a grid network with horizontal and vertical lines intersecting at nodes. The nodes are represented by black dots. There are two horizontal cuts labeled "Cut A" and "Cut B" at the bottom and top of the grid, respectively. A rectangular box is centered around one of the nodes, labeled \( n_i(t) \). Four nodes adjacent to the central node are labeled with the Greek letter \( \alpha \). The grid lines are thicker at the edges near the cuts and thinner elsewhere.

To create this image using TikZ, you would need to:
1. Draw a grid of lines.
2. Highlight certain nodes with black dots.
3. Label specific nodes with \( \alpha \).
4. Draw a rectangular box around a central node and label it \( n_i(t) \).
5. Add labels "Cut A" and "Cut B" at the appropriate positions on the grid.
TEX Edit Distance for sample 67: 0.6810970306396484
CrystalBLEU Score for sample 67: 3.537004734185493e-06
Sample 67 processing time: 8.61 seconds

Processing sample 68/560 - Caption: This image is a line plot depicting the relationship between the standard deviation (σ) on the x-axis and the average number of steps until convergence (scaled by 10^4) on the y-axis. The plot includes three lines representing different conditions: "resent" (blue), "resent+apprec" (orange), and "apprec" (green). The legend is placed inside the plot area, in the upper left quadrant. The x-axis ranges from 0 to 100, and the y-axis ranges from 0 to 3.5 (scaled by 10^4).
TEX Edit Distance for sample 68: 0.8326359987258911
CrystalBLEU Score for sample 68: 3.3616161029689382e-06
Sample 68 processing time: 70.15 seconds

Processing sample 69/560 - Caption: This image depicts a star polygon (pentagram) inscribed in a circle. The vertices of the pentagram are labeled with the numbers 1, 2, 3, 4, and 5. The intersections of the lines forming the pentagram are labeled with the numbers 14, 13, 24, 35, and 25. The points on the circle that are not vertices of the pentagram are labeled with the numbers 12, 23, 34, 45, and 15. All labels are enclosed in small circles. The entire figure is symmetric and centered around the number 25, which is at the center of the pentagram.
TEX Edit Distance for sample 69: 0.6778749823570251
CrystalBLEU Score for sample 69: 3.5734541840226314e-06
Sample 69 processing time: 10.34 seconds

Processing sample 70/560 - Caption: This image is a bubble chart that represents the relationship between different property keyword categories and the properties optimized. The x-axis is labeled "Property optimised" with categories: Time, Size, Energy, Other, and Memory. The y-axis is labeled "Property keyword category" with categories: Time, Energy, Quality, Memory, and Other. Each bubble's size represents the magnitude of the relationship, and the color indicates different categories, with larger red bubbles indicating a stronger relationship and smaller yellow bubbles indicating a weaker relationship. The grid lines and points are shown to help align the bubbles accurately.
TEX Edit Distance for sample 70: 0.5206424593925476
CrystalBLEU Score for sample 70: 7.13083362477814e-06
Sample 70 processing time: 77.18 seconds

Processing sample 71/560 - Caption: This image depicts a mathematical diagram with a number line representing the x-axis. The x-axis is divided into segments with labels at specific points: \( x_{-3/2} \), \( L_{-2} \), \( x_{-1/2} \), \( L_{-1} \), \( x_{1/2} \), \( I_0 \), \( x_{3/2} \), \( I_1 \), and \( x_2 \). Above the x-axis, there are several labeled points: \( Q_{-2} \), \( Q_{-1} \), \( Q_R \), \( Q_L \), \( Q_0 \), and \( Q_1 \). The diagram includes two partial differential equations on either side of a vertical dashed line, with terms involving \( \partial Q \), \( S_1 \), \( S_2 \), \( \epsilon \), \( F_1(U) \), \( F_2(U) \), and \( V \). At the top, there is a condition \( \Psi(Q_R, Q_L) = 0 \).
TEX Edit Distance for sample 71: 0.8069939613342285
CrystalBLEU Score for sample 71: 6.402874401737454e-06
Sample 71 processing time: 70.17 seconds

Processing sample 72/560 - Caption: The image shows a diagram with a centered text box at coordinates (0,2) containing the text "centered text at (0/2)". Below the text box, there is a vertical dashed line extending downwards. At the bottom of the dashed line, there are two horizontal lines extending left and right, each ending with a letter: "L" on the left and "R" on the right. The horizontal lines are solid and the vertical dashed line intersects them at their midpoint.
TEX Edit Distance for sample 72: 0.795890748500824
CrystalBLEU Score for sample 72: 6.376095859930162e-06
Sample 72 processing time: 70.08 seconds

Processing sample 73/560 - Caption: This image depicts a Venn diagram with five overlapping regions, each labeled with a Greek letter. The diagram consists of four ellipses, each representing a different set. The labels are as follows:

- The leftmost ellipse is labeled with "λ".
- The topmost ellipse is labeled with "ν₃".
- The middle ellipse is labeled with "ν₁".
- The bottom ellipse is labeled with "ν₂".
- The rightmost ellipse is labeled with "μ".
- The outermost region, which encompasses all the ellipses, is labeled with "ν₄".

The ellipses intersect in such a way that they create multiple overlapping regions, each representing the intersection of different sets. The labels are placed within the respective ellipses and intersections to indicate the different subsets formed by the overlaps.
TEX Edit Distance for sample 73: 0.8263223171234131
CrystalBLEU Score for sample 73: 5.986503680713651e-06
Sample 73 processing time: 70.10 seconds

Processing sample 74/560 - Caption: This image depicts a labeled tree diagram with nodes and edges. The central node is labeled \( \rho' \) and branches out in multiple directions. The diagram includes the following key features:

1. **Horizontal Branch**:
   - Extends left and right from \( \rho' \).
   - Left nodes: \( \epsilon \), \( \sigma \), and \( \text{id}_N \).
   - Right nodes: \( \epsilon \rho' \), \( \sigma \alpha_2 \), \( \epsilon \alpha_2 \), and \( \alpha_2 \).

2. **Vertical Branch**:
   - Extends upwards and downwards from \( \rho' \).
   - Upward nodes: \( \epsilon \alpha_1' \), \( \sigma \alpha_1' \), and \( \alpha_1' \).
   - Downward nodes: \( \epsilon \alpha_4' \), \( \sigma \alpha_4' \), and \( \alpha_4' \).

3. **Diagonal Branches**:
   - One branch extends diagonally upwards to the right from \( \rho' \) with nodes \( \epsilon \alpha_2' \), \( \sigma \alpha_2' \), and \( \alpha_2' \).
   - Another branch extends diagonally downwards to the right from \( \rho' \) with nodes \( \epsilon \alpha_3 \), \( \sigma \alpha_3 \), and \( \alpha_3 \).

4. **Node Labels**:
   - Each node is labeled with a specific notation such as \( \epsilon \), \( \sigma \), \( \alpha \), and combinations thereof.

This structure can be used to write the TikZ code by defining the coordinates for each node and drawing the connecting lines accordingly.
TEX Edit Distance for sample 74: 0.5526533722877502
CrystalBLEU Score for sample 74: 8.423319378067243e-06
Sample 74 processing time: 25.13 seconds

Processing sample 75/560 - Caption: The image depicts a plot with three shaded regions, each labeled with numbers 1, 2, and 3. The regions are bounded by red lines, and the shading intensity increases from region 1 to region 3. A horizontal blue line intersects the plot at y = 1.5. The x-axis ranges from 0 to 8, and the y-axis ranges from 0 to 3. The red lines appear to be linear boundaries that converge towards the origin, creating the distinct regions. The plot is likely representing a feasible region or solution space for a set of inequalities.
TEX Edit Distance for sample 75: 0.818558394908905
CrystalBLEU Score for sample 75: 8.01703563621488e-06
Sample 75 processing time: 69.99 seconds

Processing sample 76/560 - Caption: The image depicts a 3D plot of a series of concentric ellipsoids centered at the origin. The ellipsoids are shaded in varying shades of red, with the innermost ellipsoid being the darkest and the outermost being the lightest. There are three blue arrows representing the x, y, and z axes, originating from the center of the ellipsoids and extending outward in positive and negative directions. The arrows are labeled with arrowheads, indicating the direction of the axes. The overall visualization suggests a symmetrical distribution around the origin.
TEX Edit Distance for sample 76: 0.6363241076469421
CrystalBLEU Score for sample 76: 1.009088824279575e-05
Sample 76 processing time: 30.19 seconds

Processing sample 77/560 - Caption: The image depicts a geometric structure resembling a truncated icosahedron, with a blue fill color and red edges. The structure consists of a combination of hexagons and pentagons. The outer boundary is formed by a series of red edges, while the inner polygons are outlined in a lighter shade. The overall shape is spherical, with the polygons fitting together in a symmetrical pattern.

This description should help in writing the TikZ code by focusing on the following elements:
1. **Nodes and Coordinates**: Define the coordinates for the vertices of the polygons.
2. **Polygons**: Use `\filldraw` or `\draw` commands to create the hexagons and pentagons.
3. **Coloring**: Apply blue fill for the polygons and red for the edges.
4. **Symmetry**: Ensure the polygons are arranged symmetrically to form the spherical shape.

Here is a basic structure of the TikZ code to get started:

```latex
\documentclass{standalone}
\usepackage{tikz}
\begin{document}
\begin{tikzpicture}

% Define the coordinates for the vertices
% Example coordinates, adjust as needed
\coordinate (A) at (0,0);
\coordinate (B) at (1,0);
\coordinate (C) at (1.5,0.87);
\coordinate (D) at (1,1.73);
\coordinate (E) at (0,1.73);
\coordinate (F) at (-0.5,0.87);

% Draw the polygons
\filldraw[fill=blue, draw=red] (A) -- (B) -- (C) -- (D) -- (E) -- (F) -- cycle;

% Repeat for other polygons
% Add more coordinates and draw commands to complete the structure

\end{tikzpicture}
\end{document}
```

This code provides a starting point. You will need to add more coordinates and `\filldraw` commands to complete the entire structure as shown in the image.
TEX Edit Distance for sample 77: 0.8417903184890747
CrystalBLEU Score for sample 77: 6.83637075367958e-06
Sample 77 processing time: 70.33 seconds

Processing sample 78/560 - Caption: The image depicts a graph composed of three main parts: a square on the left, a hexagon on the right, and a linear chain of five vertices connecting them. Each vertex is represented by a black dot, and edges are represented by straight lines connecting the vertices. The square and hexagon are regular polygons, and the linear chain connects the rightmost vertex of the square to the leftmost vertex of the hexagon.
TEX Edit Distance for sample 78: 0.6181818246841431
CrystalBLEU Score for sample 78: 7.313059684694855e-06
Sample 78 processing time: 9.06 seconds

Processing sample 79/560 - Caption: The image depicts a cylindrical coordinate system with a cylindrical object oriented in 3D space. The cylinder is tilted and labeled with points and vectors. The key elements are:

1. The cylinder is tilted and has a shaded surface.
2. The cylinder has three orthogonal vectors originating from its surface labeled as **p**, **q**, and **r**.
3. The cylinder is intersected by a vector **U** at an angle **θ** from the vertical axis (z-axis).
4. An angle **φ** is marked between the vector **U** and the horizontal projection of the cylinder.
5. The global coordinate system is shown with **x**, **y**, and **z** axes.
6. A vector **g** is pointing downward, indicating the direction of gravity.

This description should help in writing the TikZ code to recreate the figure.
TEX Edit Distance for sample 79: 0.6808953881263733
CrystalBLEU Score for sample 79: 8.36449084075391e-06
Sample 79 processing time: 12.44 seconds

Processing sample 80/560 - Caption: The image shows a single straight line with three parallel hash marks crossing it perpendicularly at the center. The line is drawn at an angle, not horizontal or vertical. The hash marks are evenly spaced and shorter than the main line. This figure can be used to represent a specific type of electrical component or a graphical notation in a diagram.

To create this in TikZ, you would draw a line and then add three shorter perpendicular lines at the center of the main line.
TEX Edit Distance for sample 80: 0.578866183757782
CrystalBLEU Score for sample 80: 9.305708974565906e-06
Sample 80 processing time: 10.49 seconds

Processing sample 81/560 - Caption: This image depicts a complex directed graph with multiple nodes and edges. The nodes are labeled with combinations of letters and numbers, such as "1a", "2b", "3c", etc. The edges are directed, indicated by arrows, and are labeled with letters such as "a", "b", "c". The graph includes various loops, cycles, and connections between nodes, forming a network of paths. Some edges are thicker, suggesting a higher weight or importance. The overall structure appears to be intricate, with nodes connected in a non-linear, web-like fashion.

To write the TikZ code for this image, you would need to:
1. Define the nodes with their respective labels.
2. Draw directed edges between the nodes with appropriate labels.
3. Ensure some edges are thicker to indicate higher weight or importance.
4. Arrange the nodes in a way that matches the layout of the graph.

Here is a basic template to get you started with the TikZ code:

```latex
\documentclass{standalone}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}

\begin{document}
\begin{tikzpicture}[->, >=Stealth, node distance=2cm, thick]

% Define nodes
\node (1a) {1a};
\node (2b) [right of=1a] {2b};
\node (3c) [below of=1a] {3c};
% Add more nodes as needed

% Define edges
\draw (1a) -- (2b) node[midway, above] {a};
\draw (2b) -- (3c) node[midway, right] {b};
\draw (3c) -- (1a) node[midway, left] {c};
% Add more edges as needed

% Thicker edges
\draw[very thick] (1a) -- (3c) node[midway, left] {a};

\end{tikzpicture}
\end{document}
```

You will need to expand this template by adding all the nodes and edges as per the graph in the image. Adjust the positions and distances to match the layout accurately.
TEX Edit Distance for sample 81: 0.8282431960105896
CrystalBLEU Score for sample 81: 2.3856533535252625e-06
Sample 81 processing time: 71.47 seconds

Processing sample 82/560 - Caption: The image consists of two subfigures labeled (a) and (b). 

Subfigure (a) depicts a circular diagram divided into four regions by lines radiating from the center. The regions are labeled as follows: the top region is labeled "B", the left region is labeled "A", the bottom region is labeled "B", and the right region is labeled "C".

Subfigure (b) shows a series of concentric circles with three points labeled on the outermost circle: "A'" on the left, "C'" on the right, and "B'" in the center. There is a vertical blue line passing through the center of the circles, connecting points "A'" and "C'".

To create this figure using TikZ, you will need to use commands for drawing circles, lines, and labeling specific points.
TEX Edit Distance for sample 82: 0.6405890583992004
CrystalBLEU Score for sample 82: 2.808607923247281e-06
Sample 82 processing time: 14.43 seconds

Processing sample 83/560 - Caption: The image depicts a sequence of nodes connected by directed arrows, representing a flow from one node to another. Each node is labeled with a variable (e.g., \( y_i \), \( y_{i-1} \), \( x_j \), \( y_{i-1} \)) and is enclosed in a dashed red circle. The arrows between the nodes are labeled with mathematical symbols (e.g., \( \sigma_1 \), \( \sigma_1^{-1} \), \( \sigma_0^{-1} \), \( \sigma_1 \), \( x_j^{-1} \), \( \sigma_0^{-1} \)). Below each node, there is a label indicating the column position (e.g., "2nd column", "1st column", "3rd column"). The nodes and arrows are arranged horizontally, with arrows pointing from left to right.

This description can help in writing the TikZ code by identifying the nodes, their labels, the arrows connecting them, and the corresponding labels for the arrows and columns.
TEX Edit Distance for sample 83: 0.6043643355369568
CrystalBLEU Score for sample 83: 3.3597487967121673e-06
Sample 83 processing time: 14.82 seconds

Processing sample 84/560 - Caption: This image represents a grid with labeled points and curves intersecting at a central point. The grid is composed of squares with side lengths labeled as \(a_i\) and \(b_i\) (where \(i\) ranges from 1 to 4). The horizontal lines are labeled \(a_1, a_2, a_3, a_4\) from top to bottom, and the vertical lines are labeled \(b_1, b_2, b_3, b_4\) from left to right. The central intersection point is labeled \(X_{a2}\). Two curves, labeled \(\mathcal{L}_1\) and \(\mathcal{L}_2\), intersect at \(X_{a2}\). The curves extend through the grid, bending as they pass through the intersections of the grid lines.

To generate this figure using TikZ, you would need to:
1. Create a grid with labeled intersections.
2. Draw the curves \(\mathcal{L}_1\) and \(\mathcal{L}_2\) intersecting at \(X_{a2}\).
3. Label the grid lines and the intersection point.

Here is a possible TikZ code structure to start with:

```latex
\documentclass{standalone}
\usepackage{tikz}
\begin{document}
\begin{tikzpicture}

% Draw the grid
\foreach \x in {1,2,3,4} {
    \foreach \y in {1,2,3,4} {
        \draw (\x, \y) -- (\x+1, \y);
        \draw (\x, \y) -- (\x, \y+1);
    }
}

% Label the grid lines
\node at (1.5, 4.5) {$a_1$};
\node at (2.5, 4.5) {$a_2$};
\node at (3.5, 4.5) {$a_3$};
\node at (4.5, 4.5) {$a_4$};

\node at (0.5, 3.5) {$b_1$};
\node at (0.5, 2.5) {$b_2$};
\node at (0.5, 1.5) {$b_3$};
\node at (0.5, 0.5) {$b_4$};

% Draw the curves
\draw[thick] (1,4) .. controls (2,3) and (3,2) .. (4,1);
\draw[thick] (1,1) .. controls (2,2) and (3,3) .. (4,4);

% Label the intersection point and curves
\node at (2.5, 2.5) {$X_{a2}$};
\node at (1.5, 3.5) {$\mathcal{L}_1$};
\node at (3.5, 1.5) {$\mathcal{L}_2$};

\end{tikzpicture}
\end{document}
```

This code provides a basic structure to create the grid and curves, and you can adjust the positions and labels as needed to match the image more closely.
TEX Edit Distance for sample 84: 0.6308649778366089
CrystalBLEU Score for sample 84: 3.453211330713109e-06
Sample 84 processing time: 7.35 seconds

Processing sample 85/560 - Caption: This image is a scatter plot with a red line connecting the first two data points. The x-axis is labeled "Zeit" (Time) and ranges from 0 to 180 in increments of 15. The y-axis is labeled "Extinktion" (Extinction) and ranges from 1.272 to 1.29 in increments of 0.002. The data points are represented by black dots. The red line starts at the point (15, 1.282) and ends at the point (45, 1.278). The plot has a grid with both vertical and horizontal lines.
TEX Edit Distance for sample 85: 0.7062339782714844
CrystalBLEU Score for sample 85: 3.486954129182682e-06
Sample 85 processing time: 11.90 seconds

Processing sample 86/560 - Caption: This image is a flow diagram illustrating the process of solving a MOMDP (Multi-Objective Markov Decision Process) using an algorithm. The diagram is divided into two phases: the "planning or learning phase" and the "execution phase." 

1. On the left side, there is a label "MOMDP + utility function."
2. An arrow points from this label to an oval labeled "algorithm," indicating that the algorithm processes the MOMDP and utility function.
3. The oval is enclosed in a dashed box representing the "planning or learning phase."
4. A dotted vertical line separates the "planning or learning phase" from the "execution phase."
5. An arrow extends from the oval to the right side, pointing to a label "single solution," indicating the output of the algorithm.
6. The "execution phase" label is placed below the arrow pointing to the "single solution."

This description should help you write the corresponding TikZ code for this flow diagram.
TEX Edit Distance for sample 86: 0.6973131895065308
CrystalBLEU Score for sample 86: 3.4718940443372328e-06
Sample 86 processing time: 5.72 seconds

Processing sample 87/560 - Caption: The image depicts a directed graph with six nodes labeled A, B, C, D, E, and F arranged in a circular layout. Each pair of adjacent nodes is connected by two directed edges forming a bidirectional connection. The edges between the nodes are curved, creating an elliptical shape around each pair of connected nodes. The graph forms a closed loop, with the following pairs of nodes connected: (A, B), (B, C), (C, D), (D, E), (E, F), and (F, A).
TEX Edit Distance for sample 87: 0.7029716968536377
CrystalBLEU Score for sample 87: 4.153717248852583e-06
Sample 87 processing time: 19.09 seconds

Processing sample 88/560 - Caption: This image depicts a bipartite graph with two sets of nodes, represented by two ellipses labeled \(J(L)\) and \(M(L)\). The nodes within these ellipses are connected to nodes outside the ellipses. The nodes are connected by edges, some of which are colored blue and red. The nodes \(j(a)\), \(j(b)\), \(m(a)\), and \(m(b)\) are positioned outside the ellipses, with \(j(a)\) and \(j(b)\) on the left and \(m(a)\) and \(m(b)\) on the right. The top and bottom nodes are colored red, while the left and right nodes are colored blue. The connections between the nodes form a network, with the ellipses representing subsets of the nodes. The central region between the ellipses is labeled \(R\).
TEX Edit Distance for sample 88: 0.672127902507782
CrystalBLEU Score for sample 88: 4.797312801316328e-06
Sample 88 processing time: 20.02 seconds

Processing sample 89/560 - Caption: The image displays two horizontally aligned rectangles with rounded corners. Both rectangles have a red border and no fill color. The rectangles are separated by a small gap. The dimensions of the rectangles are identical.
TEX Edit Distance for sample 89: 0.5435366034507751
CrystalBLEU Score for sample 89: 5.182667227964009e-06
Sample 89 processing time: 14.42 seconds

Processing sample 90/560 - Caption: The image consists of three horizontal bar charts, each representing different approaches to workload distribution over a series of days. 

1. **Demand patterns**: The first chart shows the demand patterns for four workers (Worker 1, Worker 2, Worker 3, Worker 4) over six days. Each worker's workload is represented by a distinct color (cyan, purple, orange, pink). Overloading and underloading are indicated by striped patterns in red and green, respectively. Performance decrease is marked by a black border around the bars.

2. **Classic approach**: The second chart illustrates the classic approach to workload distribution over the same period. The same color scheme and patterns are used to represent the workers and their workload statuses.

3. **Behavior-aware approach**: The third chart displays the behavior-aware approach to workload distribution, again over the same period and using the same color scheme and patterns.

Each chart has a legend at the top that explains the colors and patterns used. The x-axis represents the days, and the y-axis represents the workload intensity. The right side of each chart has a color-coded key indicating the risk levels associated with each approach.

To write the TikZ code for this figure, you would need to create three separate bar charts with the specified colors and patterns, ensuring to include the legend and the risk indicator keys.
TEX Edit Distance for sample 90: 0.6920245885848999
CrystalBLEU Score for sample 90: 4.728220489341757e-06
Sample 90 processing time: 15.42 seconds

Processing sample 91/560 - Caption: This image represents a grid with labeled points and curves intersecting at a central point. The grid is composed of squares with side lengths labeled as \(a_i\) and \(b_i\) (where \(i\) ranges from 1 to 4). The horizontal lines are labeled \(a_1, a_2, a_3, a_4\) from top to bottom, and the vertical lines are labeled \(b_1, b_2, b_3, b_4\) from left to right. The central intersection point is labeled \(X_{a2}\). Two curves, labeled \(\mathcal{L}_1\) and \(\mathcal{L}_2\), intersect at \(X_{a2}\). The curves extend through the grid, bending as they pass through the intersections of the grid lines.

To generate this figure using TikZ, you would need to:
1. Create a grid with labeled intersections.
2. Draw the curves \(\mathcal{L}_1\) and \(\mathcal{L}_2\) intersecting at \(X_{a2}\).
3. Label the grid lines and the intersection point.

Here is a possible TikZ code structure to start with:

```latex
\documentclass{standalone}
\usepackage{tikz}
\begin{document}
\begin{tikzpicture}

% Draw the grid
\foreach \x in {1,2,3,4} {
    \foreach \y in {1,2,3,4} {
        \draw (\x, \y) -- (\x+1, \y);
        \draw (\x, \y) -- (\x, \y+1);
    }
}

% Label the grid lines
\node at (1.5, 4.5) {$a_1$};
\node at (2.5, 4.5) {$a_2$};
\node at (3.5, 4.5) {$a_3$};
\node at (4.5, 4.5) {$a_4$};

\node at (0.5, 3.5) {$b_1$};
\node at (0.5, 2.5) {$b_2$};
\node at (0.5, 1.5) {$b_3$};
\node at (0.5, 0.5) {$b_4$};

% Draw the curves
\draw[thick] (1,4) .. controls (2,3) and (3,2) .. (4,1);
\draw[thick] (1,1) .. controls (2,2) and (3,3) .. (4,4);

% Label the intersection point and curves
\node at (2.5, 2.5) {$X_{a2}$};
\node at (1.5, 3.5) {$\mathcal{L}_1$};
\node at (3.5, 1.5) {$\mathcal{L}_2$};

\end{tikzpicture}
\end{document}
```

This code provides a basic structure to create the grid and curves, and you can adjust the positions and labels as needed to match the image more closely.
TEX Edit Distance for sample 91: 0.6539918780326843
CrystalBLEU Score for sample 91: 5.51362012758704e-06
Sample 91 processing time: 19.74 seconds

Processing sample 92/560 - Caption: This image is a line plot comparing the number of nonlinear iterations (y-axis) against the degrees of freedom (x-axis) on a logarithmic scale. The x-axis ranges from \(10^4\) to \(10^6\), and the y-axis ranges from 10 to 25. There are two lines: one in red representing "PPGD \(P_1\)" and one in blue representing "PPGD \(P_2\)". The legend is located in the upper right corner of the plot. The red line has square markers, and the blue line has circular markers. Both lines show a general upward trend as the degrees of freedom increase.
TEX Edit Distance for sample 92: 0.6677981615066528
CrystalBLEU Score for sample 92: 5.941022976352058e-06
Sample 92 processing time: 11.62 seconds

Processing sample 93/560 - Caption: The image depicts a bipartite graph with multiple layers of nodes connected by edges. The graph consists of three main columns of nodes:

1. The first column contains nodes labeled \( s_1^{(1)}, s_2^{(1)}, \ldots, s_W^{(1)} \).
2. The second column contains nodes labeled \( s_1^{(2)}, s_2^{(2)}, \ldots, s_W^{(2)} \).
3. The third column contains nodes labeled \( s_{T-1}^{(1)}, s_{T-1}^{(2)}, \ldots, s_{T-1}^{(W)} \).

The nodes in the first column are connected to the nodes in the second column with solid lines, indicating direct connections. The nodes in the second column are connected to the nodes in the third column with dashed lines, indicating a different type of connection. The third column nodes are connected to a single node labeled \( \emptyset \) with solid lines.

The connections between the nodes in the first and second columns are dense, suggesting a fully connected bipartite graph, while the connections between the nodes in the second and third columns are sparse, indicated by dashed lines.

This description should help in writing the TikZ code to create this figure.
TEX Edit Distance for sample 93: 0.8179811239242554
CrystalBLEU Score for sample 93: 5.546887225976533e-06
Sample 93 processing time: 70.14 seconds

Processing sample 94/560 - Caption: This image is a plot with a vertical axis labeled \(v\) and a horizontal axis labeled \(p\). The vertical axis has several marked points: \(\epsilon\) at the bottom, \(1/\epsilon^2\) in the middle, and \(v_{\text{max}}\) at the top. The horizontal axis has marked points: \(\epsilon^{20}\) near the origin and 1 at the far right. 

There are three horizontal dashed lines: one at \(\epsilon\), one at \(1/\epsilon^2\), and one at \(v_{\text{max}}\). The region between the horizontal lines at \(\epsilon\) and \(1/\epsilon^2\) is shaded. 

A vertical dashed line is drawn at \(p = \epsilon^{20}\), intersecting the horizontal dashed line at \(\epsilon\). The intersection is labeled \((1 + \epsilon)^k = v_i\).

There are two sets of points labeled \(X_{v_i}\) and \(X_{v_i}^+\) on the horizontal line at \(1/\epsilon^2\). The first set \(X_{v_i}\) includes points \(Y_2, Y_3, Y_4, Y_5, Y_6\), and the second set \(X_{v_i}^+\) includes points \(Y_4, Y_5, Y_6, Y_7, Y_8, Y_9\). The points \(X_{v_i}\) and \(X_{v_i}^+\) are enclosed in curly braces.

This description should help in writing the TikZ code to replicate the figure.
TEX Edit Distance for sample 94: 0.6055893898010254
CrystalBLEU Score for sample 94: 6.6998349827374555e-06
Sample 94 processing time: 25.16 seconds

Processing sample 95/560 - Caption: The image shows two separate line plots, each with blue line segments and points. Both plots share the same x-axis labels, ranging from \(v_0 - 2\sqrt{\epsilon}\) to \(v_0 + 2\sqrt{\epsilon}\), and y-axis labels, ranging from \(2v_0 - 4\sqrt{\epsilon}\) to \(2v_0 + 4\sqrt{\epsilon}\). The left plot contains a single line segment connecting two points, while the right plot contains three line segments connecting four points. The points and lines are plotted in blue.
TEX Edit Distance for sample 95: 0.8271486759185791
CrystalBLEU Score for sample 95: 6.157490542293151e-06
Sample 95 processing time: 70.19 seconds

Processing sample 96/560 - Caption: The image is a state diagram for a remote controller. It consists of seven states: "Init," "read_LC_on," "check_LC_on_count," "read_LC_off," "check_LC_off_count," "check_data," and "read_data." The transitions between these states are labeled with conditions such as "pos_edge," "data=0," "LC_on counter out of range," "LC_off counter out of range," "data_counter = 31," and "data_counter /= 31." The initial state is "Init," and the diagram includes loops and transitions between states, indicating the flow of the state machine. The states are represented by circles, and the transitions are represented by arrows connecting these circles.
TEX Edit Distance for sample 96: 0.6662976741790771
CrystalBLEU Score for sample 96: 9.430548028740721e-06
Sample 96 processing time: 32.04 seconds

Processing sample 97/560 - Caption: The image depicts a graph with three distinct vertical layers of nodes, each layer containing nodes of a different color. The top layer consists of orange nodes, the middle layer consists of blue nodes, and the bottom layer consists of red nodes. Nodes are connected by black edges, forming a network with connections primarily between adjacent layers. The connections include both vertical and diagonal edges, creating a structured yet interconnected graph.

This description can help in writing the TikZ code by specifying:
1. The positions and colors of the nodes.
2. The connections (edges) between the nodes.
3. The overall layout of the graph.

Here is a sample TikZ code snippet to create a similar graph:

```latex
\documentclass{standalone}
\usepackage{tikz}

\begin{document}
\begin{tikzpicture}

% Define node styles
\tikzstyle{orange node}=[circle, fill=orange, minimum size=6pt, inner sep=0pt]
\tikzstyle{blue node}=[circle, fill=blue, minimum size=6pt, inner sep=0pt]
\tikzstyle{red node}=[circle, fill=red, minimum size=6pt, inner sep=0pt]

% Draw nodes
\node[orange node] (o1) at (0, 6) {};
\node[orange node] (o2) at (0, 5) {};
\node[orange node] (o3) at (0, 4) {};
\node[orange node] (o4) at (0, 3) {};
\node[orange node] (o5) at (1, 4) {};

\node[blue node] (b1) at (0, 2) {};
\node[blue node] (b2) at (0, 1) {};
\node[blue node] (b3) at (1, 2) {};
\node[blue node] (b4) at (1, 1) {};

\node[red node] (r1) at (0, 0) {};
\node[red node] (r2) at (1, 0) {};

% Draw edges
\draw (o1) -- (o2);
\draw (o2) -- (o3);
\draw (o3) -- (o4);
\draw (o4) -- (b1);
\draw (b1) -- (b2);
\draw (b2) -- (r1);
\draw (b4) -- (r2);

\draw (o3) -- (b3);
\draw (o4) -- (b4);
\draw (b1) -- (b3);
\draw (b2) -- (b4);

\draw (o5) -- (b3);
\draw (o5) -- (b4);

\end{tikzpicture}
\end{document}
```

This code will generate a graph similar to the one in the image, with nodes and edges placed accordingly.
TEX Edit Distance for sample 97: 0.5561171174049377
CrystalBLEU Score for sample 97: 1.0076639946705677e-05
Sample 97 processing time: 11.10 seconds

Processing sample 98/560 - Caption: The image shows a 2-3 move transformation in a knot diagram. On the left, there are two vertical strands labeled A and A' intersecting with three horizontal strands labeled B, B', and C. The intersections are marked with small circles. The right side of the image shows the result of the 2-3 move, where the two vertical strands are now connected by an additional vertical strand, creating three intersections with the horizontal strands labeled A, A', and C. The transformation is indicated by a rightward arrow labeled "2-3 move."
TEX Edit Distance for sample 98: 0.6650511622428894
CrystalBLEU Score for sample 98: 1.0358755298207571e-05
Sample 98 processing time: 5.80 seconds

Processing sample 99/560 - Caption: The image shows a hexagon with vertices marked by black dots. Two vertices, labeled \(P\) and \(Q\), are connected by a blue dashed line. The hexagon has two sides labeled \(l\) and \(m\). Additionally, there is a red dotted path connecting \(P\) to another vertex of the hexagon, forming a zigzag pattern. The blue dashed lines and the red dotted path intersect within the hexagon. 

This description can help you write the TikZ code by providing the following details:
1. Draw a hexagon with vertices marked.
2. Label two vertices as \(P\) and \(Q\).
3. Draw a blue dashed line connecting \(P\) and \(Q\).
4. Label two sides of the hexagon as \(l\) and \(m\).
5. Draw a red dotted zigzag path starting from \(P\) and connecting to another vertex of the hexagon.
6. Ensure the blue dashed lines and red dotted path intersect within the hexagon.
TEX Edit Distance for sample 99: 0.8089606165885925
CrystalBLEU Score for sample 99: 1.0058853326488598e-05
Sample 99 processing time: 70.01 seconds

Processing sample 100/560 - Caption: The image depicts a block diagram with the following components:

1. A leftward-pointing arrow at the left end, indicating an input.
2. A green circle connected to the input arrow, representing a node.
3. An oval loop starting and ending at the green circle, indicating feedback.
4. A blue square connected to the right of the green circle, representing a block or system.
5. Another green circle connected to the right of the blue square, indicating another node.
6. A rightward-pointing arrow connected to the second green circle, indicating an output.
7. A vertical arrow pointing upwards from the second green circle, indicating another output or signal.

The connections between the components are represented by solid lines, and the arrows at both ends are dashed.

This description should help you write the TikZ code for the diagram.
TEX Edit Distance for sample 100: 0.8220692276954651
CrystalBLEU Score for sample 100: 9.757269564167686e-06
Sample 100 processing time: 70.03 seconds

Processing sample 101/560 - Caption: This image depicts a three-dimensional geometric representation involving three planes labeled \( IS \), \( IS-1 \), and \( IS-2 \). Each plane contains a triangular shape, and there are arrows connecting these shapes across the planes, indicating transformations or mappings. The planes are parallel and equally spaced along the vertical axis labeled \( t \). The triangular shapes are labeled \( D_{IS} \), \( D_{IS-1} \), and \( D_{IS-2} \) respectively. The arrows are annotated with labels such as \( \Delta V_{new} S \), \( r \), and \( r_1 \), suggesting vector transformations or shifts. The overall structure resembles a helical or spiral arrangement connecting the triangular shapes across the planes.

To write the TikZ code for this figure, you would need to:
1. Define the three planes and position them at different heights.
2. Draw the triangular shapes on each plane.
3. Add arrows connecting corresponding vertices of the triangles across the planes.
4. Annotate the arrows with the provided labels.
5. Ensure the planes are labeled \( IS \), \( IS-1 \), and \( IS-2 \) along the vertical axis \( t \).
TEX Edit Distance for sample 101: 0.8075655102729797
CrystalBLEU Score for sample 101: 9.084967693567606e-06
Sample 101 processing time: 70.16 seconds

Processing sample 102/560 - Caption: This image is a line plot depicting the average Signal-to-Interference-plus-Noise Ratio (SINR) in decibels (dB) as a function of training steps. The x-axis represents the training steps ranging from 0 to 20k, while the y-axis represents the average SINR ranging from 12 to 16 dB. Multiple lines, each representing different models or algorithms (GQN, GQN(GAT), DQN, GAQ, N-DQN, H), show the progression of average SINR over the training steps. Each line is color-coded and has a corresponding legend entry. Shaded areas around the lines indicate the variability or confidence intervals of the measurements.
TEX Edit Distance for sample 102: 0.9076158404350281
CrystalBLEU Score for sample 102: 4.999546213350761e-06
Sample 102 processing time: 71.19 seconds

Processing sample 103/560 - Caption: The image is a bar chart displaying the number of students on the y-axis and a range of scores on the x-axis. The x-axis is labeled with score intervals, each represented by a blue bar. Two specific score intervals are highlighted with different colors: one in red and one in green. The chart includes a legend at the bottom indicating that the green bar represents "ChatGPT," the red bar represents "BingChat," and the blue bars represent "Estudiantes evaluados." The y-axis is labeled with a logarithmic scale (10^0 to 10^4), and each bar has a numerical value displayed at its top.
TEX Edit Distance for sample 103: 0.678302526473999
CrystalBLEU Score for sample 103: 5.035246488210808e-06
Sample 103 processing time: 19.38 seconds

Processing sample 104/560 - Caption: The image depicts a sequence of state transition diagrams, commonly used in automata theory or state machines. The diagrams show states represented by circles, with transitions between states indicated by directed edges labeled with transition symbols. Some states are shaded, possibly indicating special states such as initial or accepting states. The diagrams appear to be arranged in two rows, with three diagrams in each row. Each diagram shows different configurations of states and transitions, illustrating the progression or changes in the state machine.

Key elements to note for the TikZ code:
1. Circles representing states, some of which are shaded.
2. Directed edges (arrows) between states, labeled with transition symbols.
3. Self-loop transitions on some states.
4. The arrangement of diagrams in a 2x3 grid format.

This information will help in structuring the TikZ code to accurately represent the state transition diagrams.
TEX Edit Distance for sample 104: 0.6805078387260437
CrystalBLEU Score for sample 104: 5.369300823557835e-06
Sample 104 processing time: 17.99 seconds

Processing sample 105/560 - Caption: The image depicts a graph with seven vertices and ten edges. The vertices are arranged in a symmetrical pattern resembling a bowtie or hourglass shape. The central vertex is connected to all other vertices. On the left side, three vertices form a triangle, with each vertex connected to the central vertex. On the right side, three vertices form another triangle, with each vertex also connected to the central vertex. The left and right triangles are not directly connected to each other. The vertices are represented by black dots, and the edges are represented by black lines.
TEX Edit Distance for sample 105: 0.5918970704078674
CrystalBLEU Score for sample 105: 6.939014445629292e-06
Sample 105 processing time: 27.01 seconds

Processing sample 106/560 - Caption: The image depicts a geometric representation of complex numbers. It shows a series of ellipses increasing in size along the positive real axis, labeled as \(|z|^2\). The ellipses are aligned along a line starting from the origin (0), which is marked by a solid black dot. The x-axis is labeled with \(|z|^2\) to indicate the squared magnitude of the complex number \(z\). The ellipses are positioned at regular intervals along this axis, with their major axes increasing linearly.
TEX Edit Distance for sample 106: 0.6919423937797546
CrystalBLEU Score for sample 106: 9.481069479565016e-06
Sample 106 processing time: 65.52 seconds

Processing sample 107/560 - Caption: The image depicts a block diagram with the following components:

1. A leftward-pointing arrow at the left end, indicating an input.
2. A green circle connected to the input arrow, representing a node.
3. An oval loop starting and ending at the green circle, indicating feedback.
4. A blue square connected to the right of the green circle, representing a block or system.
5. Another green circle connected to the right of the blue square, indicating another node.
6. A rightward-pointing arrow connected to the second green circle, indicating an output.
7. A vertical arrow pointing upwards from the second green circle, indicating another output or signal.

The connections between the components are represented by solid lines, and the arrows at both ends are dashed.

This description should help you write the TikZ code for the diagram.
TEX Edit Distance for sample 107: 0.8168948888778687
CrystalBLEU Score for sample 107: 8.948450889760376e-06
Sample 107 processing time: 70.06 seconds

Processing sample 108/560 - Caption: This image depicts a number line with a central point labeled as λ. To the left of λ, there are several points labeled β1, β2, β3, β4, β5, and so on, extending towards the left. To the right of λ, there are points labeled α1, α2, α3, α4, α5, and so on, extending towards the right. The points are evenly spaced, and the line extends beyond the labeled points with tick marks indicating additional positions. The leftmost and rightmost points, β1 and α1, are marked with orange vertical lines.

To create this in TikZ, you would need to:
1. Draw a horizontal line.
2. Mark the central point with λ.
3. Evenly space and label points to the left of λ as β1, β2, β3, β4, β5, etc.
4. Evenly space and label points to the right of λ as α1, α2, α3, α4, α5, etc.
5. Add tick marks between the labeled points.
6. Highlight the leftmost and rightmost points with orange vertical lines.
TEX Edit Distance for sample 108: 0.8286682367324829
CrystalBLEU Score for sample 108: 8.245480862340711e-06
Sample 108 processing time: 70.11 seconds

Processing sample 109/560 - Caption: This image consists of two subplots arranged vertically, each with a logarithmic x-axis labeled as \(\omega / T_s\). The top subplot is a Bode magnitude plot with the y-axis labeled as \(20 \log \left( \frac{Z_w}{A_w \sqrt{T_s}} \right) \) in decibels (dB). The plot shows two curves, one in blue and one in red, both decreasing with increasing frequency. The bottom subplot is a Bode phase plot with the y-axis labeled as \(\angle Z_{zw}\) in degrees. This plot also shows two curves, one in blue and one in red, with the phase starting at 0 degrees and decreasing to -90 degrees. Both subplots have grid lines for better readability.
TEX Edit Distance for sample 109: 0.7005705237388611
CrystalBLEU Score for sample 109: 6.333687188248496e-06
Sample 109 processing time: 5.92 seconds

Processing sample 110/560 - Caption: The image depicts a rectangular diagram with several nested boxes and labeled distances. The outer rectangle has dimensions of 5 cm by 2 cm. Inside the rectangle, there are three columns of nested boxes, each containing numbers. The leftmost column has boxes labeled "123", "12", and "1", stacked vertically. The middle column has boxes labeled "12" and "123", stacked vertically. The rightmost column has two boxes labeled "1", stacked vertically. There are two horizontal red arrows indicating distances: one labeled "1 cm" between the leftmost and middle columns, and another labeled "4 cm" between the middle and rightmost columns. The arrows are marked with asterisks at their starting points and arrows at their endpoints.
TEX Edit Distance for sample 110: 0.7891411781311035
CrystalBLEU Score for sample 110: 6.237164896702345e-06
Sample 110 processing time: 70.08 seconds

Processing sample 111/560 - Caption: The image consists of three subfigures, each depicting a different type of grid with a central black dot surrounded by other dots arranged in specific patterns. 

- Subfigure (a) shows "The square grid" with the central dot surrounded by dots forming a diamond shape.
- Subfigure (b) shows "The king grid" with the central dot surrounded by dots forming a square shape.
- Subfigure (c) shows "The triangular grid" with the central dot surrounded by dots forming a hexagonal shape.

Each subfigure is labeled below with its respective grid type. The dots are evenly spaced, and the arrangement of the dots in each grid type is distinct.
TEX Edit Distance for sample 111: 0.5713974833488464
CrystalBLEU Score for sample 111: 7.3829524758810125e-06
Sample 111 processing time: 20.98 seconds

Processing sample 112/560 - Caption: The image depicts a circular arrangement of squares, evenly spaced along the circumference of the circle. Each square is oriented such that its sides are parallel to the radius of the circle at its position. There are two thick black lines intersecting the circle at different points, with one set of three small black dots connecting one of the thick lines to the nearest square. The overall structure resembles a gear or a circular array of components with additional markings.
TEX Edit Distance for sample 112: 0.8415170907974243
CrystalBLEU Score for sample 112: 7.217894116186129e-06
Sample 112 processing time: 70.18 seconds

Processing sample 113/560 - Caption: The image shows two hexagonal grids, one smaller and one larger, with labeled vertices. The smaller hexagon on the left is filled with a light green color and labeled "σp+1" at the bottom. Its vertices are labeled with the numbers 1 and 2. The larger hexagon on the right, labeled "σk'+p+1" at the bottom, is composed of multiple smaller hexagons. The central hexagon is also filled with light green and labeled with the number 2, while the surrounding hexagons are filled with light yellow and labeled with numbers in the form of "2k'-1", "2k'", "2k'+1", etc. An arrow labeled "k" points from the smaller hexagon to the larger hexagon, indicating a transformation or expansion process.
TEX Edit Distance for sample 113: 0.5017398595809937
CrystalBLEU Score for sample 113: 7.303848383779207e-06
Sample 113 processing time: 52.34 seconds

Processing sample 114/560 - Caption: The image consists of three parts, each displaying a waveform. 

1. The top part shows a single red sinusoidal wave.
2. The middle part displays a blue modulated wave with an envelope that increases and then decreases symmetrically, forming a diamond shape.
3. The bottom part shows another blue modulated wave similar to the middle one but with a different modulation frequency or amplitude.

The overall layout is vertical, with each waveform centered horizontally. The middle waveform has a label "with sine pulse" centered below it.
TEX Edit Distance for sample 114: 0.6303783059120178
CrystalBLEU Score for sample 114: 9.11114762185762e-06
Sample 114 processing time: 50.35 seconds

Processing sample 115/560 - Caption: This image depicts a circle labeled \( L \) with a point on its circumference from which several vectors emanate. The vectors are labeled as follows:
- \( \nabla^F \tilde{\rho}_1 \) pointing upwards and to the right.
- \( \nabla^Z \rho_1 \) pointing directly to the right.
- \( W \) pointing horizontally to the right.
- \( \nabla^F \tilde{\rho}_2 \) pointing downwards and to the left.
- \( \nabla^Z \rho_2 \) pointing directly downwards.

The circle \( L \) is centered at the origin of the vectors. The vectors are labeled with their respective names at their heads.
TEX Edit Distance for sample 115: 0.5582947134971619
CrystalBLEU Score for sample 115: 1.064604114947741e-05
Sample 115 processing time: 21.25 seconds

Processing sample 116/560 - Caption: The image shows a blank bar chart with the x-axis labeled "Grades" ranging from 40 to 100 in increments of 10, and the y-axis labeled "Frequency" ranging from 0 to 14 in increments of 2. The chart is currently empty, with no bars or data points plotted.
TEX Edit Distance for sample 116: 0.68036288022995
CrystalBLEU Score for sample 116: 1.08672762953957e-05
Sample 116 processing time: 7.34 seconds

Processing sample 117/560 - Caption: The image shows a diagram with a black irregular shape and a black circle containing the letter "X" inside it. The circle overlaps the irregular shape. Around these elements, there is a dashed red rectangle representing a bounding box. The title "Normal bounding box" is written above the diagram.

To create this in TikZ, you would need to:
1. Draw the irregular shape.
2. Draw the circle with the letter "X" inside it.
3. Draw the dashed red bounding box around these elements.
4. Add the title text above the diagram.

Here is a sample TikZ code to get you started:

```latex
\documentclass{standalone}
\usepackage{tikz}
\begin{document}
\begin{tikzpicture}

% Title
\node at (0, 4) {\textbf{Normal bounding box}};

% Irregular shape (approximated as an ellipse here)
\draw (0, 0) ellipse (0.5 and 1);

% Circle with "X" inside
\draw[thick] (0.5, -0.5) circle (0.5);
\node at (0.5, -0.5) {\textbf{X}};

% Bounding box
\draw[red, dashed] (-1, -2) rectangle (1, 2);

\end{tikzpicture}
\end{document}
```

This code will create a simple approximation of the described diagram. You can adjust the coordinates and dimensions as needed to match the exact appearance.
TEX Edit Distance for sample 117: 0.6205994486808777
CrystalBLEU Score for sample 117: 1.1282929763975366e-05
Sample 117 processing time: 7.38 seconds

Processing sample 118/560 - Caption: The image consists of two separate directed graphs. The left graph has three nodes labeled "000", "010", and "100". The node "000" has a self-loop and two outgoing edges pointing to "010" and "100". The right graph has six nodes labeled "000", "001", "011", "101", "110", and "111". The edges are as follows: "000" to "001", "001" to "011", "011" to "111", "111" to "110", "110" to "101", and "101" to "011". 

This description should help in writing the TikZ code to recreate the image.
TEX Edit Distance for sample 118: 0.8346639275550842
CrystalBLEU Score for sample 118: 1.1037211642596916e-05
Sample 118 processing time: 95.59 seconds

Processing sample 119/560 - Caption: The image is a diagram with four nodes, each containing text and connected vertically. The nodes are color-coded and contain descriptions of different LaTeX packages. The first node is red and labeled "Latex," describing it as a program specialized in document preparation. The second node is light blue and labeled "Musixtex," describing it as a LaTeX package specialized in music. The third node is purple and labeled "Tikz," describing it as a LaTeX package specialized in vector graphics. The fourth node is green and labeled "Beamer," describing it as a LaTeX package specialized in presentations. There is also a hyperlink on the top left labeled "¿Qué es Musixtex?" and a bulleted list with three items labeled "Some text A," "Some text B," and "Some text C."

This description should help you write the TikZ code for the diagram.
TEX Edit Distance for sample 119: 0.8020928502082825
CrystalBLEU Score for sample 119: 8.917771183287573e-06
Sample 119 processing time: 79.78 seconds

Processing sample 120/560 - Caption: This image appears to be a complex Feynman diagram, commonly used in particle physics to represent interactions between particles. The diagram consists of multiple vertical lines, each representing a particle propagating through time. These vertical lines are connected by wavy lines, which typically represent the exchange of gauge bosons (such as photons or gluons). Additionally, there are dashed lines indicating possible intermediate states or interactions.

Key elements to note for writing the TikZ code:
1. **Vertical Lines**: Representing particles propagating through time.
2. **Wavy Lines**: Connecting the vertical lines, representing the exchange of gauge bosons.
3. **Dashed Lines**: Indicating intermediate states or interactions.
4. **Repetition**: The pattern repeats multiple times horizontally.

To create this diagram in TikZ, you would use the `feynmp` or `tikz-feynman` package, which are specifically designed for drawing Feynman diagrams. You would define the vertices (interaction points) and edges (propagators and gauge bosons) accordingly.
TEX Edit Distance for sample 120: 0.6100006699562073
CrystalBLEU Score for sample 120: 8.92836902054703e-06
Sample 120 processing time: 15.20 seconds

Processing sample 121/560 - Caption: This image depicts a three-dimensional geometric representation involving three planes labeled \( IS \), \( IS-1 \), and \( IS-2 \). Each plane contains a triangular shape, and there are arrows connecting these shapes across the planes, indicating transformations or mappings. The planes are parallel and equally spaced along the vertical axis labeled \( t \). The triangular shapes are labeled \( D_{IS} \), \( D_{IS-1} \), and \( D_{IS-2} \) respectively. The arrows are annotated with labels such as \( \Delta V_{new} S \), \( r \), and \( r_1 \), suggesting vector transformations or shifts. The overall structure resembles a helical or spiral arrangement connecting the triangular shapes across the planes.

To write the TikZ code for this figure, you would need to:
1. Define the three planes and position them at different heights.
2. Draw the triangular shapes on each plane.
3. Add arrows connecting corresponding vertices of the triangles across the planes.
4. Annotate the arrows with the provided labels.
5. Ensure the planes are labeled \( IS \), \( IS-1 \), and \( IS-2 \) along the vertical axis \( t \).
TEX Edit Distance for sample 121: 0.8094906806945801
CrystalBLEU Score for sample 121: 8.443449971774958e-06
Sample 121 processing time: 70.38 seconds

Processing sample 122/560 - Caption: This image consists of two subplots arranged vertically, each with a logarithmic x-axis labeled as \(\omega / T_s\). The top subplot is a Bode magnitude plot with the y-axis labeled as \(20 \log \left( \frac{Z_w}{A_w \sqrt{T_s}} \right) \) in decibels (dB). The plot shows two curves, one in blue and one in red, both decreasing with increasing frequency. The bottom subplot is a Bode phase plot with the y-axis labeled as \(\angle Z_{zw}\) in degrees. This plot also shows two curves, one in blue and one in red, with the phase starting at 0 degrees and decreasing to -90 degrees. Both subplots have grid lines for better readability.
TEX Edit Distance for sample 122: 0.8958141207695007
CrystalBLEU Score for sample 122: 3.596625329159821e-06
Sample 122 processing time: 72.11 seconds

Processing sample 123/560 - Caption: This image depicts a directed graph with 11 nodes and multiple directed edges. The nodes are arranged in four rows. The first row has one node (1), the second row has four nodes (2, 3, 4, 5), the third row has three nodes (6, 7, 9), and the fourth row has three nodes (8, 10, 11). Each node is connected to several other nodes with directed edges, indicated by arrows. The edges are directed from left to right and from top to bottom, forming a complex network of connections. Nodes are labeled with numbers inside circles, and edges are represented by arrows pointing from one node to another.

To write the TikZ code for this graph, you would need to:
1. Define the nodes with their respective positions.
2. Draw the directed edges between the nodes.

Example TikZ code structure:
```latex
\begin{tikzpicture}
  % Define nodes
  \node (1) at (0,3) {1};
  \node (2) at (2,4) {2};
  \node (3) at (2,3) {3};
  \node (4) at (2,2) {4};
  \node (5) at (2,5) {5};
  \node (6) at (4,3) {6};
  \node (7) at (4,2) {7};
  \node (8) at (6,5) {8};
  \node (9) at (4,4) {9};
  \node (10) at (6,2) {10};
  \node (11) at (6,3) {11};
  
  % Draw edges
  \draw[->] (1) -- (2);
  \draw[->] (1) -- (3);
  \draw[->] (1) -- (4);
  \draw[->] (2) -- (5);
  \draw[->] (2) -- (6);
  \draw[->] (3) -- (6);
  \draw[->] (3) -- (7);
  \draw[->] (4) -- (7);
  \draw[->] (5) -- (8);
  \draw[->] (5) -- (9);
  \draw[->] (6) -- (8);
  \draw[->] (6) -- (9);
  \draw[->] (6) -- (10);
  \draw[->] (7) -- (10);
  \draw[->] (8) -- (11);
  \draw[->] (9) -- (11);
  \draw[->] (10) -- (11);
\end{tikzpicture}
```
TEX Edit Distance for sample 123: 0.8084117770195007
CrystalBLEU Score for sample 123: 3.4969064240851157e-06
Sample 123 processing time: 70.25 seconds

Processing sample 124/560 - Caption: This image depicts a hierarchical tree structure with nodes and directed edges. The nodes are represented as ellipses containing variables, and the edges are labeled with corresponding identifiers. The structure can be described as follows:

1. The root node contains variables \(x_1, x_2\) and is labeled \(T_{12}\).
2. The root node has a single child node containing variables \(x_1, x_3\) and is labeled \(T_{13}\).
3. The node \(T_{13}\) branches into two child nodes:
   - The left child node contains variables \(x_3, x_4, x_5\) and is labeled \(T_{345}\).
   - The right child node contains variables \(x_3, x_7\) and is labeled \(S_{37}\).
4. The node \(T_{345}\) has a single child node containing variables \(x_4, x_5, x_6\) and is labeled \(S_{45}\).
5. The node \(S_{37}\) has a single child node containing variables \(x_7, x_8, x_9\) and is labeled \(S_{78}\).

This hierarchical structure can be represented using TikZ in LaTeX with nodes and edges, where each node is an ellipse containing the specified variables, and each edge is directed and labeled accordingly.
TEX Edit Distance for sample 124: 0.6578733325004578
CrystalBLEU Score for sample 124: 4.391512542421291e-06
Sample 124 processing time: 19.95 seconds

Processing sample 125/560 - Caption: This image depicts a flowchart with several nodes and directed edges, labeled with mathematical expressions. The nodes are labeled \(C_1\), \(C_2\), \(C_3\), \(C_4\), \(C_{2i-1}\), \(C_{2i}\), \(C_{2i+1}\), and \(C_G\). The edges between the nodes are labeled with various mathematical expressions, such as \(\frac{n^2}{\pi} + 1\), \(1\), and \(2\). The nodes \(C_1\), \(C_2\), \(C_4\), \(C_{2i}\), and \(C_G\) are connected in a linear sequence with solid lines, while nodes \(C_3\), \(C_{2i-1}\), and \(C_{2i+1}\) are connected to \(C_2\), \(C_4\), and \(C_{2i}\) respectively with dashed lines. Each node also has a label below it, such as \(\frac{n-1}{2}\), \(\frac{n-3}{2}\), \(\frac{n-(2i-1)}{2}\), and \(\frac{n-(2i+1)}{2}\).
TEX Edit Distance for sample 125: 0.8107765913009644
CrystalBLEU Score for sample 125: 4.234227398446014e-06
Sample 125 processing time: 70.25 seconds

Processing sample 126/560 - Caption: The image shows a 2-3 move transformation in a knot diagram. On the left, there are two vertical strands labeled A and A' intersecting with three horizontal strands labeled B, B', and C. The intersections are marked with small circles. The right side of the image shows the result of the 2-3 move, where the two vertical strands are now connected by an additional vertical strand, creating three intersections with the horizontal strands labeled A, A', and C. The transformation is indicated by a rightward arrow labeled "2-3 move."
TEX Edit Distance for sample 126: 0.6622484922409058
CrystalBLEU Score for sample 126: 7.261412700967818e-06
Sample 126 processing time: 63.20 seconds

Processing sample 127/560 - Caption: This image shows a triangle with vertices labeled 1, 2, and 3. The vertices are represented by pink circles with black numbers inside. The edges of the triangle are colored differently: the edge between vertices 1 and 2, and the edge between vertices 1 and 3 are blue, while the edge between vertices 2 and 3 is black. The vertices are arranged in a way that forms an equilateral triangle.
TEX Edit Distance for sample 127: 0.4948659837245941
CrystalBLEU Score for sample 127: 7.953038852703766e-06
Sample 127 processing time: 16.69 seconds

Processing sample 128/560 - Caption: The image consists of a 2x5 grid of nodes. Each node is represented by an orange dot and is labeled with a mathematical or alphabetical character. The labels for the nodes in the first row are "n", "n-1", "c", and "g" from left to right. The labels for the nodes in the second row are "n", "n-1", "h", and "y" from left to right. The nodes are aligned vertically and horizontally, forming a clear grid structure.
TEX Edit Distance for sample 128: 0.7958588004112244
CrystalBLEU Score for sample 128: 7.870519058902189e-06
Sample 128 processing time: 70.31 seconds

Processing sample 129/560 - Caption: "Binary tree with multiple levels, where each node splits into two child nodes. The tree expands horizontally with increasing levels, creating a dense network of lines connecting the nodes. The tree appears to be symmetric and continues infinitely to the right."
TEX Edit Distance for sample 129: 0.8343293070793152
CrystalBLEU Score for sample 129: 5.396925106477249e-06
Sample 129 processing time: 70.83 seconds

Processing sample 130/560 - Caption: The image shows a plot with two sets of points connected by lines. The first set of points is located on the left side of the plot, with x-coordinates ranging from approximately -4 to 0 and y-coordinates ranging from 1 to 4. The second set of points is located on the right side of the plot, with x-coordinates ranging from approximately 500 to 508 and y-coordinates ranging from 1 to 4. Each set of points forms a roughly V-shaped pattern. The points are marked with black dots, and the lines connecting them are straight. The x-axis ranges from -4 to 508, and the y-axis ranges from 1 to 4.
TEX Edit Distance for sample 130: 0.7405880689620972
CrystalBLEU Score for sample 130: 7.010708668609839e-06
Sample 130 processing time: 34.61 seconds

Processing sample 131/560 - Caption: The image depicts a flowchart with nodes and arrows, illustrating a timeline from 2020 to 2070. The flowchart consists of the following elements:

1. Three purple rectangular nodes labeled "DDmg," "DT1," and "DCS" aligned vertically on the left side.
2. An orange circular node labeled "CT1" positioned to the right of "DT1."
3. A purple rectangular node labeled "DT2" to the right of "CT1."
4. A green diamond-shaped node labeled "subproblem" to the right of "DT2."
5. Arrows connecting "DDmg" to "DT2," "DT1" to "CT1," "CT1" to "DT2," and "DCS" to "subproblem."
6. A horizontal timeline at the bottom, marked with intervals from 2020 to 2070.

This description should help in creating the TikZ code for the given flowchart.
TEX Edit Distance for sample 131: 0.8207799196243286
CrystalBLEU Score for sample 131: 6.718519562304846e-06
Sample 131 processing time: 70.33 seconds

Processing sample 132/560 - Caption: "An 8-petal rose curve (rhodonea curve) centered at the origin, with each petal symmetrically distributed around the center. The petals are created using the polar equation \( r = \sin(4\theta) \), where \( \theta \) ranges from 0 to \( 2\pi \)."
TEX Edit Distance for sample 132: 0.6070700287818909
CrystalBLEU Score for sample 132: 6.949485777366518e-06
Sample 132 processing time: 6.75 seconds

Processing sample 133/560 - Caption: The image depicts a circle with two labeled points and directional arrows. The circle has two distinct points marked with black dots. The point on the left is labeled as "C2" and the point on the right is labeled as "C1". The circle is oriented with arrows indicating a counterclockwise direction. The arrows are evenly spaced around the circle, showing the flow from "C2" to "C1".
TEX Edit Distance for sample 133: 0.7960708737373352
CrystalBLEU Score for sample 133: 6.894243158303745e-06
Sample 133 processing time: 70.27 seconds

Processing sample 134/560 - Caption: This image consists of two sets of diagrams labeled (A) and (B), each depicting a transformation of a tree structure. 

In diagram (A):
- The left side shows a tree with nodes labeled 1, 2, 3, and 4, with node 4 connected to node 3 through a wavy line.
- An arrow points to the right, indicating a transformation.
- The right side shows the transformed tree, where node 4 is now connected to node 2 through a wavy line.
- Between the trees is a set notation indicating the transformation: {1, 2, 3, 4} transforms to {1, 2', 3, 4}.

In diagram (B):
- The left side shows a tree with nodes labeled 1, 2, 3, and 4, with node 4 connected to node 3 through a wavy line.
- An arrow points to the right, indicating a transformation.
- The right side shows the transformed tree, where node 4 is now connected to node 2 through a wavy line.
- Between the trees is a set notation indicating the transformation: {1, 2, 3, 4} transforms to {1, 2', 3, 4}.

Both diagrams (A) and (B) illustrate similar transformations of tree structures with different initial configurations. The wavy lines represent specific connections between nodes that change during the transformation.
TEX Edit Distance for sample 134: 0.8054946660995483
CrystalBLEU Score for sample 134: 5.788306689417153e-06
Sample 134 processing time: 70.60 seconds

Processing sample 135/560 - Caption: This image is a line graph showing the Spearman correlation on the STS-B Development Set across different layers (0 to 13) for various models. The x-axis represents the layer number, and the y-axis represents the Spearman correlation, ranging from 0.45 to 0.85. There are four lines plotted:

1. An orange line labeled "MLM" that remains constant at a low correlation value across all layers.
2. A blue line with square markers labeled "Stop" that fluctuates, peaking around layer 9.
3. A red line with triangle markers labeled "w/o Stop" that also fluctuates, peaking around layer 9 but slightly lower than the "Stop" line.
4. A black dashed line labeled "SimCSE*" that remains constant at a higher correlation value across all layers.

The legend is located inside the plot area, slightly to the right of the center, and includes the labels for each line with corresponding colors and markers.

This description can help in writing the TikZ code by providing details about the axes, the range of values, the different lines, their colors, markers, and the legend placement.
TEX Edit Distance for sample 135: 0.8856397867202759
CrystalBLEU Score for sample 135: 5.613745545756575e-06
Sample 135 processing time: 70.37 seconds

Processing sample 136/560 - Caption: This image depicts a geometric figure with several key elements:

1. **Axes**: There are two black lines intersecting at the origin, forming four quadrants.
2. **Circle**: A red dashed circle centered at the origin.
3. **Sector**: A shaded blue sector in the first quadrant.
4. **Arrows**: Two red arrows originating from the origin, labeled as \( \tau_1 \) and \( \tau_\Delta \), pointing towards the boundary of the blue sector.
5. **Labels**: The circle is labeled as \( S_a \) in red, and the blue sector is labeled as \( a^+ \) in blue.

This description should help in writing the TikZ code to recreate the figure.
TEX Edit Distance for sample 136: 0.5273662209510803
CrystalBLEU Score for sample 136: 6.000962977846871e-06
Sample 136 processing time: 33.15 seconds

Processing sample 137/560 - Caption: This image depicts a finite state machine with four states: \( q_0 \), \( q_1 \), \( q_2 \), and \( q_3 \). The initial state is \( q_0 \), indicated by an arrow pointing to it labeled "start". The final state is \( q_3 \), represented by a double circle. The transitions between states are labeled with the corresponding input symbols. The transitions are as follows:

- From \( q_0 \) to \( q_1 \) on input \( a \).
- From \( q_0 \) to \( q_2 \) on input \( b \).
- From \( q_0 \) to \( q_3 \) on inputs \( c \) and \( d \).
- From \( q_1 \) to itself on input \( b \).
- From \( q_1 \) to \( q_3 \) on inputs \( c \) and \( d \).
- From \( q_1 \) to \( q_0 \) on input \( a \).
- From \( q_2 \) to itself on input \( c \).
- From \( q_2 \) to \( q_3 \) on input \( d \).
- From \( q_2 \) to \( q_0 \) on input \( b \).
- From \( q_3 \) to \( q_1 \) on input \( a \).

This description should help in writing the TikZ code to generate this finite state machine diagram.
TEX Edit Distance for sample 137: 0.48024511337280273
CrystalBLEU Score for sample 137: 8.081743203682276e-06
Sample 137 processing time: 26.92 seconds

Processing sample 138/560 - Caption: This image depicts a shaded, irregular shape with a curved right boundary and a straight left boundary. The left boundary has a vertical length of 40 units, while the top and bottom horizontal boundaries are 5 units and 8 units long, respectively. The shape is divided into seven horizontal sections, each labeled with a numerical value (6.4, 7.5, 8.4, 9.0, 9.3, 9.2, 8.8). Each section has a horizontal arrow pointing from left to right, indicating the direction and possibly the magnitude of a certain quantity. The entire shape is filled with a blue color. The numerical labels are centered within each section, and the arrows span the width of the shape at each section.
TEX Edit Distance for sample 138: 0.8080088496208191
CrystalBLEU Score for sample 138: 7.814069658143227e-06
Sample 138 processing time: 70.38 seconds

Processing sample 139/560 - Caption: This image is a time-division diagram illustrating the operation of a relay and an IRS (Intelligent Reflecting Surface) over a period \( T \). The diagram is divided into two main parts: the first part, with duration \( \tau \), is dedicated to the energy waveform, and the second part, with duration \( T - \tau \), is dedicated to the information waveform. 

- The top row labeled "Relay" shows the sequence of operations for the relay: 
  - During the energy waveform period (\( \tau \)), the relay receives energy from \( \{T_k\}_{k=1}^K \).
  - During the information waveform period (\( T - \tau \)), the relay receives information from \( \{R_k\}_{k=1}^K \) and transmits it.

- The bottom row labeled "IRS" shows the sequence of operations for the IRS:
  - During the energy waveform period (\( \tau \)), the IRS receives energy from \( \{T_k\}_{k=1}^K \).
  - During the information waveform period (\( T - \tau \)), the IRS receives information from \( \{R_k\}_{k=1}^K \) and reflects it.

The diagram uses different colors to distinguish between the energy waveform period (green) and the information waveform period (red). The time intervals are clearly marked, and arrows indicate the direction of signal flow.
TEX Edit Distance for sample 139: 0.8166104555130005
CrystalBLEU Score for sample 139: 7.4304252541856785e-06
Sample 139 processing time: 70.35 seconds

Processing sample 140/560 - Caption: The image consists of two pentagonal graphs side by side. The left graph is labeled with binary strings at each vertex and edges are labeled with \(e_1, e_2, e_3, e_4, e_5\). The central vertex is labeled \(u\). The right graph is the same pentagonal graph but without any labels; it has thicker edges and vertices are represented as small circles. Both graphs have the same structure, with vertices connected in a pentagonal pattern and additional internal edges forming a star-like shape within the pentagon.
TEX Edit Distance for sample 140: 0.8238241076469421
CrystalBLEU Score for sample 140: 6.948766993147175e-06
Sample 140 processing time: 70.39 seconds

Processing sample 141/560 - Caption: The image shows two hexagonal grids, one smaller and one larger, with labeled vertices. The smaller hexagon on the left is filled with a light green color and labeled "σp+1" at the bottom. Its vertices are labeled with the numbers 1 and 2. The larger hexagon on the right, labeled "σk'+p+1" at the bottom, is composed of multiple smaller hexagons. The central hexagon is also filled with light green and labeled with the number 2, while the surrounding hexagons are filled with light yellow and labeled with numbers in the form of "2k'-1", "2k'", "2k'+1", etc. An arrow labeled "k" points from the smaller hexagon to the larger hexagon, indicating a transformation or expansion process.
TEX Edit Distance for sample 141: 0.5072336792945862
CrystalBLEU Score for sample 141: 8.126511429828632e-06
Sample 141 processing time: 22.28 seconds

Processing sample 142/560 - Caption: The image consists of two circular diagrams side by side, each divided into six equal sectors labeled from 1 to 6. The left circle has a dashed horizontal line across the diameter labeled with a delta symbol (Δ) and a subscript "n". The right circle is identical to the left but without the dashed line. Both circles share a common center with lines radiating out to the circumference, dividing the circles into equal parts. The sectors are numbered in a clockwise manner starting from the bottom left.
TEX Edit Distance for sample 142: 0.6437841057777405
CrystalBLEU Score for sample 142: 8.893261499140063e-06
Sample 142 processing time: 8.94 seconds

Processing sample 143/560 - Caption: This image depicts two sequences of connected circles containing various labels. The circles are connected by lines, with some connections represented by dashed lines. The top sequence consists of 11 circles labeled as follows from left to right: \(C_i\), \(C_iC_i\), \(C_i\), \(C_iL_j\), \(L_jX_i\), \(X_i\), \(X_iL_j\), \(L_j\), \(L_jC_i\), \(C_i\), \(C_iC_i\). The bottom sequence consists of 7 circles labeled as follows from left to right: \(C_i\), \(C_iC_i\), \(C_i\), \(C_iL_j\), \(L_jX_i\), \(X_i\). The first and last circles in both sequences are connected by dashed lines to indicate a continuation or a boundary.
TEX Edit Distance for sample 143: 0.8133078217506409
CrystalBLEU Score for sample 143: 8.439636052227496e-06
Sample 143 processing time: 70.40 seconds

Processing sample 144/560 - Caption: This image contains a row of three equally sized rectangular images aligned horizontally. Above the center image, there is a small rectangular text box with the label "some text". Each image is labeled with the word "Image" in the center. The layout is symmetrical with equal spacing between the images.

Caption for TikZ code:
- Three horizontally aligned rectangles representing images.
- A small rectangular text box centered above the middle image.
- Each rectangle contains the text "Image" centered within it.
TEX Edit Distance for sample 144: 0.798696756362915
CrystalBLEU Score for sample 144: 8.38492689638137e-06
Sample 144 processing time: 70.30 seconds

Processing sample 145/560 - Caption: This image depicts a directed graph with multiple nodes and edges. The nodes are labeled with lowercase letters from 'a' to 'n'. The graph consists of three disconnected components:

1. The first component includes nodes 'b' and 'a' with a directed edge from 'b' to 'a'.
2. The second component includes nodes 'g', 'f', and 'e' with directed edges from 'g' to 'f' and from 'f' to 'e'.
3. The third component is more complex, including nodes 'c', 'd', 'e', 'h', 'i', 'j', 'k', 'l', 'm', and 'n'. The directed edges are as follows:
   - 'n' to 'c'
   - 'n' to 'm'
   - 'c' to 'd'
   - 'c' to 'l'
   - 'd' to 'e'
   - 'e' to 'j'
   - 'j' to 'h'
   - 'h' to 'i'
   - 'i' to 'k'
   - 'l' to 'h'
   - 'l' to 'i'

The nodes are arranged in a hierarchical manner, with 'n' at the top and 'e', 'j', and 'k' at the bottom. The edges indicate the direction of the relationships between the nodes.
TEX Edit Distance for sample 145: 0.8218164443969727
CrystalBLEU Score for sample 145: 8.017725742510511e-06
Sample 145 processing time: 70.43 seconds

Processing sample 146/560 - Caption: This image depicts a complex directed graph with multiple nodes and edges. The nodes are labeled with combinations of letters and numbers, such as "1a", "2b", "3c", etc. The edges are directed, indicated by arrows, and are labeled with letters such as "a", "b", "c". The graph includes various loops, cycles, and connections between nodes, forming a network of paths. Some edges are thicker, suggesting a higher weight or importance. The overall structure appears to be intricate, with nodes connected in a non-linear, web-like fashion.

To write the TikZ code for this image, you would need to:
1. Define the nodes with their respective labels.
2. Draw directed edges between the nodes with appropriate labels.
3. Ensure some edges are thicker to indicate higher weight or importance.
4. Arrange the nodes in a way that matches the layout of the graph.

Here is a basic template to get you started with the TikZ code:

```latex
\documentclass{standalone}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}

\begin{document}
\begin{tikzpicture}[->, >=Stealth, node distance=2cm, thick]

% Define nodes
\node (1a) {1a};
\node (2b) [right of=1a] {2b};
\node (3c) [below of=1a] {3c};
% Add more nodes as needed

% Define edges
\draw (1a) -- (2b) node[midway, above] {a};
\draw (2b) -- (3c) node[midway, right] {b};
\draw (3c) -- (1a) node[midway, left] {c};
% Add more edges as needed

% Thicker edges
\draw[very thick] (1a) -- (3c) node[midway, left] {a};

\end{tikzpicture}
\end{document}
```

You will need to expand this template by adding all the nodes and edges as per the graph in the image. Adjust the positions and distances to match the layout accurately.
TEX Edit Distance for sample 146: 0.8283840417861938
CrystalBLEU Score for sample 146: 3.5236172715459188e-06
Sample 146 processing time: 71.92 seconds

Processing sample 147/560 - Caption: This image depicts a mathematical diagram with several key elements and annotations:

1. A dashed curve that intersects itself, forming a loop at the top left corner.
2. Four points labeled as \( a \), \( b \), \( c \), and \( d \) along the curve and lines.
3. Three solid lines extending from points on the curve, labeled with mathematical expressions:
   - The line from point \( a \) is labeled \( \mathcal{L}(s + t \sum_{i=0}^{k-1} 2^{-i/5}) N^{2/3} / (L-1) N^{2k+1} \).
   - The line from point \( b \) is labeled \( \mathcal{L}(s + t \sum_{i=0}^{k-1} 2^{-i/5}) N^{2/3} / (L+1) N^{2k+1} \).
   - The line from point \( c \) is labeled \( \mathcal{L}(s + t \sum_{i=0}^{k} 2^{-i/5}) N^{2/3} / L N^{2k+1} \).
4. A horizontal dashed line connecting points \( a \) and \( b \).

This caption provides a detailed description of the elements in the image, which will be useful for writing the TikZ code to recreate the diagram.
TEX Edit Distance for sample 147: 0.83079993724823
CrystalBLEU Score for sample 147: 3.3853212174659513e-06
Sample 147 processing time: 70.40 seconds

Processing sample 148/560 - Caption: This bar chart represents the number of papers published across various research fields. The x-axis lists the research fields, which include Weather modeling, Imaging and photonics, Dynamic systems, Fluid/solid mechanics, Geology, Remote sensing, Manufacturing, Materials science, Acc. and conflict resolution, Surveillance, Medical imaging, and Robotics. The y-axis indicates the number of papers published, ranging from 0 to 15. Each bar is colored magenta, with the height of the bars corresponding to the number of papers published in each field. Weather modeling, Dynamic systems, and Medical imaging have the highest number of publications, while Robotics has the lowest. The x-axis labels are rotated for better readability.
TEX Edit Distance for sample 148: 0.7834264039993286
CrystalBLEU Score for sample 148: 3.3335662686690037e-06
Sample 148 processing time: 70.32 seconds

Processing sample 149/560 - Caption: This image depicts a three-dimensional geometric figure within a rectangular prism. The rectangular prism is outlined with blue dashed lines, while a triangular plane is formed inside the prism, highlighted with solid red lines. The triangular plane appears to be shaded in light blue, indicating its surface area. The vertices of the triangular plane connect to various points on the edges of the rectangular prism. The perspective view shows the depth and spatial relationship between the triangular plane and the rectangular prism.

This description can be used to write the TikZ code for creating a 3D plot with a rectangular prism and an internal triangular plane.
TEX Edit Distance for sample 149: 0.5789985060691833
CrystalBLEU Score for sample 149: 3.4382357172242425e-06
Sample 149 processing time: 17.71 seconds

Processing sample 150/560 - Caption: This image depicts a Penrose diagram, which is a spacetime diagram used in general relativity. The diagram is a square with diagonal lines intersecting at the center, forming an "X" shape. The horizontal dashed line in the middle represents \( t = 0 \). There are two red dots labeled \( t_x \) and \( t_y \) on the left and right sides of the square, respectively. The diagonal lines are labeled \( x^- \) and \( x^+ \) with arrows indicating the direction of increasing \( t \). The arrows on the diagonal lines point towards the center of the diagram. The labels and arrows are in black, while the red dots and labels \( t_x \) and \( t_y \) are in red.
TEX Edit Distance for sample 150: 0.8228967189788818
CrystalBLEU Score for sample 150: 3.3771860652953983e-06
Sample 150 processing time: 70.37 seconds

Processing sample 151/560 - Caption: "An 8-petal rose curve (rhodonea curve) centered at the origin, with each petal symmetrically distributed around the center. The petals are created using the polar equation \( r = \sin(4\theta) \), where \( \theta \) ranges from 0 to \( 2\pi \)."
TEX Edit Distance for sample 151: 0.7981254458427429
CrystalBLEU Score for sample 151: 3.3767311483610954e-06
Sample 151 processing time: 70.44 seconds

Processing sample 152/560 - Caption: This image depicts a graph with a central triangular structure and three branches extending outward. The vertices are connected by edges labeled with weights, primarily "1", "q", and "q-1". The central triangle has vertices connected by edges labeled "1" and "q-1". Each vertex of the triangle has a branch extending outward. The branches are labeled with alternating weights "1" and "q". The vertices are represented by filled circles.

Caption for TikZ code:
"A graph with a central triangle and three branches extending outward. The edges are labeled with weights '1', 'q', and 'q-1'. The vertices are represented by filled circles. The central triangle has edges labeled '1' and 'q-1', and each vertex of the triangle has a branch with alternating weights '1' and 'q'."
TEX Edit Distance for sample 152: 0.5195642113685608
CrystalBLEU Score for sample 152: 3.591812403760378e-06
Sample 152 processing time: 19.98 seconds

Processing sample 153/560 - Caption: This image depicts a linear sequence of six nodes, each labeled with \( u'' \), \( u' \), \( u \), \( v \), \( v' \), and \( v'' \) from left to right. The nodes are connected by straight lines, forming a simple chain. Each node is represented by a circle, and the labels are centered within the circles. The nodes are evenly spaced along a horizontal line.
TEX Edit Distance for sample 153: 0.58495032787323
CrystalBLEU Score for sample 153: 3.871982655741781e-06
Sample 153 processing time: 9.96 seconds

Processing sample 154/560 - Caption: The image depicts a right-angled triangle \( \triangle ABC \) with the right angle at vertex \( A \). The vertices are labeled as \( A \), \( B \), and \( C \). The hypotenuse is \( BC \), and the legs are \( AB \) and \( AC \). There is a small square at vertex \( A \) indicating the right angle, and an arc at vertex \( B \) indicating an angle. The lines are drawn in black, and the right angle and arc are highlighted in pink.
TEX Edit Distance for sample 154: 0.6371855139732361
CrystalBLEU Score for sample 154: 4.266966197979737e-06
Sample 154 processing time: 14.03 seconds

Processing sample 155/560 - Caption: This image depicts a linear sequence of four circles, each labeled with different mathematical expressions. The circles are connected by straight lines. From left to right, the labels inside the circles are \( U(1)_k \), \( U(1)_{-k} \), \( U(1)_k \), and \( U(1)_{-k} \). Above the lines connecting the circles, there are additional labels: \( X, \bar{X} \) between the first and second circles, \( Y, \bar{Y} \) between the second and third circles, and \( Z, \bar{Z} \) between the third and fourth circles. The overall structure resembles a chain of nodes connected by edges, with specific labels on both the nodes and the edges.
TEX Edit Distance for sample 155: 0.8321524262428284
CrystalBLEU Score for sample 155: 4.018241955407037e-06
Sample 155 processing time: 70.49 seconds

Processing sample 156/560 - Caption: This image depicts a circle with center labeled as \( \Sigma \) and two points labeled \( G \) at the top and bottom of the circle. There are two arrows on the circle's circumference, one pointing counterclockwise on the left side labeled \( \bar{\ell} \) and the other pointing clockwise on the right side labeled \( \ell \). The circle is bisected vertically by a dashed line passing through the center \( \Sigma \) and the points \( G \).
TEX Edit Distance for sample 156: 0.692499041557312
CrystalBLEU Score for sample 156: 4.220692746721763e-06
Sample 156 processing time: 8.48 seconds

Processing sample 157/560 - Caption: The image is a histogram with the x-axis labeled "Ratio" and the y-axis labeled "Frequency." The x-axis ranges from 0.9 to 1, and the y-axis ranges from 0 to 8,000. The bars of the histogram show a distribution that increases sharply as the ratio approaches 1, with the highest frequency bar at the ratio of 1. The bars are filled with a gray color. The plot has a grid and the axes are labeled with numbers and ticks.
TEX Edit Distance for sample 157: 0.8234906196594238
CrystalBLEU Score for sample 157: 4.176871202703977e-06
Sample 157 processing time: 70.38 seconds

Processing sample 158/560 - Caption: The image consists of two parts. On the left, there is a diagram with vertical lines labeled "B" on both sides, and between them, there are horizontal lines labeled with numbers 3, 2, and dots representing "n+1". On the right, there is a graph with nodes labeled 1, 2, and 3. The central node labeled 3 is connected to nodes labeled 2, which are further connected to nodes labeled 1. The central node 3 is also connected to another node labeled 3, which is connected to nodes labeled 2 and 1, forming a symmetrical structure. An arrow points from the left diagram to the right graph, indicating a transformation from the left structure to the right structure.
TEX Edit Distance for sample 158: 0.8368772268295288
CrystalBLEU Score for sample 158: 3.734741847343985e-06
Sample 158 processing time: 70.63 seconds

Processing sample 159/560 - Caption: The image shows a plot of seven overlapping Gaussian functions, each with different colors (black, blue, red, green, orange, magenta, and cyan). The x-axis ranges from 0 to 1 and is labeled with specific points at \(0\), \(h\), \(2h\), \(3h\), \(4h\), \(5h\), \(6h\), \(7h\), and \(1\). The y-axis ranges from 0 to 0.6. Each Gaussian function peaks at one of the labeled points on the x-axis. The plot includes arrows at the ends of both axes to indicate the direction of increase.
TEX Edit Distance for sample 159: 0.691608190536499
CrystalBLEU Score for sample 159: 4.244069763192891e-06
Sample 159 processing time: 63.55 seconds

Processing sample 160/560 - Caption: The image depicts a sequence of sets \( V_1, V_{2i-1}, V_{2i}=W, V_{2i+1}=U \) arranged horizontally. Each set is represented as a rectangle containing several elements denoted by dots. Specific elements within these sets are highlighted with green circles and labeled as \( v \), \( v_1 \), \( v_i \), \( w \), and \( u \). The sets \( W \) and \( U \) are further subdivided into smaller rectangles labeled \( W' \) and \( U' \). There is a line connecting the element \( w \) in \( W \) to the element \( u \) in \( U \). The overall structure suggests a hierarchical or relational organization of elements within these sets.
TEX Edit Distance for sample 160: 0.6864628195762634
CrystalBLEU Score for sample 160: 4.241190729474804e-06
Sample 160 processing time: 9.72 seconds

Processing sample 161/560 - Caption: This image is a plot with a vertical axis labeled \(v\) and a horizontal axis labeled \(p\). The vertical axis has several marked points: \(\epsilon\) at the bottom, \(1/\epsilon^2\) in the middle, and \(v_{\text{max}}\) at the top. The horizontal axis has marked points: \(\epsilon^{20}\) near the origin and 1 at the far right. 

There are three horizontal dashed lines: one at \(\epsilon\), one at \(1/\epsilon^2\), and one at \(v_{\text{max}}\). The region between the horizontal lines at \(\epsilon\) and \(1/\epsilon^2\) is shaded. 

A vertical dashed line is drawn at \(p = \epsilon^{20}\), intersecting the horizontal dashed line at \(\epsilon\). The intersection is labeled \((1 + \epsilon)^k = v_i\).

There are two sets of points labeled \(X_{v_i}\) and \(X_{v_i}^+\) on the horizontal line at \(1/\epsilon^2\). The first set \(X_{v_i}\) includes points \(Y_2, Y_3, Y_4, Y_5, Y_6\), and the second set \(X_{v_i}^+\) includes points \(Y_4, Y_5, Y_6, Y_7, Y_8, Y_9\). The points \(X_{v_i}\) and \(X_{v_i}^+\) are enclosed in curly braces.

This description should help in writing the TikZ code to replicate the figure.
TEX Edit Distance for sample 161: 0.800089418888092
CrystalBLEU Score for sample 161: 4.099416276645349e-06
Sample 161 processing time: 70.50 seconds

Processing sample 162/560 - Caption: This image depicts a geometric figure, specifically a right triangle with an additional curved segment and several labeled elements. The base of the triangle is labeled as "1". The hypotenuse is labeled with the variable "s'", and the two legs are labeled with the variables "α" and "β". The angle opposite the base is labeled "β". There is a curved segment extending from the top vertex to a point on the hypotenuse, labeled as "ξ/2". The image also includes three equations on the right side:

1. \(\beta = \sqrt{1 - \left(\frac{\xi}{2}\right)^2}\)
2. \(\alpha = 1 - \beta\)
3. \(s' = \sqrt{\alpha^2 + \left(\frac{\xi}{2}\right)^2}\)

These equations describe the relationships between the variables in the triangle.
TEX Edit Distance for sample 162: 0.6616210341453552
CrystalBLEU Score for sample 162: 4.322954396056418e-06
Sample 162 processing time: 17.04 seconds

Processing sample 163/560 - Caption: The image shows three subfigures, each depicting a different spherical harmonic function visualized in 3D. Each subfigure includes a spherical surface with a distinct color scheme and grid pattern, and labeled x, y, and z axes. The first subfigure (left) displays a spherical harmonic with a uniform red color. The second subfigure (middle) shows a spherical harmonic with a multicolored pattern, transitioning from red at the top to blue at the bottom. The third subfigure (right) illustrates a spherical harmonic with two lobes, one red and one blue, stacked vertically. All subfigures are enclosed in a yellow border.

Caption: "Figure 1: Various spherical harmonics with TikZ"
TEX Edit Distance for sample 163: 0.6770289540290833
CrystalBLEU Score for sample 163: 4.4757717153088405e-06
Sample 163 processing time: 11.17 seconds

Processing sample 164/560 - Caption: This image depicts a General MIDI Drum Map with a labeled keyboard diagram. The diagram shows specific key numbers (35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50) on a piano keyboard and their corresponding drum sounds. The key numbers are displayed on the left side of the keyboard, and the drum sounds are listed on the right side. The drum sounds include Acoustic Bass Drum, Bass Drum 1, Side Stick, Acoustic Snare, Hand Clap, Electric Snare, Low Floor Tom, Closed Hi-Hat, High Floor Tom, Pedal Hi-Hat, Low Tom, Open Hi-Hat, Low-Mid Tom, Hi-Mid Tom. The keyboard keys are shaded in black and white, with the corresponding drum sound names in a gray box to the right of each key. The diagram is centered on the page with placeholder text above and below it.
TEX Edit Distance for sample 164: 0.6741039752960205
CrystalBLEU Score for sample 164: 4.8718931436155745e-06
Sample 164 processing time: 24.53 seconds

Processing sample 165/560 - Caption: The image consists of two diagrams side by side, each depicting geometric constructions involving right triangles and distances.

**Left Diagram:**
- A right triangle is shown with a blue hypotenuse.
- The right angle is marked with a small black square.
- The distance along the base of the triangle is labeled as \( d(k, l) \).

**Right Diagram:**
- A right triangle is shown with an orange rectangle extending vertically from the base to the hypotenuse.
- The right angle is marked with a small black square.
- The distance along the base of the triangle is labeled as \( d(j, j-1) \).

Both diagrams share a common theme of right triangles with marked distances and angles, but they differ in the specific geometric elements highlighted (blue hypotenuse vs. orange rectangle).
TEX Edit Distance for sample 165: 0.5010765790939331
CrystalBLEU Score for sample 165: 5.178879009202355e-06
Sample 165 processing time: 18.71 seconds

Processing sample 166/560 - Caption: The image depicts a directed graph with six nodes labeled from 1 to 6. The nodes are connected by directed edges as follows:
- Node 1 has an edge pointing to Node 3.
- Node 2 has edges pointing to Nodes 1, 3, and 5.
- Node 3 has edges pointing to Nodes 2 and 6.
- Node 4 has an edge pointing to Node 1.
- Node 5 has edges pointing to Nodes 2 and 3.
- Node 6 has an edge pointing to Node 5.

The nodes are arranged in a roughly circular layout.
TEX Edit Distance for sample 166: 0.6808400750160217
CrystalBLEU Score for sample 166: 5.627568961642999e-06
Sample 166 processing time: 17.08 seconds

Processing sample 167/560 - Caption: This image depicts a coordinate system with the x1-axis and x2-axis, ranging from -2 to 2 on both axes. The background is divided into two regions: the left half is shaded in red and the right half in green. The x1-axis is labeled with points a(t_min) at -1 and a(t_max) at 1. There is a semicircular arc labeled Γ centered at the origin, spanning from a(t_min) to a(t_max). The axes are labeled with x1 and x2, and there are tick marks at each integer value on both axes.
TEX Edit Distance for sample 167: 0.8143982291221619
CrystalBLEU Score for sample 167: 5.531218535573565e-06
Sample 167 processing time: 70.35 seconds

Processing sample 168/560 - Caption: This image is a phase diagram with two regimes: the perturbative regime and the non-perturbative regime. The diagram is plotted on a Cartesian coordinate system with the horizontal axis labeled as \( l_s \) and the vertical axis labeled as \( b \). The perturbative regime is located below the dashed horizontal line at \( l_s \). The non-perturbative regime is located above the dashed horizontal line and to the right of the solid line labeled "Boundary II" which has a positive slope and is described by \( b \sim R(E) \). The solid horizontal line labeled "Boundary I" separates the perturbative regime from the non-perturbative regime. The non-perturbative regime is characterized by the expression \( a(s, b) \sim \exp(-cS_{BH}) \). The bottom right corner of the diagram includes the expression \( r_S(E) \sim \left( E g_s^2 l_p^{D-2} \right)^{1/(D-3)} \).

To write the TikZ code for this diagram, you would need to:
1. Create a Cartesian coordinate system.
2. Draw and label the horizontal and vertical axes.
3. Add the dashed horizontal line for the perturbative regime.
4. Add the solid lines for Boundary I and Boundary II.
5. Place the text labels appropriately within the diagram.
TEX Edit Distance for sample 168: 0.8101164102554321
CrystalBLEU Score for sample 168: 5.315897377914037e-06
Sample 168 processing time: 70.47 seconds

Processing sample 169/560 - Caption: This image depicts a sequence of sets \( V_1, V_2, \ldots, V_{\beta+1} \) represented by ellipses. Each set contains points labeled \( v, x_\beta, y_\beta, y_1, x_1, u \). There are directed arrows between these points indicating transitions or connections. A red path labeled \( P_1 \) and a blue dashed path labeled \( P_2 \) connect these points across the sets. The red path \( P_1 \) seems to form a continuous connection through the points \( v, x_\beta, y_\beta, y_1, x_1, u \), while the blue dashed path \( P_2 \) forms a similar connection but with a different trajectory. An arrow pointing to the right indicates progression from \( V_1 \) to \( V_{\beta+1} \).
TEX Edit Distance for sample 169: 0.8123152852058411
CrystalBLEU Score for sample 169: 5.012039472122846e-06
Sample 169 processing time: 7.08 seconds

Processing sample 170/560 - Caption: This image depicts a graph with two curves, one in red and one in blue, intersecting at three points along the x-axis. The x-axis is labeled from 0 to 2, and the y-axis is labeled from 0 upwards. The area between the two curves from x=0 to x=1 is shaded in blue. There are vertical dashed lines at x=1 and x=2, intersecting the curves at these points. Additionally, there are small circles at the points of intersection of the curves with the vertical dashed lines and the x-axis. The red curve starts below the x-axis at x=0, rises to intersect the blue curve, and then falls again. The blue curve starts at the origin, rises above the x-axis, and intersects the red curve at x=1 and x=2.
TEX Edit Distance for sample 170: 0.6405792832374573
CrystalBLEU Score for sample 170: 5.384782486680756e-06
Sample 170 processing time: 23.37 seconds

Processing sample 171/560 - Caption: This image displays a polar plot with a circle of radius 5 centered at the origin. The plot is divided into four quadrants by the x and y axes, with each quadrant containing a blue shaded region. The shaded regions are bounded by the circle and lines extending from the origin at angles of 45 degrees, 135 degrees, 225 degrees, and 315 degrees. The lines are highlighted in magenta. The plot includes grid lines and labeled axes, with the origin marked by a small circle.
TEX Edit Distance for sample 171: 0.8091487288475037
CrystalBLEU Score for sample 171: 5.303792821420053e-06
Sample 171 processing time: 70.39 seconds

Processing sample 172/560 - Caption: This image depicts a graph with vertices and edges, where vertices are represented by circles and edges by lines connecting the circles. The graph has two distinct regions: one with vertices labeled \(B_1, B_2, B_3, B_4, B_5, A_1, A_2,3, B'\) in blue and another with vertices labeled \(v\) in orange. The vertices have associated values, such as +1, -1, and -2. The edges connecting the vertices are labeled \(P\) and \(H\). The vertices \(B_2\) and \(B_3\) are connected to \(A_2,3\), which has a value of -2. The vertices \(A_1\) and \(B_1\) are connected to \(B'\), which is connected to \(v\). The vertices \(B_4\) and \(B_5\) are also connected to \(B'\). The graph structure and the connections between vertices should be carefully replicated using TikZ code, ensuring the correct placement and labeling of vertices and edges.
TEX Edit Distance for sample 172: 0.8332952857017517
CrystalBLEU Score for sample 172: 4.702145981238633e-06
Sample 172 processing time: 70.60 seconds

Processing sample 173/560 - Caption: The image depicts a series of concentric hexagons centered around a common point. Each hexagon is progressively larger, creating a layered effect. The hexagons are evenly spaced and share the same center.
TEX Edit Distance for sample 173: 0.7417107224464417
CrystalBLEU Score for sample 173: 4.794788662751382e-06
Sample 173 processing time: 18.36 seconds

Processing sample 174/560 - Caption: The image shows a plot of a parabolic function \( y = x^2 \) with blue dashed lines. The plot is centered within a small box, with axes labeled and ticks marked. The entire plot is positioned in the middle of the figure, with a vertical dashed line extending from the top to the bottom of the image, passing through the center of the plot. The vertical dashed line serves as a reference line, aligning with the vertex of the parabola at the origin (0,0).
TEX Edit Distance for sample 174: 0.7796907424926758
CrystalBLEU Score for sample 174: 4.786615856842323e-06
Sample 174 processing time: 70.48 seconds

Processing sample 175/560 - Caption: This image depicts a labeled graph \( G_{100} \) with six vertices and several edges. The vertices are labeled from 1 to 6. The edges are as follows:
- Vertex 1 is connected to vertices 2 and 4.
- Vertex 2 is connected to vertex 3.
- Vertex 3 is connected to vertex 4.
- Vertex 4 is connected to vertices 5 and 6.
- Vertex 5 is connected to vertex 6.
- There are two additional dashed blue edges: one connecting vertex 4 to vertex 5 and another connecting vertex 4 to vertex 6.

The graph is drawn in a way that the vertices are positioned as follows:
- Vertex 1 is at the bottom right.
- Vertex 2 is to the top right of vertex 1.
- Vertex 3 is to the top left of vertex 4.
- Vertex 4 is at the bottom left.
- Vertex 5 is to the bottom left of vertex 4.
- Vertex 6 is to the right of vertex 5.

The label \( G_{100} \) is centered below the graph.
TEX Edit Distance for sample 175: 0.5581721067428589
CrystalBLEU Score for sample 175: 5.072025585765843e-06
Sample 175 processing time: 19.99 seconds

Processing sample 176/560 - Caption: The image depicts a geometric region \( D \) bounded by three curves. The lower boundary consists of two straight lines labeled \( C_0 \) that meet at a point, forming an angle. The upper boundary is a curved line labeled \( S = \{r = 0\} \). The region \( D \) is shaded in gray. The vertices where the lines \( C_0 \) meet and where \( C_0 \) meets \( S \) are marked with black dots. The curved line \( S \) is dashed, indicating it is different from the solid lines \( C_0 \).
TEX Edit Distance for sample 176: 0.7998923659324646
CrystalBLEU Score for sample 176: 4.96147387274505e-06
Sample 176 processing time: 70.43 seconds

Processing sample 177/560 - Caption: The figure is a line plot showing the prediction error (in \(10^{-5}\)) versus training steps (in \(10^4\)). The x-axis ranges from 0 to 20, and the y-axis ranges from 0 to 10. The plot includes four lines representing different methods: TL-NODE (ours, \(p=1\)) in magenta with diamond markers, T-NODE (\(p=2\)) in black with star markers, RK4 in blue with square markers, and Vanilla NODE in gray with circle markers. Each line shows a decreasing trend in prediction error as the training steps increase. The legend is located at the top center of the plot.
TEX Edit Distance for sample 177: 0.8178262114524841
CrystalBLEU Score for sample 177: 4.725286175534494e-06
Sample 177 processing time: 1.34 seconds

Processing sample 178/560 - Caption: The image depicts a blue outlined rightward arrow inside a black outlined square. The arrow is centered within the square, and the square has rounded corners. The arrow has a triangular head and a rectangular tail. The overall design is simple and geometric.

This description should help you write the TikZ code to recreate this image.
TEX Edit Distance for sample 178: 0.6605759263038635
CrystalBLEU Score for sample 178: 4.932285359068723e-06
Sample 178 processing time: 10.80 seconds

Processing sample 179/560 - Caption: This image depicts a complex plane with sectors highlighting different regions. The horizontal axis represents the real part (Re(λ)) and the vertical axis represents the imaginary part (Im(λ)) of a complex number λ. Three sectors are shown:

1. A sector labeled \( S(\omega/3) \) containing \( A_1 \), oriented along the positive real axis.
2. A sector labeled \( e^{i \frac{2\pi}{3}} S(\omega/3) \) containing \( A_2 \), oriented at an angle of \( \frac{2\pi}{3} \) radians counterclockwise from the positive real axis.
3. A sector labeled \( e^{-i \frac{2\pi}{3}} S(\omega/3) \) containing \( A_3 \), oriented at an angle of \( -\frac{2\pi}{3} \) radians clockwise from the positive real axis.

The sectors are shaded in blue, and the boundaries of the sectors are marked with blue lines. The real and imaginary axes are represented by dashed black lines.
TEX Edit Distance for sample 179: 0.8205842971801758
CrystalBLEU Score for sample 179: 4.75899053795268e-06
Sample 179 processing time: 70.50 seconds

Processing sample 180/560 - Caption: The image shows a polygonal shape with a gradient fill transitioning from green at the top to blue at the bottom. The shape has a complex outline with multiple right angles, resembling a pixelated or blocky structure. The perimeter of the shape is highlighted with a thick red border. This combination of gradient fill and red border emphasizes the shape's boundaries and structure.
TEX Edit Distance for sample 180: 0.8008724451065063
CrystalBLEU Score for sample 180: 4.616819227789843e-06
Sample 180 processing time: 70.48 seconds

Processing sample 181/560 - Caption: The image depicts a graph consisting of a path with three vertices and a loop attached to the last vertex. The vertices are represented by red dots. The path is a straight horizontal line with three evenly spaced vertices. The loop is a closed curve starting and ending at the last vertex of the path, forming a teardrop shape.
TEX Edit Distance for sample 181: 0.6913731098175049
CrystalBLEU Score for sample 181: 4.9839091830935385e-06
Sample 181 processing time: 21.29 seconds

Processing sample 182/560 - Caption: The image depicts a directed graph with four nodes labeled "1", "v1", "v2", and "w". The edges between the nodes are directed as follows:
- There is a loop from node "1" to itself.
- There is an arrow from node "v1" to node "1".
- There is an arrow from node "v2" to node "v1" with a label "1".
- There is an arrow from node "w" to node "v2" with a label "2".
TEX Edit Distance for sample 182: 0.787071168422699
CrystalBLEU Score for sample 182: 4.956245776948965e-06
Sample 182 processing time: 71.78 seconds

Processing sample 183/560 - Caption: The image depicts a hexagonal grid with vertices labeled from 0 to 12. The vertices are connected by edges forming a pattern of equilateral triangles. The grid is enclosed within a dashed hexagonal boundary. Each vertex is represented by a black dot, and the edges are straight lines connecting these dots. The central vertex is labeled 0, and the surrounding vertices are labeled sequentially in a clockwise manner. The vertices and edges form a regular, repeating pattern typical of a hexagonal tiling.
TEX Edit Distance for sample 183: 0.6374175548553467
CrystalBLEU Score for sample 183: 5.244815547601505e-06
Sample 183 processing time: 32.84 seconds

Processing sample 184/560 - Caption: This image depicts a table with two columns labeled "Domain" and "Range". The table contains mappings from the domain to the range using arrows. The mappings are as follows: 8 maps to 0, 9 maps to both 1 and 2, and 10 maps to 3. The table is enclosed by horizontal lines at the top and bottom. The arrows are drawn from the domain values to the corresponding range values.
TEX Edit Distance for sample 184: 0.8085083961486816
CrystalBLEU Score for sample 184: 5.198522033750643e-06
Sample 184 processing time: 70.50 seconds

Processing sample 185/560 - Caption: The image depicts a sequence of nodes connected by directed arrows, representing a flow from one node to another. Each node is labeled with a variable (e.g., \( y_i \), \( y_{i-1} \), \( x_j \), \( y_{i-1} \)) and is enclosed in a dashed red circle. The arrows between the nodes are labeled with mathematical symbols (e.g., \( \sigma_1 \), \( \sigma_1^{-1} \), \( \sigma_0^{-1} \), \( \sigma_1 \), \( x_j^{-1} \), \( \sigma_0^{-1} \)). Below each node, there is a label indicating the column position (e.g., "2nd column", "1st column", "3rd column"). The nodes and arrows are arranged horizontally, with arrows pointing from left to right.

This description can help in writing the TikZ code by identifying the nodes, their labels, the arrows connecting them, and the corresponding labels for the arrows and columns.
TEX Edit Distance for sample 185: 0.8131067752838135
CrystalBLEU Score for sample 185: 5.069257784363528e-06
Sample 185 processing time: 70.53 seconds

Processing sample 186/560 - Caption: The image consists of two graphs. The left graph is a circular representation of a bipartite graph with vertices labeled 1 through 5 placed on the circumference of a circle. The edges are drawn as chords connecting pairs of vertices. The right graph is a straight-line representation of the same bipartite graph with vertices 1, 4, and 5 on the top row and vertices 2 and 3 on the bottom row. Edges are drawn as straight lines connecting the vertices according to the same pairs as in the circular representation.
TEX Edit Distance for sample 186: 0.8272038102149963
CrystalBLEU Score for sample 186: 4.966357654035535e-06
Sample 186 processing time: 70.49 seconds

Processing sample 187/560 - Caption: The image depicts a graph with several key points and labeled horizontal lines. The graph has a continuous curve with labeled points (1), (2), (3), (4), (5), and (6). There are three dashed horizontal lines labeled \(A_1\), \(A_2\), and \(A_2 - c\). The x-axis ranges from -1 to +1. The curve starts from the left at -1, rises to point (5), dips to point (4), continues to point (3), rises to point (1), dips to point (2), and finally rises to point (6) before descending to +1. The points (1) and (6) are connected by a dashed line, indicating a possible relationship or comparison between these points.
TEX Edit Distance for sample 187: 0.5525745749473572
CrystalBLEU Score for sample 187: 5.462292029436193e-06
Sample 187 processing time: 19.43 seconds

Processing sample 188/560 - Caption: The image consists of three 7x7 grids placed horizontally in a row. Each grid has arrows indicating directions. The first grid has arrows pointing up on the top edge and right on the right edge. The second grid has arrows pointing up on the top edge and right on the right edge. The third grid has arrows pointing up on the top edge and right on the right edge. The grids are separated by some space.
TEX Edit Distance for sample 188: 0.8489964604377747
CrystalBLEU Score for sample 188: 5.13367035764951e-06
Sample 188 processing time: 70.55 seconds

Processing sample 189/560 - Caption: The image consists of three vertically aligned circles, each divided into two or more colored segments.

1. The top circle is divided into two equal halves: the left half is red, and the right half is blue.
2. The middle circle is divided into five segments: the leftmost segment is red, followed by a green segment, a blue segment, a yellow segment, and a magenta segment.
3. The bottom circle is divided into two equal halves: the left half is dark gray, and the right half is light gray.
TEX Edit Distance for sample 189: 0.6862133145332336
CrystalBLEU Score for sample 189: 5.363104750196155e-06
Sample 189 processing time: 12.28 seconds

Processing sample 190/560 - Caption: The image depicts a diagram with two distinct regions, \( \mathcal{M}' \) and \( \mathcal{M} \), separated by a dashed blue boundary. Inside \( \mathcal{M}' \), there are two nodes labeled \( p \) and \( q \). Inside \( \mathcal{M} \), there are two nodes labeled \( u \) and \( v \). There are three directed arrows: one from \( p \) to \( u \) labeled \( c \), one from \( p \) to \( v \) labeled \( b \), and one from \( q \) to \( v \) also labeled \( b \). The region \( \mathcal{M} \) is highlighted with a red border, while \( \mathcal{M}' \) is highlighted with a blue dashed border.
TEX Edit Distance for sample 190: 0.788577675819397
CrystalBLEU Score for sample 190: 5.220137543423221e-06
Sample 190 processing time: 70.46 seconds

Processing sample 191/560 - Caption: The image consists of a large circle with a smaller square inside it. The square is positioned towards the bottom-left quadrant of the circle, and its sides are parallel to the horizontal and vertical axes. The circle and the square are both centered at different points, with the circle being significantly larger than the square.
TEX Edit Distance for sample 191: 0.628892183303833
CrystalBLEU Score for sample 191: 5.373342043658902e-06
Sample 191 processing time: 8.29 seconds

Processing sample 192/560 - Caption: This image depicts a directed graph with nodes and edges. The nodes are labeled \( v_0, v_1, v_2, v_3, v_4, v_5, \) and \( v_6 \). The edges are labeled \( w_0, w_1, w_2, w_3, w_4, w_5, \) and \( w_6 \). The edges \( w_0, w_1, w_4, w_5, \) and \( w_6 \) are drawn in blue, while the edges \( w_2 \) and \( w_3 \) are drawn in red. The graph starts at \( v_0 \) and ends at \( v_6 \), with arrows indicating the direction of the edges. The nodes \( v_1, v_2, v_3, v_4, \) and \( v_5 \) are arranged in a horizontal line, and the edges \( w_2 \) and \( w_3 \) form loops connecting \( v_2 \) to \( v_3 \) and \( v_3 \) to \( v_2 \) respectively.
TEX Edit Distance for sample 192: 0.6484624743461609
CrystalBLEU Score for sample 192: 5.489279916325909e-06
Sample 192 processing time: 32.69 seconds

Processing sample 193/560 - Caption: This image depicts a grid network with horizontal and vertical lines intersecting at nodes. The nodes are represented by black dots. There are two horizontal cuts labeled "Cut A" and "Cut B" at the bottom and top of the grid, respectively. A rectangular box is centered around one of the nodes, labeled \( n_i(t) \). Four nodes adjacent to the central node are labeled with the Greek letter \( \alpha \). The grid lines are thicker at the edges near the cuts and thinner elsewhere.

To create this image using TikZ, you would need to:
1. Draw a grid of lines.
2. Highlight certain nodes with black dots.
3. Label specific nodes with \( \alpha \).
4. Draw a rectangular box around a central node and label it \( n_i(t) \).
5. Add labels "Cut A" and "Cut B" at the appropriate positions on the grid.
TEX Edit Distance for sample 193: 0.8117300271987915
CrystalBLEU Score for sample 193: 5.272749407662796e-06
Sample 193 processing time: 70.60 seconds

Processing sample 194/560 - Caption: This image shows two adjacent, vertically oriented, five-sided polygons (pentagons) with a concave shape. Each pentagon has a thick black outline and is filled with a solid gray color. The polygons are positioned side by side with a small gap between them. The top and bottom edges of each pentagon are parallel to each other, with the top edge slightly longer than the bottom edge, and the sides are angled inward to form the concave shape.
TEX Edit Distance for sample 194: 0.7155911326408386
CrystalBLEU Score for sample 194: 5.156317650871766e-06
Sample 194 processing time: 6.11 seconds

Processing sample 195/560 - Caption: This image depicts a graph with a central triangular structure and three branches extending outward. The vertices are connected by edges labeled with weights, primarily "1", "q", and "q-1". The central triangle has vertices connected by edges labeled "1" and "q-1". Each vertex of the triangle has a branch extending outward. The branches are labeled with alternating weights "1" and "q". The vertices are represented by filled circles.

Caption for TikZ code:
"A graph with a central triangle and three branches extending outward. The edges are labeled with weights '1', 'q', and 'q-1'. The vertices are represented by filled circles. The central triangle has edges labeled '1' and 'q-1', and each vertex of the triangle has a branch with alternating weights '1' and 'q'."
TEX Edit Distance for sample 195: 0.8101475834846497
CrystalBLEU Score for sample 195: 5.000650175592628e-06
Sample 195 processing time: 70.51 seconds

Processing sample 196/560 - Caption: This image depicts a block diagram with an input \( x_i(t_0) \) on the left, labeled as "Input". The input is connected to a block that contains two equations: 
\[ \theta_i = 0 \]
\[ \theta_{i+1}(t_0) = x_i(t_0) + \theta_i(t_0) \]
The input \( x_i(t_0) \) enters the block, and the output \( x_i(t_0) \) exits the block on the right. The block has an internal process represented by \( \theta_i(t_0) \) entering from the left and \( \theta_i(t_0) \) exiting on the right.
TEX Edit Distance for sample 196: 0.8180167078971863
CrystalBLEU Score for sample 196: 4.936256872730007e-06
Sample 196 processing time: 70.51 seconds

Processing sample 197/560 - Caption: The image depicts a directed graph with four nodes labeled "A," "Lx," "Ly," and "Z." Node "A" has a black arrow pointing to node "Ly." Node "Lx" has a black arrow pointing to node "Ly." Node "Ly" has a red dashed arrow pointing to node "Z." The labels "A," "Lx," and "Ly" are in black, while the label "Z" is in red.
TEX Edit Distance for sample 197: 0.5431900024414062
CrystalBLEU Score for sample 197: 5.233049381712704e-06
Sample 197 processing time: 49.07 seconds

Processing sample 198/560 - Caption: The image depicts a vertical arrangement of four closely spaced parallel lines. Each line is of equal length and thickness, and they are evenly spaced from each other. The lines are centered on the vertical axis of the image.

This description can help you write the TikZ code to create this figure.
TEX Edit Distance for sample 198: 0.5624631643295288
CrystalBLEU Score for sample 198: 5.384991549312664e-06
Sample 198 processing time: 11.56 seconds

Processing sample 199/560 - Caption: The image shows two adjacent rounded rectangles with a black border and gray fill. The left rectangle contains an icon of a stack of green dollar bills wrapped with a yellow band, while the right rectangle is empty.
TEX Edit Distance for sample 199: 0.8055605292320251
CrystalBLEU Score for sample 199: 5.346986395312274e-06
Sample 199 processing time: 77.19 seconds

Processing sample 200/560 - Caption: The image depicts a mathematical diagram featuring two semicircles and a shaded rectangular region labeled \( F \). The semicircles are centered at \( -1 \) and \( 0 \) on the x-axis, with radii of 1 and 1/2, respectively. The larger semicircle is solid, while the smaller one is dashed. The shaded region extends horizontally from \( -2 \) to \( k(1+\lambda) - 2 \) and vertically from the x-axis to an unspecified height. The y-axis is also shown, intersecting the x-axis at the origin.
TEX Edit Distance for sample 200: 0.8303912878036499
CrystalBLEU Score for sample 200: 5.249177878227333e-06
Sample 200 processing time: 89.67 seconds

Processing sample 201/560 - Caption: This image depicts a directed graph with four nodes labeled V, W, X, and Y. Each node has a set of elements associated with it, written in curly braces next to the nodes. The edges between the nodes are directed and are represented by arrows. The edges are color-coded and styled differently: red dashed lines and blue dotted lines. The red dashed edges are directed from V to W, W to X, and X to itself, while the blue dotted edges are directed from V to X, W to V, and X to V. The labels on the edges indicate the sets of elements associated with each transition. 

To create this figure using TikZ, you would need to:
1. Define the nodes and their positions.
2. Draw the directed edges with appropriate colors and styles.
3. Add labels to the nodes and edges.

This description should help in writing the TikZ code to replicate the figure.
TEX Edit Distance for sample 201: 0.7947332859039307
CrystalBLEU Score for sample 201: 5.010971538191124e-06
Sample 201 processing time: 81.51 seconds

Processing sample 202/560 - Caption: The image consists of a 2x3 matrix of subfigures, each containing a yellow cat-like figure with a red object at its base, set against a gray background with a grid pattern. The subfigures are labeled as follows: "1.1 foo" in the top-left, "1.2 bar" in the top-center, "1.3 baz" in the bottom-left, "1.4 foo" in the bottom-center, and "1.5 bar" in the bottom-right. There is an arrow pointing from "1.1 foo" to "1.2 bar". Below the matrix, there is a caption labeled "Figure 1: A matrix of figures." Additionally, there is a reference text below the figure caption that reads "See subfigure 1.1 and 1.5."
TEX Edit Distance for sample 202: 0.7377539277076721
CrystalBLEU Score for sample 202: 6.320477798800089e-06
Sample 202 processing time: 46.22 seconds

Processing sample 203/560 - Caption: This image depicts a directed graph (digraph) with six vertices arranged in a hexagonal pattern. Each vertex is connected to every other vertex with directed edges, forming a complete digraph. The vertices are labeled with different combinations of the letters "W" and "D" (e.g., \(W_{UDUD}\), \(W_{UDDU}\), etc.). The edges have arrows indicating the direction of the connection between the vertices. The labels are positioned around the vertices in a symmetric manner.
TEX Edit Distance for sample 203: 0.8191553354263306
CrystalBLEU Score for sample 203: 6.166202318722505e-06
Sample 203 processing time: 70.30 seconds

Processing sample 204/560 - Caption: The image depicts two Young tableaux side by side. The left tableau is labeled with \(\lambda_1, \lambda_2, \ldots, \lambda_9\) along the y-axis, and the right tableau is labeled with \(\mu_1, \mu_2, \ldots, \mu_9\) along the y-axis. Each tableau consists of a series of boxes arranged in rows, with some boxes filled in black to indicate specific partitions. The rows are aligned to the left in both tableaux, and the columns are aligned to the top. The labels are written in red, and the boxes are outlined in black with dotted lines for the unfilled boxes.
TEX Edit Distance for sample 204: 0.8578979969024658
CrystalBLEU Score for sample 204: 5.753629290841388e-06
Sample 204 processing time: 70.46 seconds

Processing sample 205/560 - Caption: This image depicts a geometric figure on a coordinate plane with axes labeled \( \frac{1}{p} \) (horizontal) and \( s \) (vertical). The plot includes the following elements:

1. **Axes and Grid**: The horizontal axis ranges from 0 to 2, with specific points marked at \( \frac{1}{q} + 1 \) and 1. The vertical axis ranges from 0 to 1, with a point marked at \( \frac{1}{q} \).
2. **Triangles**: Two triangles are shown:
   - A red triangle with vertices at (1, 0), (1, 1), and \( (\frac{1}{q} + 1, 0) \).
   - A green triangle with vertices at (0, 0), (1, 0), and \( (\frac{1}{q} + 1, \frac{1}{q}) \).
3. **Points and Labels**: 
   - Points \( F_{1, q} \), \( F_{p, q} \), and \( F_{p, 1} \) are marked with blue dots and connected by blue lines.
   - The points \( (1, 0) \), \( (\frac{1}{q} + 1, 0) \), and \( (1, 1) \) are marked with red dots.
4. **Dashed Lines**: 
   - Horizontal dashed lines extend from \( s = 1 \) and \( s = \frac{1}{q} \) to the vertical axis.
   - A vertical dashed line extends from \( \frac{1}{p} = 1 \) to the horizontal axis.
5. **Colors**: The red triangle is filled with a light red color, and the green triangle is filled with a light green color.

This description should help in writing the TikZ code to recreate this figure.
TEX Edit Distance for sample 205: 0.5006683468818665
CrystalBLEU Score for sample 205: 6.468946010886191e-06
Sample 205 processing time: 39.31 seconds

Processing sample 206/560 - Caption: The image shows a rectangular frame containing a grey-filled ellipse. Inside the ellipse, there is the text "H^0(\mathbb{R}^n)" positioned towards the bottom left. Outside the ellipse, but within the rectangle, there is the text "H^0(\mathbb{R}^n) = L^2(\mathbb{R}^n) (\gamma = 0)" positioned towards the top left. The rectangle has a black border, and the ellipse is centered within the rectangle.
TEX Edit Distance for sample 206: 0.8300902247428894
CrystalBLEU Score for sample 206: 6.212481362380081e-06
Sample 206 processing time: 70.50 seconds

Processing sample 207/560 - Caption: This image illustrates the determinant of a 2x2 matrix. The matrix elements are labeled as \( u \), \( v \), \( x' \), and \( y' \). The determinant is shown with a visual aid: a red arrow indicating the product of \( u \) and \( y' \), and a red loop indicating the product of \( v \) and \( x' \), with a minus sign in the center to denote the subtraction of these products. The equation is written as \( \text{det} = \begin{vmatrix} u & v \\ x' & y' \end{vmatrix} = \cdots \).

This description can be used to write the TikZ code to recreate this image.
TEX Edit Distance for sample 207: 0.796348512172699
CrystalBLEU Score for sample 207: 6.185268110786406e-06
Sample 207 processing time: 70.44 seconds

Processing sample 208/560 - Caption: This image is a table that represents the configuration of clutches and brakes for different gears in a mechanical system. The table has the following columns:

1. **G**: Gear number (1 to 6 and R for reverse).
2. **Clutch**: Columns labeled A, B, and E.
3. **Brake**: Columns labeled C and D.
4. **i**: Gear ratio for each gear.
5. **Gear step**: Gear step values for each gear.

Each cell in the Clutch and Brake columns contains either a blue dot (indicating engagement) or is empty (indicating disengagement). The gear ratios and gear step values are numerical and aligned to the right of the table.

The table is enclosed in a grid with blue lines, and the text and dots are also in blue. The total gear step value is provided at the bottom of the Gear step column.

To create this table in TikZ, you would need to use the `matrix` environment for the grid, `node` for the text and dots, and set the color to blue for all elements.
TEX Edit Distance for sample 208: 0.8090845346450806
CrystalBLEU Score for sample 208: 5.948355091202544e-06
Sample 208 processing time: 70.47 seconds

Processing sample 209/560 - Caption: This image consists of two adjacent Penrose diagrams. The left diagram features a pink curve labeled "I" and a black dot at the center. The right diagram has a blue curve labeled "R" and two red dots aligned vertically. Both diagrams have jagged boundaries on the top and bottom edges, and dashed lines outlining the borders. The left diagram has a horizontal axis labeled with "-1" and "π", while the right diagram has a horizontal axis labeled with "0". The diagrams are enclosed in a dashed rectangular frame.
TEX Edit Distance for sample 209: 0.8242447972297668
CrystalBLEU Score for sample 209: 5.828988378428216e-06
Sample 209 processing time: 70.54 seconds

Processing sample 210/560 - Caption: This image depicts a geometric shape consisting of a central circle with a dashed outline, inscribed within a diamond-like shape with curved sides. The diamond shape has sharp vertices at the left and right ends, and smooth, curved connections to the circle at the top and bottom. The overall structure resembles an eye with a circular pupil and curved edges.

To create this in TikZ, you would need to:
1. Draw a circle with a dashed outline.
2. Draw a diamond-like shape with curved sides that intersect the circle at the top and bottom.

Here is a sample TikZ code to help you get started:

```latex
\documentclass{standalone}
\usepackage{tikz}

\begin{document}
\begin{tikzpicture}
    % Draw the dashed circle
    \draw[dashed] (0,0) circle (2);
    
    % Draw the curved diamond shape
    \draw[thick] 
        (-4,0) -- 
        plot [smooth, tension=1] coordinates {(-2,2) (2,2)} -- 
        (4,0) -- 
        plot [smooth, tension=1] coordinates {(2,-2) (-2,-2)} -- 
        cycle;
\end{tikzpicture}
\end{document}
```

This code will create a figure similar to the one shown in the image. Adjust the coordinates and dimensions as necessary to match the exact proportions.
TEX Edit Distance for sample 210: 0.8153400421142578
CrystalBLEU Score for sample 210: 5.539746885661758e-06
Sample 210 processing time: 70.57 seconds

Processing sample 211/560 - Caption: The image shows four labeled bipartite graphs, each with six vertices arranged in two rows of three vertices each. The graphs are labeled \(L_{10}\), \(L_{11}\), \(L_{12}\), and \(L_{13}\) from left to right. 

- \(L_{10}\): A complete bipartite graph where each vertex in the top row is connected to each vertex in the bottom row.
- \(L_{11}\): Similar to \(L_{10}\), but with additional edges connecting vertices within the same row.
- \(L_{12}\): A bipartite graph with vertices connected in a zigzag pattern, forming two disjoint paths.
- \(L_{13}\): A bipartite graph with vertices connected in a way that forms a diamond shape in the middle, with additional edges connecting the outer vertices.

Each graph is drawn with vertices represented as circles and edges as straight lines. The labels are positioned below each graph.
TEX Edit Distance for sample 211: 0.6164016723632812
CrystalBLEU Score for sample 211: 6.391273192402583e-06
Sample 211 processing time: 39.42 seconds

Processing sample 212/560 - Caption: The image consists of two subfigures side by side. 

The left subfigure is a plot with a horizontal axis labeled "ρ" and a vertical axis labeled "f". It shows a parabolic curve with arrows along the curve pointing outward from the origin, indicating a flow or vector field. The curve is symmetric about the vertical axis.

The right subfigure is a step function plot with a horizontal axis labeled "x" ranging from -1 to 1 and a vertical axis labeled "ρ^n(t,·)". The step function has several steps of varying heights. A vertical dashed line is drawn at a specific value on the x-axis, labeled "ξ^n(t)".

This description should help in writing the TikZ code to recreate the figure.
TEX Edit Distance for sample 212: 0.6969169974327087
CrystalBLEU Score for sample 212: 6.977477972488634e-06
Sample 212 processing time: 22.74 seconds

Processing sample 213/560 - Caption: This image depicts a geometric shape consisting of a central circle with a dashed outline, inscribed within a diamond-like shape with curved sides. The diamond shape has sharp vertices at the left and right ends, and smooth, curved connections to the circle at the top and bottom. The overall structure resembles an eye with a circular pupil and curved edges.

To create this in TikZ, you would need to:
1. Draw a circle with a dashed outline.
2. Draw a diamond-like shape with curved sides that intersect the circle at the top and bottom.

Here is a sample TikZ code to help you get started:

```latex
\documentclass{standalone}
\usepackage{tikz}

\begin{document}
\begin{tikzpicture}
    % Draw the dashed circle
    \draw[dashed] (0,0) circle (2);
    
    % Draw the curved diamond shape
    \draw[thick] 
        (-4,0) -- 
        plot [smooth, tension=1] coordinates {(-2,2) (2,2)} -- 
        (4,0) -- 
        plot [smooth, tension=1] coordinates {(2,-2) (-2,-2)} -- 
        cycle;
\end{tikzpicture}
\end{document}
```

This code will create a figure similar to the one shown in the image. Adjust the coordinates and dimensions as necessary to match the exact proportions.
TEX Edit Distance for sample 213: 0.6877473592758179
CrystalBLEU Score for sample 213: 7.139733534482921e-06
Sample 213 processing time: 13.94 seconds

Processing sample 214/560 - Caption: This image depicts a graphical model, specifically a Hidden Markov Model (HMM). The model consists of a sequence of hidden states \( H_1, H_2, \ldots, H_T \) (represented by red circles) and observed states \( O_1, O_2, \ldots, O_T \) (represented by blue circles). Each hidden state \( H_t \) is connected to the next hidden state \( H_{t+1} \) with a directed arrow, indicating the Markov property. Each hidden state \( H_t \) also has a directed arrow pointing to its corresponding observed state \( O_t \). Additionally, each observed state \( O_t \) is connected to another observed variable \( X_t \) with a directed arrow. The sequence continues up to \( T \) with ellipses indicating continuation.

To create this diagram using TikZ, you would need to:
1. Define nodes for each hidden state \( H_t \) and observed state \( O_t \) and \( X_t \).
2. Use directed edges to connect \( H_t \) to \( H_{t+1} \), \( H_t \) to \( O_t \), and \( O_t \) to \( X_t \).
3. Arrange the nodes in a sequential manner horizontally for \( H_t \) and \( O_t \), and vertically for \( X_t \).

This description should help in writing the TikZ code to generate the depicted HMM diagram.
TEX Edit Distance for sample 214: 0.6286262273788452
CrystalBLEU Score for sample 214: 7.5734528214261205e-06
Sample 214 processing time: 44.92 seconds

Processing sample 215/560 - Caption: The image shows a 2-3 move transformation in a knot diagram. On the left, there are two vertical strands labeled A and A' intersecting with three horizontal strands labeled B, B', and C. The intersections are marked with small circles. The right side of the image shows the result of the 2-3 move, where the two vertical strands are now connected by an additional vertical strand, creating three intersections with the horizontal strands labeled A, A', and C. The transformation is indicated by a rightward arrow labeled "2-3 move."
TEX Edit Distance for sample 215: 0.6729042530059814
CrystalBLEU Score for sample 215: 7.255064437677611e-06
Sample 215 processing time: 13.35 seconds

Processing sample 216/560 - Caption: This figure shows a plot of Positioning Error Bound (PEB) in meters versus the Number of RIS Elements. The plot includes six different data series: 

1. UE-1 (RIS) represented by red squares and a dashed line.
2. UE-2 (RIS) represented by blue circles and a dash-dotted line.
3. UE-3 (RIS) represented by green diamonds and a dotted line.
4. UE-1 (beacon) represented by a solid red line.
5. UE-2 (beacon) represented by a solid blue line.
6. UE-3 (beacon) represented by a solid green line.

The x-axis ranges from 0 to 160, and the y-axis ranges from 0 to 1.5 meters. The legend is placed inside the plot area, at the top right corner. The background features a grid for better readability of the data points.
TEX Edit Distance for sample 216: 0.8419856429100037
CrystalBLEU Score for sample 216: 7.069449912078881e-06
Sample 216 processing time: 70.45 seconds

Processing sample 217/560 - Caption: The image shows two spiral-shaped plots, each divided into segments. The left plot is colored in a gradient from blue to green, while the right plot transitions from yellow to red. Both plots have labels: the left plot is labeled with "Ω" at the top and "φ²" in the center, while the right plot is labeled with "Ω" at the top and "∂φ" at the center. The segments in both plots appear to represent discrete elements of the spirals.
TEX Edit Distance for sample 217: 0.8093510866165161
CrystalBLEU Score for sample 217: 6.940686287739292e-06
Sample 217 processing time: 70.47 seconds

Processing sample 218/560 - Caption: The image depicts a page layout with multiple colored rectangular blocks arranged in a grid-like structure. The top section contains a large block of text spanning the entire width of the page. Below this, there are three main columns. The first column on the left contains a blue rectangle with white text inside it, followed by a green rectangle at the bottom. The middle column contains a large blue rectangle with white text inside it, and below it, a smaller green rectangle. The right column contains a red rectangle with white text inside it, followed by another red rectangle at the bottom. The layout is bordered by a black frame.

This description can help in writing the TikZ code by specifying the positions, colors, and sizes of the rectangles, as well as the text content and alignment within each rectangle.
TEX Edit Distance for sample 218: 0.7925024032592773
CrystalBLEU Score for sample 218: 6.806557402975046e-06
Sample 218 processing time: 70.47 seconds

Processing sample 219/560 - Caption: The image depicts a series of decision trees, each labeled with a specific subscript (e.g., \(T_{(1,7)}\), \(T_{(1,4)}\), etc.). Each tree consists of nodes and edges, with nodes containing numerical values and edges representing decisions or transitions. The root nodes are connected to child nodes, with some nodes containing pairs of values and others containing single values. The trees are arranged horizontally, and some nodes and edges are color-coded in red and blue to indicate different paths or decisions. The structure of each tree varies, with some having more levels and branches than others. The overall layout suggests a hierarchical decision-making process with multiple stages.

To create this figure using TikZ, you would need to define nodes and edges for each tree, specify the positions of nodes, and use color attributes for specific nodes and edges. The trees should be arranged horizontally, with appropriate spacing between them.
TEX Edit Distance for sample 219: 0.8105491995811462
CrystalBLEU Score for sample 219: 6.511249320606291e-06
Sample 219 processing time: 70.53 seconds

Processing sample 220/560 - Caption: The image consists of four subfigures, each depicting a labeled diagram with axes and points. Each subfigure shows a different configuration of points in a 3-dimensional space, labeled with coordinates and associated with specific mathematical expressions. The subfigures are arranged horizontally in a single row. Below each subfigure, there is a corresponding mathematical expression that describes the relationship between the points and their coordinates.

1. The first subfigure shows a 3D coordinate system with points labeled \( x_1 \), \( x_2 \), and \( x_3 \), and the expression \( L((1),1) = x_1 x_2 x_3 x_1 x_2 \).
2. The second subfigure shows a similar 3D coordinate system with a different configuration of points and the expression \( L((23),1) = x_1 x_2 x_3 x_2 \).
3. The third subfigure shows another 3D coordinate system with points and the expression \( L((1),(13)) = x_1 x_2 x_1 x_3 x_2 \).
4. The fourth subfigure shows the final 3D coordinate system with points and the expression \( L((23),(13)) = x_1 x_2 x_3 x_2 x_3 x_2 \).

Each subfigure includes labeled axes and points, and the mathematical expressions are placed directly below the corresponding diagrams.
TEX Edit Distance for sample 220: 0.8208420276641846
CrystalBLEU Score for sample 220: 6.131946006571683e-06
Sample 220 processing time: 70.58 seconds

Processing sample 221/560 - Caption: This image depicts a directed graph with five nodes labeled -1, 0, 1, 2, and 3. Each node is represented by a circle, and directed edges connect the nodes, indicating the direction of flow. The edges are annotated with pairs of numbers in parentheses, representing weights or capacities. The nodes are arranged in a roughly triangular layout. Specifically:

- Node 3 has outgoing edges to nodes 1 and 2, labeled with (2000, 1000) and (1600, 800) respectively.
- Node 1 has outgoing edges to nodes -1, 0, and 2, labeled with (4000, 2000), (400, 200), and (400, 200) respectively.
- Node 2 has an outgoing edge to node 0, labeled with (400, 200).
- Node -1 has an outgoing edge to node 3, labeled with (0, 0).

The arrows indicate the direction of the edges, and the labels on the edges indicate the weights or capacities associated with each edge.
TEX Edit Distance for sample 221: 0.6240202784538269
CrystalBLEU Score for sample 221: 6.738758975208351e-06
Sample 221 processing time: 21.22 seconds

Processing sample 222/560 - Caption: The image depicts a block diagram with the following components:

1. A leftward-pointing arrow at the left end, indicating an input.
2. A green circle connected to the input arrow, representing a node.
3. An oval loop starting and ending at the green circle, indicating feedback.
4. A blue square connected to the right of the green circle, representing a block or system.
5. Another green circle connected to the right of the blue square, indicating another node.
6. A rightward-pointing arrow connected to the second green circle, indicating an output.
7. A vertical arrow pointing upwards from the second green circle, indicating another output or signal.

The connections between the components are represented by solid lines, and the arrows at both ends are dashed.

This description should help you write the TikZ code for the diagram.
TEX Edit Distance for sample 222: 0.8275034427642822
CrystalBLEU Score for sample 222: 6.528334955424554e-06
Sample 222 processing time: 70.57 seconds

Processing sample 223/560 - Caption: Caption: "This image depicts a labeled graph with multiple nodes and edges. The nodes are represented by circles, some containing single numbers and others containing pairs of numbers. The nodes are connected by lines representing edges, some of which are labeled with weights. The node labeled 's' is highlighted in green, and the node labeled 'g' is highlighted in red. The graph has a complex structure with multiple connections between nodes."

This caption should help you visualize and write the TikZ code for the graph, including the nodes, edges, labels, and specific highlights for the 's' and 'g' nodes.
TEX Edit Distance for sample 223: 0.8242282271385193
CrystalBLEU Score for sample 223: 6.331527974814021e-06
Sample 223 processing time: 70.55 seconds

Processing sample 224/560 - Caption: This image depicts a complex plane diagram with two semicircles centered at the origin. The horizontal axis represents the real part of the complex plane, marked with a "0" at the origin. There are two semicircles with different radii, both centered at the origin and extending upwards. The smaller semicircle is labeled with "it_n" at its highest point, and there are two dots vertically aligned along the imaginary axis, one at the origin and the other at the label "it_n".
TEX Edit Distance for sample 224: 0.5996975302696228
CrystalBLEU Score for sample 224: 6.515611795423966e-06
Sample 224 processing time: 28.94 seconds

Processing sample 225/560 - Caption: This image depicts three distinct graphs \( G \), \( H \), and \( K \) aligned horizontally along a common baseline. The graph \( G \) consists of a diamond shape at the top connected by a vertical path of three edges to the baseline. The edges of the diamond are colored alternately in blue and red. The vertical path connecting the diamond to the baseline consists of two edges labeled \( e_0 \) and \( e_1 \), with \( e_0 \) being the topmost edge. The graph \( H \) is a simple vertical path of three edges, with the top and bottom edges colored red and the middle edge colored blue. The graph \( K \) is a diamond shape similar to the one in \( G \), with alternating blue and red edges, but it is directly on the baseline. All vertices are represented by black dots.
TEX Edit Distance for sample 225: 0.5423281788825989
CrystalBLEU Score for sample 225: 6.611461750853164e-06
Sample 225 processing time: 45.11 seconds

Processing sample 226/560 - Caption: This image depicts a complex plane with the real axis labeled as Re(T_i) and the imaginary axis labeled as Im(T_i). The plot includes a shaded green region representing an area of interest in the complex plane. The shaded region is bounded by a vertical line at Re(T_i) = 0, extending from the point labeled ρ on the imaginary axis to the point labeled 1.23i. The boundary continues horizontally from 1.23i to the right, then curves downwards and returns to the imaginary axis at the point i. The points ρ, i, and 1.23i are marked with black dots. The shaded region is enclosed by dashed lines on the right side.

This description can help in writing the TikZ code by providing information about the axes, labels, points, shaded region, and boundaries.
TEX Edit Distance for sample 226: 0.6717007756233215
CrystalBLEU Score for sample 226: 6.888078869743864e-06
Sample 226 processing time: 13.75 seconds

Processing sample 227/560 - Caption: This image depicts a graph with an \( \omega \) (vertical) axis and an \( a \) (horizontal) axis. The graph includes three horizontal dotted lines at different \( \omega \) values, each labeled \( v_{t,\omega} \) in red. There is a red arrow pointing to the right along the \( a \)-axis labeled \( v_{t,a} \). The region between the two dotted lines is labeled as \( A \). The origin is marked, and the axes are labeled. The graph appears to illustrate a relationship between \( \omega \) and \( a \) with specific velocities \( v_{t,\omega} \) and \( v_{t,a} \).
TEX Edit Distance for sample 227: 0.8082547783851624
CrystalBLEU Score for sample 227: 6.781718822874698e-06
Sample 227 processing time: 70.54 seconds

Processing sample 228/560 - Caption: This image depicts a Cartesian coordinate system with a grid, featuring a series of numbered circles placed at specific coordinates. The x-axis and y-axis are highlighted with thicker lines. The circles are either red or blue and are positioned as follows:

- Red circles are located at coordinates (0,0), (1,0), and (2,0).
- Blue circles are located at coordinates (-1,0), (-2,1), (-1,-1), (0,-2), (1,2), (2,1), and (3,1).
- Each circle contains a number from 1 to 6, indicating its label.

The grid lines are evenly spaced, and the arrows on the axes indicate the positive directions.
TEX Edit Distance for sample 228: 0.5894181132316589
CrystalBLEU Score for sample 228: 7.287838357116226e-06
Sample 228 processing time: 15.08 seconds

Processing sample 229/560 - Caption: The image consists of two subfigures, (a) and (b), each depicting a grid of black dots arranged in a regular pattern. In subfigure (a), a polyline connects several dots, forming a zigzag pattern that starts from the upper left and moves to the right. In subfigure (b), a similar but shorter zigzag pattern starts from the lower left and moves to the right. Both subfigures illustrate different paths on a grid of points.

To create this figure using TikZ, you need to:
1. Draw a grid of dots.
2. Plot the zigzag lines connecting specific dots in each subfigure.

The TikZ code should include:
- A grid of dots using `\foreach` loop for both subfigures.
- Lines connecting specific dots for the zigzag patterns in subfigures (a) and (b) using the `\draw` command.
- Labels (a) and (b) for the subfigures using the `\node` command.
TEX Edit Distance for sample 229: 0.5443785190582275
CrystalBLEU Score for sample 229: 7.458205509255235e-06
Sample 229 processing time: 14.84 seconds

Processing sample 230/560 - Caption: The image depicts a grid of squares arranged in three rows and three columns within a rectangular plot. The x-axis is labeled "X axis" and ranges from 1 to 5, while the y-axis is labeled "Y axis" and includes the labels "A", "B", and "C" corresponding to each row. Each square is centered at integer coordinates (1,1), (2,1), (3,1), (1,2), (2,2), (3,2), (1,3), (2,3), and (3,3). The plot is enclosed by a rectangular border.
TEX Edit Distance for sample 230: 0.6715073585510254
CrystalBLEU Score for sample 230: 7.829649162813142e-06
Sample 230 processing time: 15.09 seconds

Processing sample 231/560 - Caption: This image depicts a Hasse diagram of a partially ordered set (poset) representing the power set of the set {a, b, c}, ordered by inclusion. The elements of the power set are shown in curly braces, with the empty set at the bottom and the full set {a, b, c} at the top. Each line (edge) between two sets indicates that the lower set is a subset of the upper set, and there is no intermediate set between them in this ordering. The diagram includes labels on the edges, indicating the meet (greatest lower bound) operation in the lattice.

To create this diagram using TikZ, you would need to:
1. Define nodes for each subset of {a, b, c}.
2. Arrange the nodes in a diamond shape, with the empty set at the bottom and the full set at the top.
3. Draw edges between nodes to represent the subset relationships.
4. Label the edges with the meet operation results.

Here is an example of how you might start the TikZ code for this diagram:

```latex
\documentclass{standalone}
\usepackage{tikz}
\usetikzlibrary{positioning}

\begin{document}
\begin{tikzpicture}[scale=1, transform shape]
  % Define nodes
  \node (abc) at (0,4) { $\{a,b,c\}$ };
  \node (ab) at (-2,2) { $\{a,b\}$ };
  \node (ac) at (0,2) { $\{a,c\}$ };
  \node (bc) at (2,2) { $\{b,c\}$ };
  \node (a) at (-2,0) { $\{a\}$ };
  \node (b) at (0,0) { $\{b\}$ };
  \node (c) at (2,0) { $\{c\}$ };
  \node (empty) at (0,-2) { $\emptyset$ };

  % Draw edges with labels
  \draw (abc) -- node[sloped, above] {$g(\{a,b,c\})$} (ab);
  \draw (abc) -- node[sloped, above] {$g(\{a,b,c\})$} (ac);
  \draw (abc) -- node[sloped, above] {$g(\{a,b,c\})$} (bc);
  \draw (ab) -- node[sloped, above] {$g(\{a,b\})$} (a);
  \draw (ab) -- node[sloped, above] {$g(\{a,b\})$} (b);
  \draw (ac) -- node[sloped, above] {$g(\{a,c\})$} (a);
  \draw (ac) -- node[sloped, above] {$g(\{a,c\})$} (c);
  \draw (bc) -- node[sloped, above] {$g(\{b,c\})$} (b);
  \draw (bc) -- node[sloped, above] {$g(\{b,c\})$} (c);
  \draw (a) -- node[sloped, above] {$g(\{a\})$} (empty);
  \draw (b) -- node[sloped, above] {$g(\{b\})$} (empty);
  \draw (c) -- node[sloped, above] {$g(\{c\})$} (empty);
\end{tikzpicture}
\end{document}
```

This code sets up the nodes and edges for the Hasse diagram, with labels on the edges. You can adjust the positions and labels as needed to match the exact
TEX Edit Distance for sample 231: 0.46775442361831665
CrystalBLEU Score for sample 231: 9.637367775015433e-06
Sample 231 processing time: 30.23 seconds

Processing sample 232/560 - Caption: The image shows three circles demonstrating the effect of path fading and fill opacity in TikZ. The first circle on the left is a simple circle with no fill. The second circle in the middle has a gradient fill fading from white at the top to blue at the bottom, with the path fading effect applied from the south. The third circle on the right has a similar gradient fill but with a higher opacity, resulting in a more intense blue at the bottom. The text above the circles reads "With path fading=south and fill opacity".
TEX Edit Distance for sample 232: 0.59001624584198
CrystalBLEU Score for sample 232: 1.0112414946097626e-05
Sample 232 processing time: 11.85 seconds

Processing sample 233/560 - Caption: The image is a Cartesian coordinate system with a grid, ranging from 0 to 11 on both the x and y axes. It features four distinct lines, each labeled with an equation and plotted in different colors:

1. A red line labeled \( d_i^+ : y = x - x_i + y_i \) passing through points (5, 6) and (9, 10).
2. A blue line labeled \( d_i^- : y = -x + x_i + y_i \) passing through points (1, 6) and (5, 2).
3. A black line labeled \( y = x - x_j + y_j \) passing through points (5, 4) and (9, 8).
4. A brown line labeled \( y = -x + x_j + y_j \) passing through points (1, 8) and (5, 4).

The intersections of these lines are marked with blue dots and labeled as follows:
- Intersection of the red and black lines at point \( c_j \) (5, 6).
- Intersection of the blue and black lines at point \( B \) (5, 2).
- Intersection of the red and brown lines at point \( A_j^+ \) (7, 8).
- Intersection of the blue and brown lines at point \( A_i^- \) (3, 6).

The axes are labeled with arrows, and the grid lines are drawn to provide a clear reference for plotting the points and lines.
TEX Edit Distance for sample 233: 0.8026838898658752
CrystalBLEU Score for sample 233: 9.962864613047692e-06
Sample 233 processing time: 70.50 seconds

Processing sample 234/560 - Caption: The image consists of three 7x7 grids placed horizontally in a row. Each grid has arrows indicating directions. The first grid has arrows pointing up on the top edge and right on the right edge. The second grid has arrows pointing up on the top edge and right on the right edge. The third grid has arrows pointing up on the top edge and right on the right edge. The grids are separated by some space.
TEX Edit Distance for sample 234: 0.8422092795372009
CrystalBLEU Score for sample 234: 9.77216019287453e-06
Sample 234 processing time: 70.53 seconds

Processing sample 235/560 - Caption: This image consists of two distinct parts. On the left side, there is a vertical split rectangle with the left half white and the right half black, labeled with a red letter "A" in the center of the white section. On the right side, there is a horizontal gradient rectangle transitioning smoothly from black on the left to white on the right. Below the gradient rectangle, there is a horizontal arrow pointing from left to right, labeled "B" at the tail (left) and "C" at the head (right).
TEX Edit Distance for sample 235: 0.5345947742462158
CrystalBLEU Score for sample 235: 1.0148818531843429e-05
Sample 235 processing time: 13.89 seconds

Processing sample 236/560 - Caption: The image depicts a transformation of a diagram involving two arrows labeled "a" and "b" pointing to a rectangle. On the left side, the arrows "a" and "b" point downward to the top of the rectangle. An arrow labeled "τ_{a,b}" points from the left diagram to the right diagram. On the right side, the arrows "a" and "b" are swapped, with "b" on the left and "a" on the right, and an additional curved arrow loops from the bottom of the rectangle back to the top right corner.
TEX Edit Distance for sample 236: 0.7915217876434326
CrystalBLEU Score for sample 236: 9.9130268454814e-06
Sample 236 processing time: 70.56 seconds

Processing sample 237/560 - Caption: The image shows a grid of evenly spaced green dots arranged in a square pattern. The grid is enclosed within a black square border. Each dot is uniformly distributed, creating a regular lattice structure. The dots are small and circular, and the spacing between the dots is consistent both horizontally and vertically.

This description can help you write the TikZ code to create a similar figure.
TEX Edit Distance for sample 237: 0.6634960770606995
CrystalBLEU Score for sample 237: 1.0399741891095195e-05
Sample 237 processing time: 16.99 seconds

Processing sample 238/560 - Caption: The image depicts a complex directed graph with multiple nodes and edges, representing a probabilistic graphical model. The nodes are of two types: square nodes labeled \(F_1, F_2, \ldots, F_k\) and circular nodes labeled \(\alpha_1, \alpha_2, \ldots, \alpha_k\) and \(\mu_1, \mu_2, \ldots, \mu_k\). The square nodes are connected to the circular nodes via solid, dashed, and wavy lines, indicating different types of relationships or dependencies. The connections between the nodes include both directed and undirected edges, with some edges looping back to the same node. The structure is repeated for \(k\) groups, showing a pattern that can be generalized for any number of groups.
TEX Edit Distance for sample 238: 0.7057527899742126
CrystalBLEU Score for sample 238: 1.0155308132911448e-05
Sample 238 processing time: 71.55 seconds

Processing sample 239/560 - Caption: The image depicts a directed graph with four nodes labeled q0, q1, q2, and q3. The nodes are connected by directed edges, each labeled with complex mathematical expressions. The edges are color-coded, with some in black and others in red. The node q0 is at the top, connected to q1 and q2 by red edges. Node q1 is connected to q2 by a red edge and to q3 by a black edge. Node q2 is connected to q3 by a black edge. There are also edges forming loops on nodes q0 and q1, with q0 having a red loop and q1 having a black loop. The graph appears to represent a state transition system with conditions for each transition.
TEX Edit Distance for sample 239: 0.8134194612503052
CrystalBLEU Score for sample 239: 9.762783325499074e-06
Sample 239 processing time: 70.56 seconds

Processing sample 240/560 - Caption: This image depicts a directed acyclic graph (DAG) with nodes and directed edges. The nodes are labeled as follows: \( u_7 \), \( x_7 \), \( u_3 \), \( x_3 \), \( y \), \( X \), \( U \), and \( u_y \). The edges indicate the following dependencies:
- \( u_7 \) points to \( x_7 \).
- \( u_3 \) points to \( x_3 \).
- \( x_7 \) points to \( x_3 \).
- \( x_3 \) points to \( y \).
- \( y \) points to \( X \).
- \( y \) points to \( U \).
- \( u_y \) points to \( y \).

All nodes are represented as circles filled with a light blue color, and the edges are represented as black arrows.
TEX Edit Distance for sample 240: 0.6834867000579834
CrystalBLEU Score for sample 240: 1.0254812738371614e-05
Sample 240 processing time: 13.70 seconds

Processing sample 241/560 - Caption: The image consists of two subfigures labeled (a) and (b). 

Subfigure (a) depicts a circular diagram divided into four regions by lines radiating from the center. The regions are labeled as follows: the top region is labeled "B", the left region is labeled "A", the bottom region is labeled "B", and the right region is labeled "C".

Subfigure (b) shows a series of concentric circles with three points labeled on the outermost circle: "A'" on the left, "C'" on the right, and "B'" in the center. There is a vertical blue line passing through the center of the circles, connecting points "A'" and "C'".

To create this figure using TikZ, you will need to use commands for drawing circles, lines, and labeling specific points.
TEX Edit Distance for sample 241: 0.6471362709999084
CrystalBLEU Score for sample 241: 1.1541570994940027e-05
Sample 241 processing time: 24.12 seconds

Processing sample 242/560 - Caption: The image depicts two file icons connected by a line. The file on the left represents code, illustrated by a gray file icon with angle brackets ("<>") inside it and labeled "code" below. The file on the right represents a PSD file, illustrated by a blue file icon with a blue outline and labeled "file.psd" below. The two files are connected by a horizontal line in the middle, indicating a relationship or connection between the code and the PSD file.

This description should help in writing the TikZ code to create a similar diagram.
TEX Edit Distance for sample 242: 0.6263149976730347
CrystalBLEU Score for sample 242: 1.1942559317499742e-05
Sample 242 processing time: 10.86 seconds

Processing sample 243/560 - Caption: This image is a horizontal bar chart representing SHAP values for various features. The chart has the following characteristics:

- The x-axis represents the SHAP value, and it ranges from 0 to approximately 230.
- The y-axis lists the features, which include "Chemotherapy," "Gender," "dim z," "Surgery," "Age," "Count 2," "Count 0," "Count 1," "Performance status," "Weight," "eGFR," "HPVstatus," "CenterID," and "Tobacco."
- Each feature has a corresponding horizontal bar indicating its SHAP value.
- The bars are colored blue.
- The SHAP values are labeled at the end of each bar.
- There is a legend in the top right corner labeled "SHAP Value" with a blue bar next to it.

This description should help you in writing the TikZ code to recreate this bar chart.
TEX Edit Distance for sample 243: 0.6067423820495605
CrystalBLEU Score for sample 243: 1.2657084731210805e-05
Sample 243 processing time: 27.74 seconds

Processing sample 244/560 - Caption: This image consists of a 2x2 grid of plots, each depicting the alignments of vectors \( u_1 \) and \( u_2 \) with respect to \( x_1 \) and \( x_2 \). The x-axis of each plot is labeled \( \beta_2 \), and the y-axis is labeled with "Alignments of \( u_1 \)" on the left side and "Alignments of \( u_2 \)" on the right side. The top row of plots is labeled with \( \langle x_1, x_2 \rangle = 0 \) and \( \langle x_1, x_2 \rangle = 0.5 \) respectively. Each plot contains two curves: a solid blue line representing \( \langle u_1, x_1 \rangle \) and a dashed orange line representing \( \langle u_1, x_2 \rangle \) in the left column, and \( \langle u_2, x_1 \rangle \) and \( \langle u_2, x_2 \rangle \) in the right column. The bottom of each plot is labeled \( \beta_1 = \beta_2^0 \) in purple.
TEX Edit Distance for sample 244: 0.7716304659843445
CrystalBLEU Score for sample 244: 1.202851974413499e-05
Sample 244 processing time: 18.45 seconds

Processing sample 245/560 - Caption: This image consists of a diagram with multiple nodes and directed edges, labeled with coordinate pairs. The nodes are connected by different types of lines and arrows, indicating various relationships between the coordinates. The diagram includes:

1. A vertical line with an upward arrow connecting nodes labeled (x, y) and (x, z).
2. A dotted diagonal line with no arrows connecting nodes labeled (x, x) and (z, z).
3. A horizontal line with a rightward arrow connecting nodes labeled (y, x) and (z, x).
4. A horizontal line with a rightward arrow connecting nodes labeled (y, y) and (z, y).
5. Nodes labeled (x, z) and (y, z) are not connected by any lines.

This description should help in writing the TikZ code to recreate the diagram.
TEX Edit Distance for sample 245: 0.6798579692840576
CrystalBLEU Score for sample 245: 1.248962254091379e-05
Sample 245 processing time: 20.19 seconds

Processing sample 246/560 - Caption: This image consists of five horizontal lines, each labeled with a pair of repeated letters (HSHS, WSWS, ZSZS, HAHA, WAWA) positioned above the lines. Each line has a series of vertical lines extending both above and below it, ending in circles. The circles are either filled (black) or unfilled (white). The arrangement of the vertical lines and circles varies for each label. For ZSZS, there are two additional vertical lines extending below the horizontal line, ending in gray circles. This image appears to represent some form of pattern or structure associated with each label.
TEX Edit Distance for sample 246: 0.8359861969947815
CrystalBLEU Score for sample 246: 1.1824327330253196e-05
Sample 246 processing time: 70.62 seconds

Processing sample 247/560 - Caption: This image depicts a plot of a function \( f(x) \) that is decreasing and convex. The curve is colored blue from \( a_t \) to \( x_1 \) and red from \( x_1 \) to \( x_2 \). Vertical lines are drawn from the x-axis to the curve at points \( a_t \), \( a_{t+1} \), \( x_1 \), and \( x_2 \). The y-axis is labeled \( f(x) \), and the x-axis is labeled with points \( a_t \), \( a_{t+1} \), \( x_1 \), and \( x_2 \).
TEX Edit Distance for sample 247: 0.8246177434921265
CrystalBLEU Score for sample 247: 1.1664517282632524e-05
Sample 247 processing time: 70.45 seconds

Processing sample 248/560 - Caption: The image consists of two classical mosaic patterns using tiles. The first pattern is a 5x5 grid with various curved and straight line segments forming a complex design. The second pattern is a 6x6 grid with numbered rows and columns, where each cell contains a curved line segment creating a wave-like pattern across the grid. The rows and columns are labeled from 1 to 6. The designs are created using a combination of horizontal, vertical, and diagonal lines.
TEX Edit Distance for sample 248: 0.6616800427436829
CrystalBLEU Score for sample 248: 1.1401586084557296e-05
Sample 248 processing time: 10.38 seconds

Processing sample 249/560 - Caption: The image shows a 3D dodecahedron with transparent light blue faces and red edges. The dodecahedron is composed of 12 regular pentagonal faces. The edges of the pentagons are highlighted in red, while the faces are filled with a light blue color and are semi-transparent, allowing the inner structure to be visible. The perspective view displays the polyhedron in a way that multiple faces and edges are visible, giving a clear representation of its three-dimensional structure.
TEX Edit Distance for sample 249: 0.8396408557891846
CrystalBLEU Score for sample 249: 1.0927946423473112e-05
Sample 249 processing time: 70.59 seconds

Processing sample 250/560 - Caption: This image depicts a flowchart with nodes and arrows connecting them, organized in three rows labeled zz, yy, and xx. The nodes are color-coded and labeled as follows:

- In the zz row, there is a text label "something".
- In the yy row, there are three nodes: "A" (purple), "B" (purple), and "C" (purple).
- In the xx row, there are two nodes: "D" (yellow) and "E" (green).

The connections between the nodes are as follows:
- Node "A" (yy row) points to node "B" (yy row).
- Node "B" (yy row) points to node "C" (yy row).
- Node "D" (xx row) points to node "E" (xx row).

This description should help in writing the TikZ code for the flowchart.
TEX Edit Distance for sample 250: 0.6331528425216675
CrystalBLEU Score for sample 250: 1.1509558183057516e-05
Sample 250 processing time: 10.66 seconds

Processing sample 251/560 - Caption: The image depicts a finite state machine (FSM) with six states, represented by circles, and labeled with numbers 0 and 1. The FSM has directed edges labeled with binary inputs (0 or 1) indicating state transitions. The initial state is marked with an arrow pointing to it. The transitions between states are as follows:

1. From the initial state (leftmost state labeled 0), there are two outgoing edges:
   - One labeled '0' leading to the top state.
   - One labeled '1' leading to the bottom state.

2. The top state has:
   - A self-loop labeled '0'.
   - An edge labeled '1' leading to the right state.

3. The bottom state has:
   - A self-loop labeled '0,1'.
   - An edge labeled '1' leading to the right state.

4. The right state has:
   - An edge labeled '0' leading to the next state to the right.

5. The next state to the right has:
   - A self-loop labeled '0'.
   - An edge labeled '1' leading to the final state.

6. The final state has:
   - A self-loop labeled '0'.
   - An edge labeled '1' leading back to the previous state.

This description should help in writing the TikZ code to represent this FSM.
TEX Edit Distance for sample 251: 0.7954628467559814
CrystalBLEU Score for sample 251: 1.1351324280074232e-05
Sample 251 processing time: 70.31 seconds

Processing sample 252/560 - Caption: The image consists of two graphs side by side. 

On the left, there is a labeled graph \( G \) with six vertices labeled \( a, b, c, d, e, \) and \( f \). The vertices are connected by edges as follows: \( (a, d), (a, e), (a, f), (b, e), (b, f), (c, e), (c, f) \).

On the right, there is a labeled graph \( TS_2(G) \) which represents the 2-subset graph of \( G \). The vertices are labeled with 2-subsets of the vertex set of \( G \): \( ab, ac, ae, bd, ef, \) and \( ce \). The edges connect vertices that share a common element in their subsets: \( (ab, ac), (ab, ae), (ac, ce), (ae, ef), (bd, ef) \).

The vertices in both graphs are represented by circles, and the edges are represented by straight lines connecting the vertices. The labels are placed near the corresponding vertices.
TEX Edit Distance for sample 252: 0.8032310605049133
CrystalBLEU Score for sample 252: 1.112210632083639e-05
Sample 252 processing time: 70.38 seconds

Processing sample 253/560 - Caption: The image shows three triangular diagrams side by side, each with vertices labeled by coordinates and edges labeled by different symbols. 

- The first triangle on the left has vertices at (1,1), (3,2), (2,1), and (2,2). The edges are labeled \(T_1\), \(T_2\), and \(T_3\), with \(T_1\) and \(T_3\) in red.
- The middle triangle has vertices at (1,1), (3,2), (3,1), and (2,2). The edges are labeled \(T_1''\), \(T_2''\), and \(T_3''\), with \(T_3''\) in red.
- The right triangle has vertices at (1,1), (3,2), (3,1), and (2,2). The edges are labeled \(T_1'''\), \(T_2'''\), and \(T_3'''\), with \(T_2''' \) in red and \(T_3''' \) in a dotted line.

Each triangle shares the same set of coordinates for vertices but differs in the labeling and styling of the edges.
TEX Edit Distance for sample 253: 0.7231215238571167
CrystalBLEU Score for sample 253: 1.0861911407604435e-05
Sample 253 processing time: 70.47 seconds

Processing sample 254/560 - Caption: The image depicts a 2D coordinate system with axes labeled \(x_1\) and \(x_2\). There is an ellipse centered at the origin, and a square centered at the origin with its sides parallel to the axes. The square is shaded with blue diagonal lines. The ellipse intersects the square at four points. The region inside the square is marked as \(Q\), and the entire plane is labeled as \(X\). Horizontal lines extend from the sides of the square to the edges of the ellipse.
TEX Edit Distance for sample 254: 0.8144744038581848
CrystalBLEU Score for sample 254: 1.078617558737098e-05
Sample 254 processing time: 70.31 seconds

Processing sample 255/560 - Caption: This image depicts a 3D hexagonal prism with a height \( h \). The top face of the prism is a regular hexagon labeled as \( B \) and is highlighted in yellow with red edges. The vertical edges and the bottom face of the prism are shown with solid black lines, while the hidden edges are represented with dashed lines. The height \( h \) is marked on the right side of the prism. The hexagonal base is parallel to the top face and shares the same dimensions.
TEX Edit Distance for sample 255: 0.8238176703453064
CrystalBLEU Score for sample 255: 1.05815476081724e-05
Sample 255 processing time: 70.42 seconds

Processing sample 256/560 - Caption: This image depicts a Cayley graph for the symmetric group \( S_3 \) with vertices representing the elements of \( S_3 \) and edges labeled by transpositions. The central vertex is labeled "0" and connected to other vertices by colored edges. Each vertex has a corresponding tree diagram illustrating the permutation. The edges are color-coded and labeled with transpositions: blue for 12/03, orange for 13/02, and green for 23/01. The vertices are arranged in a manner that highlights the structure of the group and the action of the transpositions on the elements.
slurmstepd: error: *** JOB 9450607 ON cn017 CANCELLED AT 2024-11-17T12:21:04 ***
